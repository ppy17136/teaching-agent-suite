# app.py - å®Œæ•´é›†æˆ LLM å…¨é‡è§£æä¸ Key è½®æ¢ç‰ˆæœ¬
from __future__ import annotations

import io
import os
import re
import json
import uuid
import zipfile
import hashlib
import time
import datetime as dt
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st
import pandas as pd
import requests
import streamlit.components.v1 as components
import pdfplumber
import google.generativeai as genai
from openai import OpenAI

# ---- Word å¯¼å‡ºæ”¯æŒ ----
try:
    from docx import Document
    from docx.shared import Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH
except Exception:
    Document = None

# ============================================================
# 1. é…ç½®ä¸å…¨å±€å¸¸é‡
# ============================================================
APP_NAME = "Teaching Agent Suite"
APP_VERSION = "v0.7 (LLM-Mega-Extraction)"
DATA_ROOT = Path("data/projects")

PROVIDERS = {
    "Gemini (Google)": {"base_url": None, "model": "gemini-1.5-flash"},
    "DeepSeek": {"base_url": "https://api.deepseek.com", "model": "deepseek-chat"},
    "Kimi (Moonshot)": {"base_url": "https://api.moonshot.cn/v1", "model": "moonshot-v1-8k"},
    "æ™ºè°± AI (GLM)": {"base_url": "https://open.bigmodel.cn/api/paas/v4/", "model": "glm-4"},
    "é›¶ä¸€ä¸‡ç‰© (Yi)": {"base_url": "https://api.lingyiwanwu.com/v1", "model": "yi-34b-chat-0205"},
    "é€šä¹‰åƒé—® (Qwen)": {"base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1", "model": "qwen-plus"},
    "è±†åŒ… (å­—èŠ‚)": {"base_url": "https://ark.cn-beijing.volces.com/api/v3", "model": "doubao-pro-32k"}
}

SECTION_TITLES = [
    "ä¸€ã€åŸ¹å…»ç›®æ ‡", "äºŒã€æ¯•ä¸šè¦æ±‚", "ä¸‰ã€ä¸“ä¸šå®šä½ä¸ç‰¹è‰²",
    "å››ã€ä¸»å¹²å­¦ç§‘ã€ä¸“ä¸šæ ¸å¿ƒè¯¾ç¨‹å’Œä¸»è¦å®è·µæ€§æ•™å­¦ç¯èŠ‚",
    "äº”ã€æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½", "å…­ã€æ¯•ä¸šæ¡ä»¶",
    "ä¸ƒã€ä¸“ä¸šæ•™å­¦è®¡åˆ’è¡¨", "å…«ã€å­¦åˆ†ç»Ÿè®¡è¡¨", "ä¹ã€æ•™å­¦è¿›ç¨‹è¡¨",
    "åã€è¯¾ç¨‹è®¾ç½®å¯¹æ¯•ä¸šè¦æ±‚æ”¯æ’‘å…³ç³»è¡¨", "åä¸€ã€è¯¾ç¨‹è®¾ç½®é€»è¾‘æ€ç»´å¯¼å›¾",
]

# æ˜ å°„ï¼šå¤§æ¨¡å‹ JSON å­—æ®µ -> UI æ ‡å‡†æ ‡é¢˜
LLM_TO_STANDARD_MAP = {
    "1åŸ¹å…»ç›®æ ‡": "ä¸€ã€åŸ¹å…»ç›®æ ‡",
    "2æ¯•ä¸šè¦æ±‚": "äºŒã€æ¯•ä¸šè¦æ±‚",
    "3ä¸“ä¸šå®šä½ä¸ç‰¹è‰²": "ä¸‰ã€ä¸“ä¸šå®šä½ä¸ç‰¹è‰²",
    "4ä¸»å¹²å­¦ç§‘/æ ¸å¿ƒè¯¾ç¨‹/å®è·µç¯èŠ‚": "å››ã€ä¸»å¹²å­¦ç§‘ã€ä¸“ä¸šæ ¸å¿ƒè¯¾ç¨‹å’Œä¸»è¦å®è·µæ€§æ•™å­¦ç¯èŠ‚",
    "5æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½": "äº”ã€æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½",
    "6æ¯•ä¸šæ¡ä»¶": "å…­ã€æ¯•ä¸šæ¡ä»¶",
}

# ============================================================
# 2. LLM æ ¸å¿ƒè·¯ç”±ä¸ Key è½®æ¢
# ============================================================

def call_llm_core(provider_name, api_key, prompt):
    """åº•å±‚çš„ API è°ƒç”¨"""
    config = PROVIDERS[provider_name]
    if "Gemini" in provider_name:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(config["model"])
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(response.text)
    else:
        client = OpenAI(api_key=api_key, base_url=config["base_url"])
        response = client.chat.completions.create(
            model=config["model"],
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåªè¾“å‡º JSON çš„æ•™åŠ¡ä¸“å®¶åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)

def call_llm_with_retry_and_rotation(provider_name, user_api_key, prompt):
    """å¸¦è½®æ¢å’Œé‡è¯•é€»è¾‘çš„è·¯ç”±"""
    all_keys = st.secrets.get("GEMINI_KEYS", [])
    if "Gemini" not in provider_name or user_api_key:
        target_key = user_api_key if user_api_key else st.secrets.get("GEMINI_API_KEY", "")
        return call_llm_core(provider_name, target_key, prompt)

    if not all_keys:
        raise Exception("æœªåœ¨ Secrets ä¸­é…ç½® GEMINI_KEYS åˆ—è¡¨")

    if "api_key_index" not in st.session_state:
        st.session_state.api_key_index = 0

    start_idx = st.session_state.api_key_index % len(all_keys)
    for i in range(len(all_keys)):
        curr_idx = (start_idx + i) % len(all_keys)
        curr_key = all_keys[curr_idx]
        st.session_state.api_key_index = curr_idx
        try:
            st.write(f"æ­£åœ¨å°è¯•ä½¿ç”¨ Key #{curr_idx + 1}...")
            result = call_llm_core(provider_name, curr_key, prompt)
            st.session_state.api_key_index = (curr_idx + 1) % len(all_keys)
            return result
        except Exception as e:
            err = str(e).lower()
            if any(x in err for x in ["429", "quota", "limit"]):
                st.warning(f"âš ï¸ Key #{curr_idx + 1} é…é¢è€—å°½ï¼Œå°è¯•åˆ‡æ¢...")
                continue
            raise e
    raise Exception("âŒ æ‰€æœ‰é…ç½®çš„ Key å‡å·²å¤±æ•ˆæˆ–è¶…é™ã€‚")

# ============================================================
# 3. åŸ¹å…»æ–¹æ¡ˆå…¨é‡è§£æå¼•æ“
# ============================================================

MEGA_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é«˜æ ¡æ•™åŠ¡ä¸“å®¶ã€‚è¯·æ·±åº¦é˜…è¯»æä¾›çš„çš„åŸ¹å…»æ–¹æ¡ˆæ–‡æœ¬ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ç²¾ç¡®æå–ä¿¡æ¯ã€‚

### æå–è¦æ±‚ï¼š
1. **åˆ†æ¡åˆ—å‡º**ï¼šæ¯•ä¸šè¦æ±‚ç­‰å­é¡¹å¿…é¡»ä¿ç•™åŸå§‹ç¼–å·ï¼Œä½¿ç”¨ Markdown åˆ—è¡¨ã€‚
2. **å®Œæ•´æ€§**ï¼šå¿…é¡»åŒ…å«æ‰€æœ‰ç»†åˆ†æ¡æ¬¾ï¼ˆå¦‚å…·ä½“çš„å­¦åˆ†æ•°å€¼ï¼‰ã€‚
3. **è¡¨æ ¼ç²¾åº¦**ï¼š
   - é™„è¡¨ 1ï¼š(æ•™å­¦è®¡åˆ’è¡¨) æå–æ‰€æœ‰è¯¾ç¨‹ï¼Œä¿ç•™å­¦ä½è¯¾æ ‡è®°ã€‚
   - é™„è¡¨ 2ï¼š(å­¦åˆ†ç»Ÿè®¡) åŒºåˆ†ä¸åŒä¸“ä¸šæ–¹å‘ã€‚
   - é™„è¡¨ 4ï¼š(æ”¯æ’‘çŸ©é˜µ) æå– H/M/L å¼ºåº¦ã€‚

### è¾“å‡ºæ ¼å¼ï¼š
å¿…é¡»è¾“å‡ºå¦‚ä¸‹ JSONï¼š
{
  "sections": {
    "1åŸ¹å…»ç›®æ ‡": "...", "2æ¯•ä¸šè¦æ±‚": "...", "3ä¸“ä¸šå®šä½ä¸ç‰¹è‰²": "...",
    "4ä¸»å¹²å­¦ç§‘/æ ¸å¿ƒè¯¾ç¨‹/å®è·µç¯èŠ‚": "...", "5æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½": "...", "6æ¯•ä¸šæ¡ä»¶": "..."
  },
  "table1": [{"è¯¾ç¨‹åç§°": "...", "è¯¾å†…å­¦åˆ†": "...", ...}],
  "table2": [...], "table4": [...]
}"""

def base_plan_llm_mega_parse(pdf_bytes, provider_name, api_key):
    """å¸¦è¿›åº¦æ˜¾ç¤ºçš„ AI å…¨é‡è§£æ"""
    with st.status(f"ğŸš€ æ­£åœ¨é€šè¿‡ {provider_name} è§£æåŸ¹å…»æ–¹æ¡ˆ...", expanded=True) as status:
        try:
            st.write("ğŸ” æ­£åœ¨æå– PDF æ–‡æœ¬...")
            with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
                all_text = "\n".join([p.extract_text() or "" for p in pdf.pages])
            
            st.write(f"ğŸ“‘ æ­£åœ¨å‘é€ AI æŠ½å–è¯·æ±‚ (å†…å®¹é•¿åº¦: {len(all_text)})...")
            prompt = f"{MEGA_PROMPT}\n\nåŸ¹å…»æ–¹æ¡ˆåŸæ–‡ï¼š\n{all_text}"
            
            start_time = time.time()
            raw_result = call_llm_with_retry_and_rotation(provider_name, api_key, prompt)
            
            # æ ¼å¼è½¬æ¢æ˜ å°„
            standard_sections = {}
            llm_sections = raw_result.get("sections", {})
            for l_key, s_key in LLM_TO_STANDARD_MAP.items():
                standard_sections[s_key] = llm_sections.get(l_key, "")
            
            append_tables = {
                "ä¸ƒã€ä¸“ä¸šæ•™å­¦è®¡åˆ’è¡¨": raw_result.get("table1", []),
                "å…«ã€å­¦åˆ†ç»Ÿè®¡è¡¨": raw_result.get("table2", []),
                "ä¹ã€æ•™å­¦è¿›ç¨‹è¡¨": [], 
                "åã€è¯¾ç¨‹è®¾ç½®å¯¹æ¯•ä¸šè¦æ±‚æ”¯æ’‘å…³ç³»è¡¨": raw_result.get("table4", [])
            }

            status.update(label="âœ… è§£ææˆåŠŸï¼", state="complete", expanded=False)
            return {
                "meta": {"sha256": hashlib.sha256(pdf_bytes).hexdigest(), "rev": int(time.time()), "provider": provider_name},
                "sections": standard_sections,
                "appendices": {"tables": append_tables},
                "course_graph": {"nodes": [], "edges": []},
                "raw_pages_text": [all_text]
            }
        except Exception as e:
            status.update(label="âŒ è§£æå¤±è´¥", state="error", expanded=True)
            st.error(str(e))
            return None

# ============================================================
# 4. Persistence & Utilities (ä¿æŒåŸæœ‰é€»è¾‘)
# ============================================================

def safe_json_load(s: str, default: Any = None) -> Any:
    try: return json.loads(s)
    except: return default

def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True)

@dataclass
class Project:
    project_id: str; name: str; llm: Dict[str, Any] = field(default_factory=dict)
    updated_at: str = ""; logo_file: str = ""

def load_base_plan(pid: str) -> Dict[str, Any]:
    p = DATA_ROOT / pid / "base_training_plan.json"
    return safe_json_load(p.read_text("utf-8"), {}) if p.exists() else {}

def save_base_plan(pid: str, plan: Dict[str, Any]):
    ensure_dir(DATA_ROOT / pid)
    (DATA_ROOT / pid / "base_training_plan.json").write_text(json.dumps(plan, ensure_ascii=False, indent=2), "utf-8")

# ============================================================
# 5. UI éƒ¨åˆ†
# ============================================================

def ui_base_training_plan(pid: str):
    st.subheader("åŸ¹å…»æ–¹æ¡ˆåŸºåº§ (LLM å…¨é‡è§£æç‰ˆ)")
    plan = load_base_plan(pid)
    rev = plan.get("meta", {}).get("rev", 0)

    colL, colR = st.columns([1, 2])
    with colL:
        provider = st.selectbox("é€‰æ‹©è§£ææ¨¡å‹", list(PROVIDERS.keys()))
        api_key = st.text_input("æ‰‹åŠ¨ API Key (å¯é€‰)", type="password")
        up = st.file_uploader("ä¸Šä¼  PDF åŸ¹å…»æ–¹æ¡ˆ", type=["pdf"])
        
        if up and st.button("ğŸš€ æ‰§è¡Œå…¨é‡ AI æŠ½å–", type="primary", use_container_width=True):
            res = base_plan_llm_mega_parse(up.read(), provider, api_key)
            if res:
                save_base_plan(pid, res)
                st.rerun()

    with colR:
        if not plan: st.info("è¯·å…ˆä¸Šä¼ å¹¶è§£æåŸ¹å…»æ–¹æ¡ˆã€‚"); return
        
        tabs = st.tabs(SECTION_TITLES)
        sections = plan.get("sections", {})
        append_tables = plan.get("appendices", {}).get("tables", {})

        for i, title in enumerate(SECTION_TITLES[:6]):
            with tabs[i]:
                st.text_area(title, value=sections.get(title, ""), height=300, key=f"txt_{rev}_{i}")

        for j, title in enumerate(SECTION_TITLES[6:10], start=6):
            with tabs[j]:
                df = pd.DataFrame(append_tables.get(title, []))
                st.data_editor(df, num_rows="dynamic", use_container_width=True, key=f"edt_{rev}_{j}")

def main():
    st.set_page_config(layout="wide", page_title=APP_NAME)
    ensure_dir(DATA_ROOT)
    
    # ç®€å•çš„é¡¹ç›®åˆå§‹åŒ–
    pid = "default_project"
    if not (DATA_ROOT / pid).exists(): ensure_dir(DATA_ROOT / pid)

    st.title(f"ğŸ§  {APP_NAME} {APP_VERSION}")
    
    tab_base, tab_docs = st.tabs(["åŸ¹å…»æ–¹æ¡ˆåŸºåº§", "æ•™å­¦æ–‡ä»¶ç®¡ç†"])
    with tab_base: ui_base_training_plan(pid)
    with tab_docs: st.info("æ•™å­¦æ–‡ä»¶ç®¡ç†æ¨¡å—å·²å°±ç»ªï¼Œæ­£åœ¨åŒæ­¥åŸºåº§æ•°æ®...")

if __name__ == "__main__":
    main()