# app.py
# Teaching Agent Suite (single-file demo)
# - Base plan 1-11 extraction
# - Appendix tables (7-10) auto extraction + classification
# - Streamlit keys fixed (no DuplicateElementKey / ValueAssignmentNotAllowedError)
# - Sidebar logo fixed (components.html or upload image)

from __future__ import annotations

import io
import re
import json
import time
import hashlib
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional, Any

import pandas as pd
import streamlit as st
import pdfplumber
import streamlit.components.v1 as components

def payload_to_jsonable(payload: dict) -> dict:
    """æŠŠ payload é‡Œçš„ DataFrame / numpy ç±»å‹è½¬æˆ JSON å¯åºåˆ—åŒ–å¯¹è±¡ã€‚"""
    if payload is None:
        return {}

    out = {}
    for k, v in payload.items():
        if isinstance(v, pd.DataFrame):
            df = v.copy()
            df = df.fillna("")
            out[k] = {
                "__type__": "dataframe",
                "columns": [str(c) for c in df.columns.tolist()],
                "data": df.astype(str).values.tolist(),
            }
        elif isinstance(v, dict):
            out[k] = payload_to_jsonable(v)
        elif isinstance(v, list):
            out[k] = [payload_to_jsonable(x) if isinstance(x, dict) else x for x in v]
        else:
            # å…œåº•ï¼šæŠŠ pandas/numpy çš„æ ‡é‡è½¬æˆ Python æ ‡é‡
            try:
                if hasattr(v, "item") and callable(v.item):
                    out[k] = v.item()
                else:
                    out[k] = v
            except Exception:
                out[k] = str(v)
    return out

# -----------------------------
# Helpers
# -----------------------------
def _now_str() -> str:
    return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())


def _short_id(s: str) -> str:
    return hashlib.md5(s.encode("utf-8")).hexdigest()[:10]


def _safe_text(x: Any) -> str:
    if x is None:
        return ""
    return str(x).strip()


def _compact_lines(s: str) -> str:
    s = s.replace("\u00a0", " ")
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def _join_pages(pages_text: List[str]) -> str:
    return _compact_lines("\n\n".join([t or "" for t in pages_text]))


def _read_pdf_pages_text(pdf_bytes: bytes) -> List[str]:
    pages = []
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        for p in pdf.pages:
            txt = p.extract_text() or ""
            pages.append(_compact_lines(txt))
    return pages


# -----------------------------
# Base plan (sections 1-11) text extraction (regex best-effort)
# -----------------------------
_SECTION_PATTERNS: List[Tuple[str, List[str]]] = [
    ("1", [r"ä¸€[ã€\.\s]*åŸ¹å…»ç›®æ ‡", r"1[ã€\.\s]*åŸ¹å…»ç›®æ ‡"]),
    ("2", [r"äºŒ[ã€\.\s]*æ¯•ä¸šè¦æ±‚", r"2[ã€\.\s]*æ¯•ä¸šè¦æ±‚"]),
    ("3", [r"ä¸‰[ã€\.\s]*ä¸“ä¸šå®šä½ä¸ç‰¹è‰²", r"3[ã€\.\s]*ä¸“ä¸šå®šä½ä¸ç‰¹è‰²"]),
    ("4", [r"å››[ã€\.\s]*ä¸»å¹²å­¦ç§‘.*?å®è·µ.*?ç¯èŠ‚", r"4[ã€\.\s]*ä¸»å¹²å­¦ç§‘"]),
    ("5", [r"äº”[ã€\.\s]*æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½", r"5[ã€\.\s]*æ ‡å‡†å­¦åˆ¶"]),
    ("6", [r"å…­[ã€\.\s]*æ¯•ä¸šæ¡ä»¶", r"6[ã€\.\s]*æ¯•ä¸šæ¡ä»¶"]),
    ("7", [r"ä¸ƒ[ã€\.\s]*ä¸“ä¸šæ•™å­¦è®¡åˆ’è¡¨", r"7[ã€\.\s]*ä¸“ä¸šæ•™å­¦è®¡åˆ’è¡¨"]),
    ("8", [r"å…«[ã€\.\s]*å­¦åˆ†ç»Ÿè®¡è¡¨", r"8[ã€\.\s]*å­¦åˆ†ç»Ÿè®¡è¡¨"]),
    ("9", [r"ä¹[ã€\.\s]*æ•™å­¦è¿›ç¨‹è¡¨", r"9[ã€\.\s]*æ•™å­¦è¿›ç¨‹è¡¨"]),
    ("10", [r"å[ã€\.\s]*è¯¾ç¨‹è®¾ç½®å¯¹æ¯•ä¸šè¦æ±‚æ”¯æ’‘å…³ç³»è¡¨", r"10[ã€\.\s]*è¯¾ç¨‹è®¾ç½®å¯¹æ¯•ä¸šè¦æ±‚æ”¯æ’‘å…³ç³»è¡¨"]),
    ("11", [r"åä¸€[ã€\.\s]*è¯¾ç¨‹è®¾ç½®é€»è¾‘æ€ç»´å¯¼å›¾", r"11[ã€\.\s]*è¯¾ç¨‹è®¾ç½®é€»è¾‘æ€ç»´å¯¼å›¾"]),
]


def _build_section_spans(full_text: str) -> Dict[str, Tuple[int, int]]:
    """
    Find each section heading position; return char spans [start,end) for each section.
    """
    hits: List[Tuple[str, int]] = []
    for sec_id, pats in _SECTION_PATTERNS:
        pos = None
        for pat in pats:
            m = re.search(pat, full_text)
            if m:
                pos = m.start()
                break
        if pos is not None:
            hits.append((sec_id, pos))

    hits.sort(key=lambda x: x[1])
    spans: Dict[str, Tuple[int, int]] = {}
    for i, (sec_id, start) in enumerate(hits):
        end = hits[i + 1][1] if i + 1 < len(hits) else len(full_text)
        spans[sec_id] = (start, end)
    return spans


def _extract_section_text(full_text: str, spans: Dict[str, Tuple[int, int]], sec_id: str) -> str:
    if sec_id not in spans:
        return ""
    s, e = spans[sec_id]
    chunk = full_text[s:e].strip()

    # å»æ‰æ ‡é¢˜è¡Œè‡ªèº«ï¼ˆå°½é‡ï¼‰
    chunk = re.sub(r"^\s*(ä¸€|äºŒ|ä¸‰|å››|äº”|å…­|ä¸ƒ|å…«|ä¹|å|åä¸€|\d+)[ã€\.\s]*[^\n]{0,30}\n", "", chunk)
    return _compact_lines(chunk)


# -----------------------------
# Appendix table extraction (pdfplumber) + classification
# -----------------------------
def _valid_table_settings_lines() -> dict:
    """
    Safe pdfplumber settings (avoid TableSettings.resolve TypeError).
    """
    # è¿™äº› key æ˜¯ pdfplumber å¸¸ç”¨ä¸”ç›¸å¯¹ç¨³å®šçš„
    return dict(
        vertical_strategy="lines",
        horizontal_strategy="lines",
        snap_tolerance=3,
        join_tolerance=3,
        edge_min_length=3,
        intersection_tolerance=3,
        text_tolerance=3,
    )


def _extract_tables_from_pages(pdf_bytes: bytes, page_idx_list: List[int]) -> List[List[List[str]]]:
    """
    Return: list of tables; table is list of rows; row is list of cell strings.
    """
    out: List[List[List[str]]] = []
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        for idx in page_idx_list:
            if idx < 0 or idx >= len(pdf.pages):
                continue
            page = pdf.pages[idx]

            # try "lines" settings first, fallback to default
            tables = []
            try:
                tables = page.extract_tables(table_settings=_valid_table_settings_lines()) or []
            except TypeError:
                tables = page.extract_tables() or []
            except Exception:
                # å†å…œåº•ä¸€æ¬¡ï¼šæœ‰äº› PDF ä¼šåœ¨ extract_tables æŠ›æœªçŸ¥å¼‚å¸¸
                try:
                    tables = page.extract_tables() or []
                except Exception:
                    tables = []

            for t in tables:
                # t: list[list[cell]]
                norm = []
                for row in t:
                    norm.append([_safe_text(c) for c in row])
                out.append(norm)
    return out


def _table_to_df(table_rows: List[List[str]]) -> pd.DataFrame:
    # è¿‡æ»¤å…¨ç©ºè¡Œ
    rows = [r for r in table_rows if any(_safe_text(x) for x in r)]
    if not rows:
        return pd.DataFrame()

    # ç»Ÿä¸€åˆ—æ•°
    max_cols = max(len(r) for r in rows)
    rows = [r + [""] * (max_cols - len(r)) for r in rows]

    # å°è¯•è¯†åˆ«è¡¨å¤´ï¼šç¬¬ä¸€è¡Œå¦‚æœâ€œåƒè¡¨å¤´â€
    header = rows[0]
    header_join = " ".join(header)
    header_like = any(k in header_join for k in ["è¯¾ç¨‹", "å­¦åˆ†", "å‘¨æ¬¡", "æŒ‡æ ‡", "æ”¯æ’‘", "åˆè®¡", "è¯¾ç¨‹ç¼–ç ", "è¯¾ç¨‹åç§°"])
    if header_like:
        cols = [c if c else f"åˆ—{i+1}" for i, c in enumerate(header)]
        df = pd.DataFrame(rows[1:], columns=_dedup_cols(cols))
    else:
        cols = [f"åˆ—{i+1}" for i in range(max_cols)]
        df = pd.DataFrame(rows, columns=cols)

    return _clean_df(df)


def _dedup_cols(cols: List[str]) -> List[str]:
    seen = {}
    out = []
    for c in cols:
        c0 = c.strip() or "åˆ—"
        if c0 not in seen:
            seen[c0] = 1
            out.append(c0)
        else:
            seen[c0] += 1
            out.append(f"{c0}_{seen[c0]}")
    return out


def _clean_df(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()

    # å»æ‰å…¨ç©ºåˆ—
    df = df.copy()
    df.replace({None: ""}, inplace=True)

    # æŠŠ "nan" æ–‡æœ¬ä¹Ÿæ¸…æ‰
    df = df.applymap(lambda x: "" if str(x).strip().lower() == "nan" else str(x).strip())

    # drop all-empty rows/cols
    df = df.loc[~df.apply(lambda r: all((str(x).strip() == "") for x in r), axis=1)]
    df = df.loc[:, ~df.apply(lambda c: all((str(x).strip() == "") for x in c), axis=0)]

    # å†æ¬¡ reset index
    df = df.reset_index(drop=True)

    # æœ‰äº› PDF è¡¨ä¼šæŠŠ â€œå›› äº” å…­ ä¸ƒ å…«â€ è¿™ç§å­¦æœŸè¡ŒæŠ½æˆä¸€è¡Œæ··åœ¨æ•°æ®é‡Œï¼šè‹¥è¯¥è¡Œå¤šæ•°å­—æ®µæ˜¯ä¸­æ–‡æ•°å­—ï¼Œå»æ‰
    def _looks_like_semester_row(row: pd.Series) -> bool:
        tokens = [str(x).strip() for x in row.tolist() if str(x).strip()]
        if len(tokens) < 3:
            return False
        cn_nums = set(list("ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å"))
        hits = sum(1 for t in tokens if (len(t) == 1 and t in cn_nums))
        return hits >= 3

    if not df.empty:
        df = df.loc[~df.apply(_looks_like_semester_row, axis=1)].reset_index(drop=True)

    return df


def _table_signature_text(df: pd.DataFrame) -> str:
    if df is None or df.empty:
        return ""
    head = " ".join([str(c) for c in df.columns.tolist()])
    top_rows = []
    for i in range(min(3, len(df))):
        top_rows.append(" ".join([str(x) for x in df.iloc[i].tolist()]))
    return (head + " " + " ".join(top_rows)).lower()


def _classify_table(df: pd.DataFrame) -> Tuple[str, int]:
    """
    Return (section_id, score). section_id in {"7","8","9","10"} or ("",0)
    """
    s = _table_signature_text(df)

    # ä¸“ä¸šæ•™å­¦è®¡åˆ’è¡¨ï¼šå…¸å‹å­—æ®µï¼šè¯¾ç¨‹ç¼–ç /è¯¾ç¨‹åç§°/å­¦åˆ†/æ€»å­¦æ—¶/è€ƒæ ¸/å¼€è¯¾
    score7 = 0
    for k in ["è¯¾ç¨‹ç¼–ç ", "è¯¾ç¨‹ä»£ç ", "è¯¾ç¨‹åç§°", "å­¦åˆ†", "æ€»å­¦æ—¶", "è€ƒæ ¸", "å¼€è¯¾"]:
        if k in s:
            score7 += 3

    # å­¦åˆ†ç»Ÿè®¡è¡¨ï¼šå…¸å‹å­—æ®µï¼šé€šè¯†/ä¸“ä¸š/å®è·µ/å¿…ä¿®/é€‰ä¿®/å°è®¡/åˆè®¡
    score8 = 0
    for k in ["å­¦åˆ†ç»Ÿè®¡", "å¿…ä¿®", "é€‰ä¿®", "é€šè¯†", "ä¸“ä¸š", "å®è·µ", "åˆè®¡", "å°è®¡"]:
        if k in s:
            score8 += 3

    # æ•™å­¦è¿›ç¨‹è¡¨ï¼šå…¸å‹å­—æ®µï¼šå‘¨æ¬¡/æ•™å­¦å†…å®¹/å­¦æ—¶/å®éªŒ/ç« èŠ‚/è¿›åº¦
    score9 = 0
    for k in ["å‘¨æ¬¡", "æ•™å­¦å†…å®¹", "è¿›åº¦", "ç« èŠ‚", "å­¦æ—¶", "å®éªŒ"]:
        if k in s:
            score9 += 3

    # æ”¯æ’‘å…³ç³»è¡¨ï¼šå…¸å‹å­—æ®µï¼šæ¯•ä¸šè¦æ±‚/æŒ‡æ ‡ç‚¹/æ”¯æ’‘/è¯¾ç¨‹å¯¹â€¦/è¾¾æˆ
    score10 = 0
    for k in ["æ¯•ä¸šè¦æ±‚", "æŒ‡æ ‡ç‚¹", "æ”¯æ’‘", "è¾¾æˆ", "å¯¹åº”", "è¯¾ç¨‹è®¾ç½®å¯¹æ¯•ä¸šè¦æ±‚"]:
        if k in s:
            score10 += 3

    scores = [("7", score7), ("8", score8), ("9", score9), ("10", score10)]
    best = max(scores, key=lambda x: x[1])
    if best[1] >= 6:
        return best
    return ("", 0)


def extract_appendix_tables_best_effort(pdf_bytes: bytes, pages_text: List[str]) -> Tuple[Dict[str, pd.DataFrame], Dict[str, Any]]:
    """
    ä» PDF æœ«å°¾é¡µé¢æŠ½å–è¡¨æ ¼ï¼Œè‡ªåŠ¨åˆ†ç±»åˆ†é…åˆ° 7-10ã€‚
    Return:
      tables_map: {"7":df, "8":df, "9":df, "10":df}
      debug_meta: helpful debug info
    """
    n = len(pages_text)
    tail_pages = list(range(max(0, n - 12), n))  # é»˜è®¤æŠ½æœ€å 12 é¡µ
    raw_tables = _extract_tables_from_pages(pdf_bytes, tail_pages)

    dfs: List[pd.DataFrame] = []
    for t in raw_tables:
        df = _table_to_df(t)
        if df is None or df.empty:
            continue
        # å¤ªå°çš„è¡¨ä¸è¦ï¼ˆé˜²æ­¢å™ªå£°ï¼‰
        if df.shape[0] < 2 and df.shape[1] < 3:
            continue
        dfs.append(df)

    assigned: Dict[str, pd.DataFrame] = {}
    used_idx = set()
    scored: List[Tuple[int, str, int]] = []  # (idx, sec, score)
    for i, df in enumerate(dfs):
        sec, score = _classify_table(df)
        if sec:
            scored.append((i, sec, score))

    # è´ªå¿ƒï¼šæŒ‰ score ä»å¤§åˆ°å°åˆ†é…ï¼Œç¡®ä¿æ¯ä¸ª sec åªå–ä¸€å¼ è¡¨ä¸”ä¸é‡å¤
    scored.sort(key=lambda x: x[2], reverse=True)
    for i, sec, score in scored:
        if sec in assigned:
            continue
        if i in used_idx:
            continue
        assigned[sec] = dfs[i].copy(deep=True)
        used_idx.add(i)

    debug = {
        "tail_pages": tail_pages,
        "raw_tables_count": len(raw_tables),
        "dfs_count": len(dfs),
        "scored": scored[:20],
        "assigned": {k: list(v.shape) for k, v in assigned.items()},
    }
    return assigned, debug


def base_plan_from_pdf(pdf_bytes: bytes) -> Dict[str, Any]:
    pages = _read_pdf_pages_text(pdf_bytes)
    full = _join_pages(pages)
    spans = _build_section_spans(full)

    base = {}
    for sec_id, _ in _SECTION_PATTERNS:
        base[sec_id] = _extract_section_text(full, spans, sec_id)

    # å†è¡¥ï¼š7-11 å¯èƒ½æ­£æ–‡åªæœ‰æ ‡é¢˜ï¼Œè¿™é‡Œç»™æç¤º
    for sec_id in ["7", "8", "9", "10", "11"]:
        if not base.get(sec_id, "").strip():
            base[sec_id] = f"{sec_id}ï¼šæ­£æ–‡å¯èƒ½ä»…æœ‰æ ‡é¢˜ï¼›è¯·å°è¯•ä» PDF æœ«å°¾é™„è¡¨è‡ªåŠ¨æŠ½å–ã€‚"

    auto_tables, debug_meta = extract_appendix_tables_best_effort(pdf_bytes, pages)

    return dict(
        pages=pages,
        full_text=full,
        sections=base,              # 1-11 text
        tables=auto_tables,         # 7-10 tables
        debug=debug_meta,
    )


# -----------------------------
# UI
# -----------------------------
@dataclass
class Project:
    project_id: str
    name: str
    updated_at: str


def _init_state():
    if "projects" not in st.session_state:
        # é»˜è®¤é¡¹ç›®
        pid = _short_id(_now_str())
        st.session_state.projects = [
            Project(project_id=pid, name=f"é»˜è®¤é¡¹ç›®-{time.strftime('%Y%m%d-%H%M')}", updated_at=_now_str())
        ]
        st.session_state.active_project_id = pid

    if "project_data" not in st.session_state:
        # project_id -> payload
        st.session_state.project_data = {}

    if "logo_bytes" not in st.session_state:
        st.session_state.logo_bytes = None


def ui_sidebar_brand():
    with st.sidebar:
        col1, col2 = st.columns([1, 4])
        with col1:
            if st.session_state.logo_bytes:
                st.image(st.session_state.logo_bytes, width=44)
            else:
                # é»˜è®¤ä¸€ä¸ªç®€å• SVG åœ†å½¢ TA
                svg = """
                <div style="width:44px;height:44px;border-radius:50%;
                            background:#2f6fed;display:flex;align-items:center;justify-content:center;
                            color:white;font-weight:800;font-family:Arial;">
                  TA
                </div>
                """
                components.html(svg, height=48)

        with col2:
            st.markdown("**Teaching Agent Suite**")
            st.caption("v0.6 (base 1â€“11 + appendix tables + logo fixed)")

        # Logo ä¸Šä¼ ï¼ˆå¯é€‰ï¼‰
        up = st.file_uploader("ä¸Šä¼  Logoï¼ˆå¯é€‰ï¼Œpng/jpgï¼‰", type=["png", "jpg", "jpeg"], key="logo_uploader")
        if up is not None:
            st.session_state.logo_bytes = up.getvalue()


def ui_project_sidebar() -> Project:
    ui_sidebar_brand()

    with st.sidebar:
        st.divider()
        st.markdown("### é¡¹ç›®")
        options = {p.project_id: p for p in st.session_state.projects}
        labels = {p.project_id: f"{p.name} ({p.project_id})" for p in st.session_state.projects}

        pid = st.selectbox(
            "é€‰æ‹©é¡¹ç›®",
            options=list(labels.keys()),
            format_func=lambda x: labels[x],
            index=list(labels.keys()).index(st.session_state.active_project_id),
            key="project_select",
        )
        st.session_state.active_project_id = pid
        return options[pid]


def _render_top_header(project: Project):
    # è¿™é‡Œä¸€å®šè¦ unsafe_allow_html=Trueï¼Œå¦åˆ™ä¼šåƒä½ æˆªå›¾é‚£æ ·æŠŠ html å½“æ–‡å­—æ˜¾ç¤º
    html = f"""
    <div style="border:1px solid #e7eefc; background:#f6f9ff; padding:18px 18px; border-radius:14px;">
      <div style="font-weight:900; font-size:28px;">æ•™å­¦æ–‡ä»¶å·¥ä½œå°</div>
      <div style="color:#666; margin-top:4px; font-size:14px;">
        é¡¹ç›®ï¼š <b>{project.name}</b>ï¼ˆ{project.project_id}ï¼‰ Â· æœ€åæ›´æ–°ï¼š {project.updated_at}
      </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)


def ui_base_training_plan(project: Project):
    st.subheader("åŸ¹å…»æ–¹æ¡ˆåŸºåº§ï¼ˆå…¨é‡å†…å®¹åº“ï¼‰")
    st.caption("ä¸Šä¼ åŸ¹å…»æ–¹æ¡ˆ PDF â†’ æŠ½å–å¡«å…… 1â€“11 â†’ å¹¶å°è¯•ä»æœ«å°¾é™„è¡¨è‡ªåŠ¨æŠ½è¡¨å¡«å…… 7â€“10ã€‚")

    left, right = st.columns([1, 1.4], gap="large")

    with left:
        pdf = st.file_uploader("ä¸Šä¼ åŸ¹å…»æ–¹æ¡ˆ PDFï¼ˆå¯é€‰ï¼‰", type=["pdf"], key=f"pdf_{project.project_id}")

        if st.button("æŠ½å–å¹¶å†™å…¥åŸºåº§", use_container_width=True, type="primary", key=f"extract_btn_{project.project_id}"):
            if not pdf:
                st.warning("è¯·å…ˆä¸Šä¼  PDFã€‚")
            else:
                pdf_bytes = pdf.getvalue()
                payload = base_plan_from_pdf(pdf_bytes)
                st.session_state.project_data[project.project_id] = payload
                # æ›´æ–°æ—¶é—´
                for i, p in enumerate(st.session_state.projects):
                    if p.project_id == project.project_id:
                        st.session_state.projects[i] = Project(
                            project_id=p.project_id,
                            name=p.name,
                            updated_at=_now_str()
                        )
                        break
                st.success("å·²æŠ½å–å¹¶å†™å…¥åŸºåº§ã€‚å³ä¾§å·²è”åŠ¨å¡«å……ã€‚")

        # ä¸‹è½½ JSON
        payload = st.session_state.project_data.get(project.project_id)
        if payload:
            json_payload = payload_to_jsonable(payload)

            st.download_button(
                "ä¸‹è½½åŸºåº§ JSON",
                data=json.dumps(json_payload, ensure_ascii=False, indent=2).encode("utf-8"),
                file_name=f"base_{project.project_id}.json",
                mime="application/json",
                use_container_width=True,
                key=f"dl_{project.project_id}",
            )


        st.divider()
        if payload:
            missing = [k for k in [str(i) for i in range(1, 12)] if not payload["sections"].get(k, "").strip()]
            if missing:
                st.warning(f"æ£€æŸ¥ï¼šç¼ºå°‘æ ç›® {missing}")
            else:
                st.success("1â€“11 æ ç›®å‡å·²å­˜åœ¨ï¼ˆä»å»ºè®®äººå·¥å¿«é€Ÿæ‰«è¯»ï¼‰ã€‚")

        with st.expander("è°ƒè¯•ï¼šåˆ†é¡µåŸæ–‡ (raw_pages_text)"):
            if payload:
                st.write(payload["pages"])
            else:
                st.info("å…ˆæŠ½å–åå¯è§ã€‚")

        with st.expander("è°ƒè¯•ï¼šé™„è¡¨æŠ½å–ä¿¡æ¯ (appendix_debug)"):
            if payload:
                st.json(payload["debug"])
            else:
                st.info("å…ˆæŠ½å–åå¯è§ã€‚")

    with right:
        st.markdown("#### åŸ¹å…»æ–¹æ¡ˆå†…å®¹ï¼ˆæŒ‰æ ç›®å±•ç¤ºï¼Œå¯ç¼–è¾‘ï¼‰")

        payload = st.session_state.project_data.get(project.project_id)
        if not payload:
            st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF å¹¶ç‚¹å‡»â€œæŠ½å–å¹¶å†™å…¥åŸºåº§â€ã€‚")
            return

        sections = payload["sections"]
        tables = payload.get("tables", {})

        # é¡¶éƒ¨ç›®å½•
        toc = [
            ("1", "åŸ¹å…»ç›®æ ‡"),
            ("2", "æ¯•ä¸šè¦æ±‚"),
            ("3", "ä¸“ä¸šå®šä½ä¸ç‰¹è‰²"),
            ("4", "ä¸»å¹²å­¦ç§‘/æ ¸å¿ƒè¯¾ç¨‹/å®è·µç¯èŠ‚"),
            ("5", "æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½"),
            ("6", "æ¯•ä¸šæ¡ä»¶"),
            ("7", "ä¸“ä¸šæ•™å­¦è®¡åˆ’è¡¨ï¼ˆé™„è¡¨1ï¼‰"),
            ("8", "å­¦åˆ†ç»Ÿè®¡è¡¨ï¼ˆé™„è¡¨2ï¼‰"),
            ("9", "æ•™å­¦è¿›ç¨‹è¡¨ï¼ˆé™„è¡¨3ï¼‰"),
            ("10", "æ”¯æ’‘å…³ç³»è¡¨ï¼ˆé™„è¡¨4ï¼‰"),
            ("11", "é€»è¾‘æ€ç»´å¯¼å›¾ï¼ˆé™„è¡¨5ï¼‰"),
        ]
        # ç”¨ radio æ¨¡æ‹Ÿâ€œæ ‡ç­¾â€
        sec_pick = st.radio(
            "æ ç›®",
            options=[x[0] for x in toc],
            format_func=lambda x: dict(toc)[x],
            horizontal=True,
            key=f"sec_radio_{project.project_id}",
        )

        # å±•ç¤ºå½“å‰æ ç›®
        title_map = dict(toc)
        st.markdown(f"##### {sec_pick}ã€{title_map[sec_pick]}")

        # 6ï¼šåªå±•ç¤º 6 æœ¬èº«ï¼Œåˆ«æŠŠ 7-11 æ··è¿›å»ï¼ˆé€šå¸¸æ··è¿›å»æ˜¯å› ä¸º span åˆ‡åˆ†å¤±è´¥ï¼‰
        # è¿™é‡Œå·²ç»é  spans åˆ‡åˆ†ï¼›å†åŠ ä¸€é“â€œæˆªæ–­â€å…œåº•ï¼šé‡åˆ°ä¸‹ä¸€èŠ‚æ ‡é¢˜å°±æˆªæ–­
        def _truncate_at_next_heading(txt: str, next_sec_id: str) -> str:
            if not txt:
                return ""
            next_title = dict(toc).get(next_sec_id, "")
            if not next_title:
                return txt
            m = re.search(rf"\n\s*{next_sec_id}[ã€\.\s]*{re.escape(next_title)}", "\n" + txt)
            if m:
                return _compact_lines(txt[: m.start()])
            return txt

        # Text area
        txt = sections.get(sec_pick, "")

        if sec_pick == "6":
            txt = _truncate_at_next_heading(txt, "7")

        st.text_area(
            f"{sec_pick} æ–‡æœ¬æŠ½å–ç»“æœ",
            value=txt,
            height=220,
            key=f"sec_text_{project.project_id}_{sec_pick}",
        )

        # 7-10ï¼šè¡¨æ ¼åŒºï¼ˆè‡ªåŠ¨æŠ½å–ï¼‰
        if sec_pick in ["7", "8", "9", "10"]:
            st.markdown("###### è¡¨æ ¼åŒºï¼ˆå¯ç¼–è¾‘ï¼Œè¡Œå¯å¢åˆ ï¼‰")

            df0 = tables.get(sec_pick)
            if df0 is None or df0 is False or (isinstance(df0, pd.DataFrame) and df0.empty):
                st.info("æœªè‡ªåŠ¨æŠ½å–åˆ°è¯¥é™„è¡¨ï¼ˆå¯èƒ½ PDF è¡¨æ ¼æ˜¯å›¾ç‰‡æˆ–çº¿æ¡ä¸è§„åˆ™ï¼‰ã€‚ä½ å¯ä»¥æ‰‹å·¥è¡¥å…¨ã€‚")
                df0 = pd.DataFrame()

            # æ³¨æ„ï¼šä¸è¦æŠŠ widget key çš„ session_state è‡ªå·±å†èµ‹å€¼ï¼Œå¦åˆ™ä¼š ValueAssignmentNotAllowed
            editor_key = f"tbl_editor_{project.project_id}_{sec_pick}"
            edited = st.data_editor(
                df0,
                num_rows="dynamic",
                use_container_width=True,
                key=editor_key,
            )
            # æŠŠç»“æœå­˜åˆ°å¦ä¸€ä¸ª keyï¼ˆä¸è¦†ç›– widget keyï¼‰
            st.session_state[f"{editor_key}__value"] = edited

        if sec_pick == "11":
            st.info("é€»è¾‘æ€ç»´å¯¼å›¾ï¼ˆé™„è¡¨5ï¼‰é€šå¸¸æ˜¯å›¾ç‰‡/æµç¨‹å›¾ï¼Œä¸ä¸€å®šèƒ½ä»è¡¨æ ¼æŠ½å–ã€‚å¯åç»­åŠ ï¼šæœ«é¡µå›¾ç‰‡æŠ½å–ã€‚")


def main():
    st.set_page_config(page_title="Teaching Agent Suite", page_icon="ğŸ§ ", layout="wide")
    _init_state()

    prj = ui_project_sidebar()

    _render_top_header(prj)

    # tabs
    tab1, tab2, tab3 = st.tabs(["åŸ¹å…»æ–¹æ¡ˆåŸºåº§", "æ¨¡æ¿åŒ–æ•™å­¦æ–‡ä»¶", "é¡¹ç›®æ¦‚è§ˆ"])
    with tab1:
        ui_base_training_plan(prj)
    with tab2:
        st.info("è¿™é‡Œç•™ç»™ä½ çš„â€œæ¨¡æ¿åŒ–æ•™å­¦æ–‡ä»¶â€æ¨¡å—ï¼ˆä½ åŸæ¥çš„ç”Ÿæˆ/æ ¡å¯¹/å¯¼å‡ºæµç¨‹å¯ä»¥æ”¾å›è¿™é‡Œï¼‰ã€‚")
    with tab3:
        st.write("é¡¹ç›®IDï¼š", prj.project_id)
        st.write("æœ€åæ›´æ–°ï¼š", prj.updated_at)
        payload = st.session_state.project_data.get(prj.project_id)
        if payload:
            st.write("å·²å†™å…¥åŸºåº§ï¼šâœ…")
            st.write("å·²æŠ½å–é™„è¡¨ï¼š", payload.get("debug", {}).get("assigned", {}))
        else:
            st.write("å·²å†™å…¥åŸºåº§ï¼šâŒ")


if __name__ == "__main__":
    main()
