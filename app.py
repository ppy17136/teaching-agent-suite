import io, json, time, random, re
import pandas as pd
import streamlit as st
import pdfplumber
import google.generativeai as genai
from typing import Dict, List, Any
from openai import OpenAI
from google.api_core import exceptions  # âœ… ä¿®æ­£ 1ï¼šç¡®ä¿å¯¼å…¥å¼‚å¸¸å¤„ç†æ¨¡å—

# ============================================================
# 1. æ¨¡å‹ä¾›åº”å•†é…ç½®
# ============================================================
PROVIDERS = {
    "Gemini (Google)": {"base_url": None, "model": "gemini-1.5-flash", "is_gemini": True},
    "DeepSeek": {"base_url": "https://api.deepseek.com", "model": "deepseek-chat", "is_gemini": False},
    "Kimi (Moonshot)": {"base_url": "https://api.moonshot.cn/v1", "model": "moonshot-v1-8k", "is_gemini": False},
    "æ™ºè°± AI (GLM)": {"base_url": "https://open.bigmodel.cn/api/paas/v4/", "model": "glm-4", "is_gemini": False},
    "é€šä¹‰åƒé—® (Qwen)": {"base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1", "model": "qwen-plus", "is_gemini": False},
    "è±†åŒ… (å­—èŠ‚)": {"base_url": "https://ark.cn-beijing.volces.com/api/v3", "model": "doubao-pro-32k", "is_gemini": False}
}

# ============================================================
# 2. æ ¸å¿ƒæç¤ºè¯ï¼šå¼ºè°ƒç»“æ„åŒ–ä¸åˆ†æ¡
# ============================================================
MEGA_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é«˜æ ¡æ•™åŠ¡ä¸“å®¶ã€‚è¯·ç²¾ç¡®æå–ä»¥ä¸‹å†…å®¹å¹¶ä¸¥æ ¼è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ã€‚
æå–è¦æ±‚ï¼š
1. **åˆ†æ¡åˆ—å‡º**ï¼š1-6é¡¹æ­£æ–‡å¿…é¡»ä¿ç•™åŸå§‹ç¼–å·ï¼Œä½¿ç”¨ '\\n' æ¢è¡Œã€‚
2. **ç¦æ­¢åµŒå¥—**ï¼šè¡¨æ ¼å†…ä¸¥ç¦å‡ºç°åµŒå¥— JSONï¼Œå¿…é¡»å…¨éƒ¨ä¸ºæ‰å¹³å­—ç¬¦ä¸²ã€‚
3. **é™„è¡¨è¦æ±‚**ï¼šé™„è¡¨1æå–å…¨é‡è¯¾ç¨‹ï¼›é™„è¡¨2åŒºåˆ†ç„Šæ¥/æ— æŸæ–¹å‘ï¼›é™„è¡¨4æå–æ”¯æ’‘å¼ºåº¦ã€‚
"""

# ============================================================
# 3. ç»Ÿä¸€é©±åŠ¨å¼•æ“ (å¸¦é‡è¯•ã€èŠ‚æµä¸ Token ä¿æŠ¤)
# ============================================================
def call_llm_engine(provider_name, api_key, prompt, max_retries=3):
    """ç»Ÿä¸€å¤„ç†æ‰€æœ‰æ¨¡å‹çš„è°ƒç”¨é€»è¾‘ï¼Œä¿®å¤ NameError å’Œ æˆªæ–­é—®é¢˜"""
    if provider_name not in PROVIDERS:
        st.error(f"æ— æ•ˆçš„ä¾›åº”å•†: {provider_name}")
        return None
        
    config = PROVIDERS[provider_name]
    
    for i in range(max_retries):
        try:
            # åŸºç¡€æµæ§ (é˜²æ­¢è¿‡å¿«è§¦å‘é™åˆ¶)
            time.sleep(5 if config["is_gemini"] else 2)
            
            if config["is_gemini"]:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(config["model"])
                # Gemini æ”¯æŒ 8192 token è¾“å‡º
                response = model.generate_content(
                    prompt, 
                    generation_config={"response_mime_type": "application/json", "max_output_tokens": 8192}
                )
                return json.loads(response.text)
            else:
                client = OpenAI(api_key=api_key, base_url=config["base_url"])
                # âœ… ä¿®æ­£ 2ï¼šä¸º OpenAI å…¼å®¹æ¨¡å‹å¢åŠ  max_tokens è®¾ç½®ï¼Œé˜²æ­¢æˆªæ–­
                response = client.chat.completions.create(
                    model=config["model"],
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æ•™åŠ¡ä¸“å®¶ï¼Œåªè¾“å‡ºå®Œæ•´çš„ JSONï¼Œä¸¥ç¦æˆªæ–­ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    response_format={"type": "json_object"},
                    max_tokens=4096 # å›½äº§æ¨¡å‹é€šå¸¸æœ€å¤§æ”¯æŒ 4k è¾“å‡º
                )
                return json.loads(response.choices[0].message.content)
                
        except exceptions.ResourceExhausted:
            wait = (i + 1) * 20
            st.warning(f"è§¦å‘é…é¢é™åˆ¶ï¼Œæ­£åœ¨ç¬¬ {i+1} æ¬¡é‡è¯•ï¼Œéœ€ç­‰å¾… {wait} ç§’...")
            time.sleep(wait)
        except json.JSONDecodeError as je:
            # æ•è·æˆªæ–­å¯¼è‡´çš„ JSON é”™è¯¯
            st.error(f"JSON è§£æå¤±è´¥ (å¯èƒ½æ˜¯å†…å®¹å¤ªé•¿è¢«æ¨¡å‹å¼ºè¡Œæˆªæ–­): {str(je)}")
            return None
        except Exception as e:
            if i == max_retries - 1: st.error(f"è°ƒç”¨å¤±è´¥: {str(e)}")
            continue
    return None

# ============================================================
# 4. æ™ºèƒ½è§£æå¼•æ“ (åˆ†æ®µç­–ç•¥å†³ç­–)
# ============================================================
def intelligent_processor(api_key, pdf_bytes, provider_name):
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        all_text = "\n".join([p.extract_text() or "" for p in pdf.pages])
    
    char_count = len(all_text)
    is_gemini = PROVIDERS[provider_name]["is_gemini"]
    
    # ç­–ç•¥åˆ¤æ–­ï¼šé Gemini ä¸”å­—ç¬¦ > 12,000ï¼Œåˆ™åˆ†æ®µè¯·æ±‚ä»¥é˜²æ­¢æˆªæ–­
    needs_split = (not is_gemini) and (char_count > 12000)
    final_res = {"sections": {}, "table1": [], "table2": [], "table4": []}

    if not needs_split:
        st.info("ğŸ“Š é‡‡ç”¨ã€å…¨é‡å•æ¬¡ã€‘æŠ½å–æ¨¡å¼...")
        full_p = f"{MEGA_PROMPT}\n\nå†…å®¹åŸæ–‡ï¼š\n{all_text}"
        res = call_llm_engine(provider_name, api_key, full_p)
        if res: final_res = res
    else:
        st.warning(f"ğŸ“Š æ–‡æ¡£è¾ƒé•¿ ({char_count} å­—ç¬¦)ï¼Œä¸ºé˜²æ­¢è¾“å‡ºæˆªæ–­ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸ºã€åˆ†æ®µå®‰å…¨ã€‘æŠ½å–æ¨¡å¼...")
        
        # ä»»åŠ¡ 1: æ­£æ–‡ + å­¦åˆ†è¡¨ (é™åˆ¶è¾“å…¥é•¿åº¦)
        st.write("æ­¥éª¤ 1: æ­£åœ¨æå–æ­£æ–‡ä¸å­¦åˆ†ç»Ÿè®¡...")
        p1 = f"{MEGA_PROMPT}\nä»»åŠ¡ï¼šä»…æå– 1-6 é¡¹æ­£æ–‡å’Œé™„è¡¨ 2ã€‚å†…å®¹ï¼š{all_text[:15000]}"
        r1 = call_llm_engine(provider_name, api_key, p1)
        if r1:
            final_res["sections"] = r1.get("sections", {})
            final_res["table2"] = r1.get("table2", [])

        # ä»»åŠ¡ 2: æ•™å­¦è®¡åˆ’è¡¨ (é™„è¡¨ 1)
        st.write("æ­¥éª¤ 2: æ­£åœ¨æå–æ•™å­¦è®¡åˆ’è¡¨...")
        p2 = f"è¯·æå–é™„è¡¨ 1 çš„æ‰€æœ‰è¯¾ç¨‹ï¼Œæ ¼å¼ {{'table1':[...]}}ã€‚å†…å®¹ï¼š\n{all_text}"
        r2 = call_llm_engine(provider_name, api_key, p2)
        if r2: final_res["table1"] = r2.get("table1", [])

        # ä»»åŠ¡ 3: æ”¯æ’‘çŸ©é˜µ (é™„è¡¨ 4)
        st.write("æ­¥éª¤ 3: æ­£åœ¨æå–æ”¯æ’‘çŸ©é˜µ...")
        p3 = f"è¯·æå–é™„è¡¨ 4 çš„æ”¯æ’‘çŸ©é˜µï¼Œæ ¼å¼ {{'table4':[...]}}ã€‚å†…å®¹ï¼š\n{all_text}"
        r3 = call_llm_engine(provider_name, api_key, p3)
        if r3: final_res["table4"] = r3.get("table4", [])

    return final_res

# ============================================================
# 5. UI é€»è¾‘ (ä¿®å¤ä¸‹æ‹‰åˆ—è¡¨çŠ¶æ€é—®é¢˜)
# ============================================================
def main():
    st.set_page_config(layout="wide", page_title="æ™ºèƒ½æ•™å­¦å·¥ä½œå° v4.1")
    
    if "mega_data" not in st.session_state:
        st.session_state.mega_data = None

    with st.sidebar:
        st.title("ğŸ¤– æ¨¡å‹é…ç½®")
        selected_provider = st.selectbox("é€‰æ‹©æ¨¡å‹ä¾›åº”å•†", list(PROVIDERS.keys()), key="prov_v4")
        api_key = st.text_input(f"è¾“å…¥ {selected_provider} çš„ API Key", type="password", key="key_v4")
        st.divider()
        if st.button("æ¸…ç†ç¼“å­˜æ•°æ®"):
            st.session_state.mega_data = None
            st.rerun()

    st.header("ğŸ§  åŸ¹å…»æ–¹æ¡ˆå…¨é‡æå– (ç­–ç•¥åˆ†æµç‰ˆ)")
    file = st.file_uploader("ä¸Šä¼  PDF åŸ¹å…»æ–¹æ¡ˆ", type="pdf")

    if file and api_key and st.button("ğŸš€ æ‰§è¡Œå…¨é‡æŠ½å–", type="primary"):
        with st.spinner("AI æ­£åœ¨æ·±åº¦è§£ææ–‡æ¡£ï¼Œè¯·ç¨å€™..."):
            result = intelligent_processor(api_key, file.getvalue(), selected_provider)
            if result:
                st.session_state.mega_data = result
                st.success("æŠ½å–æˆåŠŸï¼")

    if st.session_state.mega_data:
        d = st.session_state.mega_data
        tab1, tab2, tab3, tab4 = st.tabs(["1-6 æ­£æ–‡", "é™„è¡¨1: è®¡åˆ’è¡¨", "é™„è¡¨2: å­¦åˆ†ç»Ÿè®¡", "é™„è¡¨4: æ”¯æ’‘çŸ©é˜µ"])
        
        with tab1:
            sections = d.get("sections", {})
            if sections:
                sec_pick = st.selectbox("é€‰æ‹©æ ç›®", list(sections.keys()), key="sec_pick_v4")
                # âœ… ä¿®æ­£ 3ï¼šä½¿ç”¨åŠ¨æ€ key ç¡®ä¿åˆ‡æ¢ä¸‹æ‹‰åˆ—è¡¨åå†…å®¹å³æ—¶åˆ·æ–°
                st.text_area("å†…å®¹æ–‡æœ¬", value=sections.get(sec_pick, ""), height=450, key=f"ta_v4_{sec_pick}")
            else:
                st.warning("æ­£æ–‡éƒ¨åˆ†æå–å¤±è´¥ã€‚")

        with tab2:
            st.dataframe(pd.DataFrame(d.get("table1", [])), use_container_width=True)
        with tab3:
            st.dataframe(pd.DataFrame(d.get("table2", [])), use_container_width=True)
        with tab4:
            st.dataframe(pd.DataFrame(d.get("table4", [])), use_container_width=True)

if __name__ == "__main__":
    main()