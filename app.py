import io, json, time, random, re
import pandas as pd
import streamlit as st
import pdfplumber
import google.generativeai as genai
from google.api_core import exceptions
from typing import Dict, List, Any

# ============================================================
# 1. å¸¸é‡ä¸å­—æ®µå®šä¹‰
# ============================================================
TABLE_1_FULL_COLS = [
    "è¯¾ç¨‹ä½“ç³»", "è¯¾ç¨‹ç¼–ç ", "è¯¾ç¨‹åç§°", "å¼€è¯¾æ¨¡å¼", "è€ƒæ ¸æ–¹å¼", 
    "å­¦åˆ†", "æ€»å­¦æ—¶", "å†…_è®²è¯¾", "å†…_å®éªŒ", "å†…_ä¸Šæœº", "å†…_å®è·µ", 
    "å¤–_å­¦åˆ†", "å¤–_å­¦æ—¶", "ä¸Šè¯¾å­¦æœŸ", "ä¸“ä¸šæ–¹å‘", "å­¦ä½è¯¾", "å¤‡æ³¨"
]

# ============================================================
# 2. AI å¤„ç†å¼•æ“ (å¢å¼ºé²æ£’æ€§)
# ============================================================
def ai_safe_call(model, prompt: str, max_retries=3):
    """å¸¦å†·å´å’Œé‡è¯•çš„ AI è°ƒç”¨ï¼Œç¡®ä¿ RPM é™åˆ¶"""
    for i in range(max_retries):
        try:
            time.sleep(5)  # å¼ºåˆ¶å†·å´ï¼Œé€‚é…å…è´¹ç‰ˆ RPM é™åˆ¶
            response = model.generate_content(
                prompt, 
                generation_config={"response_mime_type": "application/json"}
            )
            clean_text = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(clean_text)
        except exceptions.ResourceExhausted:
            st.warning(f"è§¦å‘é…é¢é™åˆ¶ï¼Œæ­£åœ¨ç¬¬ {i+1} æ¬¡é‡è¯•...")
            time.sleep(10 * (i + 1))
        except Exception as e:
            continue
    return None

def extract_sections_precise(model, full_text):
    """å¼ºåŒ– 1-6 é¡¹å®šä½ï¼Œç¡®ä¿ 4/5/6 ä¸è¢«é—æ¼ [cite: 10-91]"""
    prompt = f"""
    æå–åŸ¹å…»æ–¹æ¡ˆæ­£æ–‡ 1-6 é¡¹ã€‚ç¡®ä¿æå–å†…å®¹å®Œæ•´ï¼š
    1: åŸ¹å…»ç›®æ ‡ (ä¸€ã€åŸ¹å…»ç›®æ ‡ ä¹‹å) [cite: 10]
    2: æ¯•ä¸šè¦æ±‚ (äºŒã€æ¯•ä¸šè¦æ±‚ ä¹‹å) [cite: 21]
    3: ä¸“ä¸šå®šä½ä¸ç‰¹è‰² (ä¸‰ã€ä¸“ä¸šå®šä½ä¸ç‰¹è‰² ä¹‹å) [cite: 80]
    4: ä¸»å¹²å­¦ç§‘/æ ¸å¿ƒè¯¾ç¨‹/å®è·µç¯èŠ‚ (å››ã€ä¸»å¹²å­¦ç§‘ ä¹‹å) [cite: 84]
    5: æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½ (äº”ã€æ ‡å‡†å­¦åˆ¶ ä¹‹å) [cite: 88]
    6: æ¯•ä¸šæ¡ä»¶ (å…­ã€æ¯•ä¸šæ¡ä»¶ ä¹‹å) [cite: 91]
    
    è¿”å› JSON: {{"1åŸ¹å…»ç›®æ ‡": "...", "2æ¯•ä¸šè¦æ±‚": "...", "3ä¸“ä¸šå®šä½ä¸ç‰¹è‰²": "...", "4ä¸»å¹²å­¦ç§‘/æ ¸å¿ƒè¯¾ç¨‹/å®è·µç¯èŠ‚": "...", "5æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½": "...", "6æ¯•ä¸šæ¡ä»¶": "..."}}
    æ–‡æœ¬ï¼š{full_text[:18000]}
    """
    return ai_safe_call(model, prompt)

def process_table_2_flat(model, raw_text):
    """æ·±åº¦æ‰å¹³åŒ–å¤„ç†å­¦åˆ†è¡¨ï¼Œè¯†åˆ«ä¸åŒä¸“ä¸šæ–¹å‘ """
    prompt = f"""
    å°†å­¦åˆ†ç»Ÿè®¡æ–‡æœ¬è½¬æ¢ä¸ºæ‰å¹³çš„ JSON åˆ—è¡¨ã€‚
    å¿…é¡»è¯†åˆ«â€œç„Šæ¥â€å’Œâ€œæ— æŸæ£€æµ‹â€ä¸¤ä¸ªä¸“ä¸šæ–¹å‘çš„å·®å¼‚ã€‚
    å­—æ®µï¼š["ä¸“ä¸šæ–¹å‘", "è¯¾ç¨‹ä½“ç³»", "å­¦åˆ†ç»Ÿè®¡", "å­¦åˆ†æ¯”ä¾‹", "å¤‡æ³¨"]
    æ–‡æœ¬ï¼š{raw_text}
    """
    return ai_safe_call(model, prompt)

# ============================================================
# 3. æ–‡æ¡£è§£æå¼•æ“ (ä¿®æ­£ NameError)
# ============================================================
def parse_document_v12_1(api_key, pdf_bytes):
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash')
    results = {"sections": {}, "tables": {"1": [], "2": [], "4": []}}
    
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        # æ­£ç¡®è·å–å…¨æ–‡æ–‡æœ¬
        all_text = [p.extract_text() or "" for p in pdf.pages]
        
        # 1. æå–æ­£æ–‡ (ä¿®æ­£ all_pages ä¸º all_text)
        st.write("æ­£åœ¨æ™ºèƒ½åˆ†æåŸ¹å…»æ–¹æ¡ˆæ­£æ–‡ (1-6é¡¹)...")
        results["sections"] = extract_sections_precise(model, "\n".join(all_text[:6]))

        # 2. å…¨é‡æ‰«æé™„è¡¨é¡µ
        raw_t1, raw_t4, text_t2 = [], [], ""
        for i, page in enumerate(pdf.pages):
            txt = all_text[i]
            # å®šä½é™„è¡¨1
            if "é™„è¡¨1" in txt or "æ•™å­¦è®¡åˆ’è¡¨" in txt:
                tbl = page.extract_table()
                if tbl: raw_t1.extend(tbl[1:])
            # å®šä½é™„è¡¨2 [cite: 113, 119]
            elif "é™„è¡¨2" in txt or "å­¦åˆ†ç»Ÿè®¡" in txt:
                text_t2 += f"\n{txt}"
            # å®šä½é™„è¡¨4 [cite: 124, 128]
            elif "é™„è¡¨4" in txt or "æ”¯æ’‘å…³ç³»" in txt:
                tbl = page.extract_table()
                if tbl: raw_t4.extend(tbl[1:])

        # 3. åˆ†å—å¤„ç†é™„è¡¨
        if raw_t1:
            st.write("æ­£åœ¨æ ¡å¯¹æ•™å­¦è®¡åˆ’è¡¨...")
            # åˆ†å—é€»è¾‘åŒå‰ï¼Œchunk_size è®¾ä¸º 80 ä»¥å‡å°‘è¯·æ±‚æ•°
            for i in range(0, len(raw_t1), 80):
                chunk = raw_t1[i : i+80]
                prompt = f"è½¬æ¢æ•™å­¦è®¡åˆ’è¡¨ç‰‡æ®µä¸º JSON åˆ—è¡¨ã€‚å­—æ®µï¼š{TABLE_1_FULL_COLS}ã€‚æ•°æ®ï¼š{json.dumps(chunk, ensure_ascii=False)}"
                res = ai_safe_call(model, prompt)
                if isinstance(res, list): results["tables"]["1"].extend(res)
            
        if text_t2:
            st.write("æ­£åœ¨é‡æ„é™„è¡¨2: å­¦åˆ†ç»Ÿè®¡è¡¨...")
            results["tables"]["2"] = process_table_2_flat(model, text_t2)
            
        if raw_t4:
            st.write("æ­£åœ¨å¤„ç†æ”¯æ’‘çŸ©é˜µè¡¨...")
            for i in range(0, len(raw_t4), 100):
                chunk = raw_t4[i : i+100]
                prompt = f"æå–æ”¯æ’‘å…³ç³» JSON åˆ—è¡¨ [è¯¾ç¨‹åç§°, æŒ‡æ ‡ç‚¹, å¼ºåº¦]ã€‚æ•°æ®ï¼š{json.dumps(chunk, ensure_ascii=False)}"
                res = ai_safe_call(model, prompt)
                if isinstance(res, list): results["tables"]["4"].extend(res)

    return results

# ============================================================
# 4. Streamlit UI é€»è¾‘
# ============================================================
def main():
    st.set_page_config(layout="wide", page_title="æ•™å­¦æ–‡ä»¶å·¥ä½œå° v1.2.1")
    
    if "data_v121" not in st.session_state:
        st.session_state.data_v121 = None

    with st.sidebar:
        st.title("âš™ï¸ è®¾ç½®")
        api_key = st.text_input("Gemini API Key", type="password", key="v121_api_key")
        st.caption("ç‰ˆæœ¬: v1.2.1 (ä¿®å¤ NameError)")
        
    st.markdown("## ğŸ§  åŸ¹å…»æ–¹æ¡ˆå…¨é‡æ™ºèƒ½æå– (ä¿®å¤ç‰ˆ)")
    
    file = st.file_uploader("ä¸Šä¼ åŸ¹å…»æ–¹æ¡ˆ PDF", type="pdf", key="v121_uploader")

    if file and api_key:
        if st.button("ğŸš€ æ‰§è¡Œä¸€é”®å…¨é‡æŠ½å–", type="primary", key="v121_run"):
            with st.spinner("AI æ­£åœ¨æ·±åº¦è§£ææ–‡æ¡£..."):
                data = parse_document_v12_1(api_key, file.getvalue())
                if data:
                    st.session_state.data_v121 = data
                    st.success("æŠ½å–ä»»åŠ¡å·²å®Œæˆï¼")

    if st.session_state.data_v121:
        d = st.session_state.data_v121
        tab1, tab2, tab3, tab4 = st.tabs(["1-6 æ­£æ–‡", "é™„è¡¨1: è®¡åˆ’è¡¨", "é™„è¡¨2: å­¦åˆ†ç»Ÿè®¡", "é™„è¡¨4: æ”¯æ’‘çŸ©é˜µ"])
        
        with tab1:
            # è§£å†³åˆ‡æ¢é—®é¢˜çš„å…³é”®ï¼šä½¿ç”¨å¸¦æœ‰ sec_pick çš„ key
            sec_pick = st.selectbox("æŸ¥çœ‹æ ç›®å†…å®¹", ["1åŸ¹å…»ç›®æ ‡", "2æ¯•ä¸šè¦æ±‚", "3ä¸“ä¸šå®šä½ä¸ç‰¹è‰²", "4ä¸»å¹²å­¦ç§‘/æ ¸å¿ƒè¯¾ç¨‹/å®è·µç¯èŠ‚", "5æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½", "6æ¯•ä¸šæ¡ä»¶"], key="v121_sec_pick")
            content = d["sections"].get(sec_pick, "æœªæå–åˆ°ç›¸å…³æ­£æ–‡ã€‚")
            st.text_area("æå–ç»“æœ", value=content, height=450, key=f"v121_ta_{sec_pick}")

        with tab2:
            df1 = pd.DataFrame(d["tables"]["1"])
            if not df1.empty:
                st.data_editor(df1.reindex(columns=TABLE_1_FULL_COLS), use_container_width=True, key="v121_ed1")

        with tab3:
            st.markdown("### å­¦åˆ†ç»Ÿè®¡æ˜ç»† ")
            df2 = pd.DataFrame(d["tables"]["2"])
            if not df2.empty:
                st.dataframe(df2, use_container_width=True, key="v121_df2")
            else:
                st.info("æš‚æ— å­¦åˆ†ç»Ÿè®¡æ•°æ®ã€‚")

        with tab4:
            st.markdown("### è¯¾ç¨‹è®¾ç½®å¯¹æ¯•ä¸šè¦æ±‚è¾¾æˆæ”¯æ’‘å…³ç³»è¡¨ [cite: 124, 128]")
            st.dataframe(pd.DataFrame(d["tables"]["4"]), use_container_width=True, key="v121_df4")

if __name__ == "__main__":
    main()