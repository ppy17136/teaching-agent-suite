# -*- coding: utf-8 -*-
"""
æ•™å­¦æ™ºèƒ½ä½“å¹³å°ï¼ˆå•æ–‡ä»¶ç‰ˆ app.pyï¼‰- ä¿®æ”¹å¢å¼ºç‰ˆ
å¢å¼ºç‚¹ï¼š
1) åŸ¹å…»æ–¹æ¡ˆä¸Šä¼ è¯†åˆ« -> è¯†åˆ«æ¸…å•ï¼ˆå¯ç¼–è¾‘ï¼‰-> ç”¨æˆ·ç¡®è®¤/ä¿®æ­£ -> å†ä¿å­˜ï¼ˆç»“æ„åŒ–+å¯è¿½æº¯ï¼‰
2) è¡¨æ ¼ä»¥ data_editor å½¢å¼å±•ç¤ºï¼Œä¾¿äºç¡®è®¤/ä¿®æ­£ï¼›å›¾/å¯¼å›¾ç”¨â€œè¾¹è¡¨+Graphvizâ€æ›¿ä»£è¯†åˆ«è¿˜åŸä¸ä½³
3) ä¾§è¾¹æ æ–°å¢å¤‡ä»½/è¿˜åŸï¼ˆzipï¼‰
4) ä¿®å¤ ensure_db_schema ä¸ db() WAL è®¾ç½®ä¸ä¸€è‡´å¯¼è‡´çš„æ½œåœ¨ OperationalError

è¯´æ˜ï¼š
- ä¸ä¾èµ– OCRï¼›pdfplumber èƒ½æŠ½åˆ°è¡¨å°±ç”¨è¡¨ï¼Œå¦åˆ™é€€åŒ–ä¸ºâ€œæ‰‹å·¥è¾¹è¡¨/æ‰‹å·¥çŸ©é˜µâ€
- åœ¨çº¿æ¨¡å¼å¯ç”¨åƒé—®åšè¿›ä¸€æ­¥â€œçº é”™/è¡¥å…¨â€ï¼ˆå¯é€‰ï¼‰
"""

import os
import io
import re
import json
import time
import base64
import hashlib
import sqlite3
import zipfile
import threading
from typing import List, Optional, Dict, Any, Tuple

import streamlit as st
import requests
import numpy as np
from PIL import Image, ImageOps

# -------- å¯é€‰è§£æä¾èµ–ï¼ˆç¼ºå¤±ä¹Ÿèƒ½è·‘ï¼‰ --------
try:
    import pdfplumber
except Exception:
    pdfplumber = None

try:
    from docx import Document
except Exception:
    Document = None

try:
    import mammoth
except Exception:
    mammoth = None

# docxtplï¼ˆæ¨¡æ¿åŒ–å¯¼å‡ºç”¨ï¼Œå¯é€‰ï¼‰
try:
    from docxtpl import DocxTemplate
except Exception:
    DocxTemplate = None

# pandasï¼ˆç”¨äºè¡¨æ ¼ç¼–è¾‘æ›´èˆ’æœï¼Œå¯é€‰ï¼‰
try:
    import pandas as pd
except Exception:
    pd = None


# ---------------------------
# åŸºç¡€é…ç½®ï¼ˆäº‘ç«¯å‹å¥½ï¼‰
# ---------------------------
st.set_page_config(page_title="æ•™å­¦æ™ºèƒ½ä½“å¹³å°", layout="wide")

BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
DEFAULT_TEXT_MODEL = "qwen-max"
DEFAULT_VL_MODEL = "qwen-vl-plus"

DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)
DB_PATH = os.path.join(DATA_DIR, "app.db")

_DB_LOCK = threading.Lock()


# ---------------------------
# UI ç¾åŒ–ï¼ˆCSSï¼‰
# ---------------------------
def inject_css():
    st.markdown(
        """
<style>
.main .block-container { padding-top: 1.0rem; padding-bottom: 2rem; max-width: 1320px; }
h1, h2, h3 { letter-spacing: .2px; }
code { font-size: 0.9em; }

.topbar{
  padding: 18px 18px;
  border-radius: 18px;
  background: linear-gradient(90deg, #0ea5e9 0%, #6366f1 55%, #8b5cf6 100%);
  color: white;
  box-shadow: 0 8px 24px rgba(0,0,0,.12);
}
.topbar .title{ font-size: 30px; font-weight: 800; }
.topbar .sub{ opacity: .9; margin-top: 6px; font-size: 14px; }

.card{
  border: 1px solid rgba(0,0,0,.08);
  border-radius: 18px;
  padding: 16px 16px;
  background: rgba(255,255,255,.6);
  box-shadow: 0 6px 16px rgba(0,0,0,.06);
}
.badge{
  display:inline-block; padding: 2px 10px; border-radius: 999px;
  font-size: 12px; border: 1px solid rgba(0,0,0,.12); margin-right: 6px;
}
.badge.ok { background:#ecfdf5; color:#065f46; border-color:#a7f3d0; }
.badge.warn { background:#fffbeb; color:#92400e; border-color:#fde68a; }
.badge.bad { background:#fef2f2; color:#991b1b; border-color:#fecaca; }

.depbar{ display:flex; gap:8px; flex-wrap: wrap; padding: 10px 0; }
.depitem{
  padding: 8px 10px; border-radius: 14px; border: 1px solid rgba(0,0,0,.10);
  background: rgba(255,255,255,.7); font-size: 13px;
}
.depitem b{ margin-right:6px; }

.docbox{
  border: 1px solid rgba(0,0,0,.10);
  border-radius: 18px;
  padding: 14px 16px;
  background: rgba(255,255,255,.75);
  line-height: 1.55;
  white-space: normal;
}
section[data-testid="stSidebar"] .stMarkdown h2{ font-size: 18px; font-weight: 800; }
div[data-testid="stDataFrame"] { border-radius: 14px; overflow:hidden; }
</style>
""",
        unsafe_allow_html=True,
    )


inject_css()


# ---------------------------
# æ•°æ®å±‚ï¼šSQLite + ç‰ˆæœ¬ç®¡ç† + ä¾èµ–è¾¹
# ---------------------------
def db() -> sqlite3.Connection:
    os.makedirs(DATA_DIR, exist_ok=True)
    conn = sqlite3.connect(DB_PATH, check_same_thread=False, timeout=30)
    conn.execute("PRAGMA foreign_keys=ON;")
    conn.execute("PRAGMA busy_timeout=5000;")
    try:
        conn.execute("PRAGMA journal_mode=WAL;")
    except Exception:
        conn.execute("PRAGMA journal_mode=DELETE;")
    return conn


def init_db():
    with _DB_LOCK:
        conn = db()
        conn.execute(
            """
CREATE TABLE IF NOT EXISTS projects(
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT NOT NULL,
  meta_json TEXT DEFAULT '{}',
  created_at INTEGER NOT NULL
);
"""
        )
        conn.execute(
            """
CREATE TABLE IF NOT EXISTS artifacts(
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  project_id INTEGER NOT NULL,
  type TEXT NOT NULL,
  title TEXT NOT NULL,
  content_md TEXT NOT NULL,
  content_json TEXT NOT NULL DEFAULT '{}',
  hash TEXT NOT NULL,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL,
  FOREIGN KEY(project_id) REFERENCES projects(id) ON DELETE CASCADE
);
"""
        )
        conn.execute(
            """
CREATE TABLE IF NOT EXISTS versions(
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  artifact_id INTEGER NOT NULL,
  version_no INTEGER NOT NULL,
  content_md TEXT NOT NULL,
  content_json TEXT NOT NULL,
  hash TEXT NOT NULL,
  created_at INTEGER NOT NULL,
  note TEXT DEFAULT '',
  FOREIGN KEY(artifact_id) REFERENCES artifacts(id) ON DELETE CASCADE
);
"""
        )
        conn.execute(
            """
CREATE TABLE IF NOT EXISTS edges(
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  project_id INTEGER NOT NULL,
  child_artifact_id INTEGER NOT NULL,
  parent_artifact_id INTEGER NOT NULL,
  created_at INTEGER NOT NULL,
  FOREIGN KEY(project_id) REFERENCES projects(id) ON DELETE CASCADE,
  FOREIGN KEY(child_artifact_id) REFERENCES artifacts(id) ON DELETE CASCADE,
  FOREIGN KEY(parent_artifact_id) REFERENCES artifacts(id) ON DELETE CASCADE
);
"""
        )
        conn.commit()
        conn.close()


def ensure_db_schema():
    # ä¸ db() è¡Œä¸ºä¿æŒä¸€è‡´ï¼Œä¸åœ¨è¿™é‡Œå¼ºåˆ¶ WALï¼ˆæŸäº›ç¯å¢ƒä¼šç‚¸ï¼‰
    init_db()


def now_ts() -> int:
    return int(time.time())


def sha256_text(s: str) -> str:
    return hashlib.sha256(s.encode("utf-8")).hexdigest()


def compute_hash(content_md: str, content_json: Dict[str, Any], parent_hashes: List[str]) -> str:
    payload = {"content_md": content_md, "content_json": content_json, "parents": parent_hashes}
    return sha256_text(json.dumps(payload, ensure_ascii=False, sort_keys=True))


def get_projects() -> List[Tuple[int, str]]:
    conn = db()
    rows = conn.execute("SELECT id, name FROM projects ORDER BY id DESC;").fetchall()
    conn.close()
    return rows


def get_project_meta(project_id: int) -> Dict[str, Any]:
    conn = db()
    row = conn.execute("SELECT meta_json FROM projects WHERE id=?", (project_id,)).fetchone()
    conn.close()
    if not row:
        return {}
    try:
        return json.loads(row[0] or "{}")
    except Exception:
        return {}


def create_project(name: str, meta: Dict[str, Any]) -> int:
    with _DB_LOCK:
        conn = db()
        ts = now_ts()
        cur = conn.execute(
            "INSERT INTO projects(name, meta_json, created_at) VALUES(?,?,?)",
            (name, json.dumps(meta, ensure_ascii=False), ts),
        )
        conn.commit()
        pid = cur.lastrowid
        conn.close()
        return pid


def list_artifacts(project_id: int) -> List[Dict[str, Any]]:
    conn = db()
    try:
        rows = conn.execute(
            "SELECT id, type, title, hash, updated_at "
            "FROM artifacts WHERE project_id=? ORDER BY updated_at DESC",
            (project_id,),
        ).fetchall()
    except sqlite3.OperationalError:
        conn.close()
        ensure_db_schema()
        conn = db()
        rows = conn.execute(
            "SELECT id, type, title, hash, updated_at "
            "FROM artifacts WHERE project_id=? ORDER BY updated_at DESC",
            (project_id,),
        ).fetchall()
    conn.close()

    out = []
    for r in rows:
        out.append({"id": r[0], "type": r[1], "title": r[2], "hash": r[3], "updated_at": r[4]})
    return out


def get_artifact(project_id: int, a_type: str) -> Optional[Dict[str, Any]]:
    conn = db()
    row = conn.execute(
        "SELECT id, title, content_md, content_json, hash, created_at, updated_at "
        "FROM artifacts WHERE project_id=? AND type=? ORDER BY updated_at DESC LIMIT 1",
        (project_id, a_type),
    ).fetchone()
    conn.close()
    if not row:
        return None
    return {
        "id": row[0],
        "type": a_type,
        "title": row[1],
        "content_md": row[2],
        "content_json": json.loads(row[3] or "{}"),
        "hash": row[4],
        "created_at": row[5],
        "updated_at": row[6],
    }


def get_versions(artifact_id: int) -> List[Dict[str, Any]]:
    conn = db()
    rows = conn.execute(
        "SELECT version_no, hash, created_at, note FROM versions WHERE artifact_id=? ORDER BY version_no DESC",
        (artifact_id,),
    ).fetchall()
    conn.close()
    return [{"version_no": r[0], "hash": r[1], "created_at": r[2], "note": r[3]} for r in rows]


def set_edges(project_id: int, child_id: int, parent_ids: List[int]):
    with _DB_LOCK:
        conn = db()
        conn.execute("DELETE FROM edges WHERE project_id=? AND child_artifact_id=?", (project_id, child_id))
        ts = now_ts()
        for pid in parent_ids:
            conn.execute(
                "INSERT INTO edges(project_id, child_artifact_id, parent_artifact_id, created_at) VALUES(?,?,?,?)",
                (project_id, child_id, pid, ts),
            )
        conn.commit()
        conn.close()


def upsert_artifact(
    project_id: int,
    a_type: str,
    title: str,
    content_md: str,
    content_json: Dict[str, Any],
    parent_ids: List[int],
    note: str = "",
) -> Dict[str, Any]:
    existing = get_artifact(project_id, a_type)

    parent_hashes: List[str] = []
    for pid in parent_ids:
        conn = db()
        row = conn.execute("SELECT hash FROM artifacts WHERE id=? AND project_id=?", (pid, project_id)).fetchone()
        conn.close()
        if row:
            parent_hashes.append(row[0])

    new_hash = compute_hash(content_md, content_json, parent_hashes)
    ts = now_ts()

    with _DB_LOCK:
        conn = db()
        if existing:
            cur_ver = conn.execute("SELECT MAX(version_no) FROM versions WHERE artifact_id=?", (existing["id"],)).fetchone()
            next_ver = (cur_ver[0] or 0) + 1
            conn.execute(
                "INSERT INTO versions(artifact_id, version_no, content_md, content_json, hash, created_at, note) "
                "VALUES(?,?,?,?,?,?,?)",
                (
                    existing["id"],
                    next_ver,
                    existing["content_md"],
                    json.dumps(existing["content_json"], ensure_ascii=False),
                    existing["hash"],
                    ts,
                    note or "auto-save",
                ),
            )
            conn.execute(
                "UPDATE artifacts SET title=?, content_md=?, content_json=?, hash=?, updated_at=? "
                "WHERE id=? AND project_id=?",
                (title, content_md, json.dumps(content_json, ensure_ascii=False), new_hash, ts, existing["id"], project_id),
            )
            conn.commit()
        else:
            conn.execute(
                "INSERT INTO artifacts(project_id, type, title, content_md, content_json, hash, created_at, updated_at) "
                "VALUES(?,?,?,?,?,?,?,?)",
                (project_id, a_type, title, content_md, json.dumps(content_json, ensure_ascii=False), new_hash, ts, ts),
            )
            conn.commit()
        conn.close()

    a = get_artifact(project_id, a_type)
    if a:
        set_edges(project_id, a["id"], parent_ids)
    return a


# ---------------------------
# æ–‡æ¡£é“¾ & ä¾èµ–è§„åˆ™
# ---------------------------
DOC_TYPES = [
    ("overview", "é¦–é¡µæ€»è§ˆ"),
    ("training_plan", "åŸ¹å…»æ–¹æ¡ˆï¼ˆåº•åº§ï¼‰"),
    ("syllabus", "è¯¾ç¨‹æ•™å­¦å¤§çº²ï¼ˆä¾èµ–åŸ¹å…»æ–¹æ¡ˆï¼‰"),
    ("calendar", "æ•™å­¦æ—¥å†ï¼ˆä¾èµ–å¤§çº²ï¼‰"),
    ("lesson_plan", "æ•™æ¡ˆï¼ˆä¾èµ–æ—¥å†ï¼‰"),
    ("assessment", "ä½œä¸š/é¢˜åº“/è¯•å·æ–¹æ¡ˆï¼ˆä¾èµ–å¤§çº²ï¼‰"),
    ("review", "å®¡æ ¸è¡¨ï¼ˆä¾èµ–è¯•å·æ–¹æ¡ˆ/å¤§çº²ï¼‰"),
    ("report", "è¯¾ç¨‹ç›®æ ‡è¾¾æˆæŠ¥å‘Šï¼ˆä¾èµ–å¤§çº²/æˆç»©ï¼‰"),
    ("manual", "æˆè¯¾æ‰‹å†Œï¼ˆä¾èµ–æ•™æ¡ˆ/è¿‡ç¨‹è¯æ®ï¼‰"),
    ("evidence", "è¯¾å ‚çŠ¶æ€ä¸è¿‡ç¨‹è¯æ®ï¼ˆå¯é€‰ï¼‰"),
    ("vge", "è¯æ®é“¾ä¸å¯éªŒè¯ç”Ÿæˆï¼ˆVGEï¼‰"),
    ("dep_graph", "ä¾èµ–å›¾å¯è§†åŒ–ï¼ˆæ ‘/Graphvizï¼‰"),
    ("docx_export", "æ¨¡æ¿åŒ–DOCXå¯¼å‡ºï¼ˆå­—æ®µæ˜ å°„å¡«å……ï¼‰"),
]

DEP_RULES = {
    "training_plan": [],
    "syllabus": ["training_plan"],
    "calendar": ["syllabus"],
    "lesson_plan": ["calendar"],
    "assessment": ["syllabus"],
    "review": ["assessment", "syllabus"],
    "report": ["syllabus"],
    "manual": ["lesson_plan"],
    "evidence": [],
    "vge": [],
    "overview": [],
    "dep_graph": [],
    "docx_export": [],
}


# ---------------------------
# æ–‡ä»¶æŠ½å–ï¼ˆä¸Šä¼ ï¼‰
# ---------------------------
def extract_text_from_upload(file) -> str:
    name = (file.name or "").lower()
    file.seek(0)

    if name.endswith(".pdf") and pdfplumber is not None:
        with pdfplumber.open(file) as pdf:
            texts = []
            for p in pdf.pages:
                t = p.extract_text() or ""
                if t.strip():
                    texts.append(t)
            return "\n".join(texts).strip()

    if name.endswith(".docx") and Document is not None:
        file.seek(0)
        doc = Document(file)
        paras = [p.text for p in doc.paragraphs if p.text.strip()]
        return "\n".join(paras).strip()

    if name.endswith(".doc") and mammoth is not None:
        file.seek(0)
        res = mammoth.convert_to_text(file)
        return (res.value or "").strip()

    file.seek(0)
    try:
        return file.read().decode("utf-8", errors="ignore")
    except Exception:
        return ""


def extract_pdf_tables(upload_file) -> List[Dict[str, Any]]:
    """
    å°è¯•ä» PDF æŠ½å–è¡¨æ ¼ï¼Œè¿”å›ï¼š
    [
      {"page": 12, "tables": [ [ [cell, ...], ... ], ... ]},
      ...
    ]
    """
    if pdfplumber is None:
        return []
    upload_file.seek(0)
    out: List[Dict[str, Any]] = []
    try:
        with pdfplumber.open(upload_file) as pdf:
            for i, p in enumerate(pdf.pages, start=1):
                try:
                    tabs = p.extract_tables() or []
                except Exception:
                    tabs = []
                good_tabs = []
                for t in tabs:
                    # è¿‡æ»¤æ‰å¤ªå°/å¤ªç¢çš„
                    if not t or len(t) < 2:
                        continue
                    max_cols = max([len(r) for r in t if r] + [0])
                    if max_cols >= 3 and len(t) >= 3:
                        good_tabs.append(t)
                if good_tabs:
                    out.append({"page": i, "tables": good_tabs})
    except Exception:
        return []
    return out


def table_to_dataframe(table_2d: List[List[Any]]) -> Optional["pd.DataFrame"]:
    if pd is None:
        return None
    if not table_2d:
        return pd.DataFrame()
    # å–ç¬¬ä¸€è¡Œä¸ºè¡¨å¤´ï¼ˆè‹¥ç©ºåˆ™ç»™é»˜è®¤ï¼‰
    header = table_2d[0]
    header = [(h or "").strip() if isinstance(h, str) else (str(h) if h is not None else "") for h in header]
    if all([h == "" for h in header]):
        header = [f"col{i+1}" for i in range(len(header))]
    rows = table_2d[1:]
    # è¡¥é½åˆ—æ•°
    ncol = len(header)
    norm_rows = []
    for r in rows:
        r = r or []
        rr = list(r)[:ncol] + [""] * max(0, ncol - len(r))
        norm_rows.append(rr)
    return pd.DataFrame(norm_rows, columns=header)


def guess_course_support_matrix(tables_pack: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    å°è¯•åœ¨æŠ½åˆ°çš„è¡¨æ ¼é‡ŒçŒœâ€œè¯¾ç¨‹-æ¯•ä¸šè¦æ±‚æ”¯æ’‘çŸ©é˜µâ€
    è¾“å‡ºï¼š
    {
      "found": bool,
      "hint": "...",
      "matrix": [ {"course": "...", "supports": {"1.1":"H", "2.3":"M", ...}}, ... ],
      "raw_tables": [...]
    }
    """
    res = {"found": False, "hint": "æœªè‡ªåŠ¨è¯†åˆ«åˆ°æ”¯æ’‘çŸ©é˜µï¼ˆå¯æ‰‹å·¥å½•å…¥/ä¿®æ­£ï¼‰", "matrix": [], "raw_tables": []}
    if not tables_pack:
        return res

    # ç»éªŒï¼šæ”¯æ’‘çŸ©é˜µå¾€å¾€è¡¨å¤´å«â€œæ¯•ä¸šè¦æ±‚/æŒ‡æ ‡ç‚¹/è¾¾æˆ/æ”¯æ’‘/H/M/Lâ€ç­‰å­—æ ·
    key_words = ["æ¯•ä¸šè¦æ±‚", "æŒ‡æ ‡", "æ”¯æ’‘", "è¾¾æˆ", "H", "M", "L"]
    candidates = []

    for pack in tables_pack:
        page = pack["page"]
        for t in pack["tables"]:
            flat = " ".join([" ".join([(c or "") for c in (r or [])]) for r in t if r])
            hit = sum([1 for k in key_words if k in flat])
            if hit >= 2:
                candidates.append({"page": page, "table": t, "hit": hit})

    if not candidates:
        res["raw_tables"] = tables_pack
        return res

    candidates.sort(key=lambda x: x["hit"], reverse=True)
    best = candidates[0]
    res["found"] = True
    res["hint"] = f"è‡ªåŠ¨æŒ‘é€‰äº†ç¬¬ {best['page']} é¡µçš„ç–‘ä¼¼æ”¯æ’‘çŸ©é˜µï¼ˆå‘½ä¸­å…³é”®è¯æ•°={best['hit']}ï¼‰ã€‚è¯·åœ¨ä¸‹æ–¹ç¡®è®¤/ä¿®æ­£ã€‚"
    res["raw_tables"] = tables_pack

    # å…ˆä¸åšå¤æ‚æ™ºèƒ½è§£æï¼šæŠŠ best table åŸæ ·äº¤ç»™ç”¨æˆ·ç¼–è¾‘ç¡®è®¤
    res["best_table"] = {"page": best["page"], "table": best["table"]}
    return res


def extract_training_plan_checklist(text: str) -> Dict[str, Any]:
    """
    ä»æ–‡æœ¬ç²—æŠ½ä¸€äº›æ¸…å•å­—æ®µï¼ˆå¯ç¼–è¾‘ï¼Œæœ€ç»ˆä»¥ç”¨æˆ·ç¡®è®¤ä¸ºå‡†ï¼‰
    """
    # ç®€å•æ­£åˆ™ï¼šåŸ¹å…»ç›®æ ‡é€šå¸¸â€œåŸ¹å…»ç›®æ ‡/ç›®æ ‡â€é™„è¿‘ï¼›æ¯•ä¸šè¦æ±‚é€šå¸¸â€œæ¯•ä¸šè¦æ±‚â€é™„è¿‘
    major = ""
    grade = ""
    # ä»ç±»ä¼¼â€œ2024ç‰ˆ/2024çº§â€ç­‰ä¸­çŒœå¹´çº§
    m = re.search(r"(\d{2,4})çº§", text)
    if m:
        grade = m.group(1)

    # ä¸“ä¸šåç§°çŒœæµ‹
    m2 = re.search(r"(ææ–™æˆå‹åŠæ§åˆ¶å·¥ç¨‹|æœºæ¢°å·¥ç¨‹|ç”µæ°”å·¥ç¨‹åŠå…¶è‡ªåŠ¨åŒ–|è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯|åœŸæœ¨å·¥ç¨‹|èˆªç©ºèˆªå¤©|æµ‹æ§æŠ€æœ¯ä¸ä»ªå™¨)", text)
    if m2:
        major = m2.group(1)

    # ç²—æâ€œåŸ¹å…»ç›®æ ‡â€æ®µè½
    goals = []
    m3 = re.search(r"(åŸ¹å…»ç›®æ ‡[\s\S]{0,2000}?)(æ¯•ä¸šè¦æ±‚|ä¸‰ã€|å››ã€|äº”ã€|è¯¾ç¨‹ä½“ç³»|$)", text)
    if m3:
        chunk = m3.group(1)
        for line in chunk.splitlines():
            line = line.strip()
            if re.match(r"^(\d+[\.\ã€]|[-â€¢])", line):
                goals.append(re.sub(r"^(\d+[\.\ã€]|[-â€¢])\s*", "", line))

    # ç²—æâ€œæ¯•ä¸šè¦æ±‚â€ç¼–å·è¡Œ
    outcomes = []
    # æ‰¾åˆ°â€œæ¯•ä¸šè¦æ±‚â€å 2000 å­—å†…çš„ â€œ1.â€ã€â€œ2.â€ ç­‰
    m4 = re.search(r"(æ¯•ä¸šè¦æ±‚[\s\S]{0,2500})", text)
    if m4:
        chunk = m4.group(1)
        for line in chunk.splitlines():
            line = line.strip()
            mm = re.match(r"^(\d{1,2})[\.ã€]\s*(.+)$", line)
            if mm:
                outcomes.append({"no": mm.group(1), "name": mm.group(2).strip()})

    return {
        "major_guess": major,
        "grade_guess": grade,
        "goals_guess": goals[:8],
        "outcomes_guess": outcomes[:20],
    }


# ---------------------------
# åƒé—®ï¼šæ–‡æœ¬ç”Ÿæˆï¼ˆå¯é€‰ï¼‰
# ---------------------------
def get_qwen_key() -> str:
    return st.secrets.get("QWEN_API_KEY", os.environ.get("QWEN_API_KEY", "")).strip()


def qwen_chat(
    messages: List[Dict[str, Any]],
    model: str = DEFAULT_TEXT_MODEL,
    temperature: float = 0.3,
    max_tokens: int = 1400,
) -> str:
    key = get_qwen_key()
    if not key:
        raise RuntimeError("æœªé…ç½® QWEN_API_KEYï¼ˆå½“å‰ä¸ºæ¼”ç¤ºæ¨¡å¼å¯ä¸å¡«ï¼‰")
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    data = {"model": model, "messages": messages, "temperature": temperature, "max_tokens": max_tokens}
    resp = requests.post(BASE_URL + "/chat/completions", headers=headers, json=data, timeout=60)
    if resp.status_code != 200:
        raise RuntimeError(f"LLMæ¥å£é”™è¯¯ï¼š{resp.status_code} {resp.text[:300]}")
    return resp.json()["choices"][0]["message"]["content"]


# ---------------------------
# å¤‡ä»½/è¿˜åŸï¼ˆzipï¼‰
# ---------------------------
def safe_extract_zip(zip_bytes: bytes, target_dir: str):
    os.makedirs(target_dir, exist_ok=True)
    with zipfile.ZipFile(io.BytesIO(zip_bytes), "r") as z:
        for member in z.infolist():
            # é˜²è·¯å¾„ç©¿è¶Š
            p = os.path.normpath(member.filename).replace("\\", "/")
            if p.startswith("../") or p.startswith("..\\") or p.startswith("/"):
                continue
            out_path = os.path.join(target_dir, p)
            # åˆ›å»ºç›®å½•
            if member.is_dir():
                os.makedirs(out_path, exist_ok=True)
                continue
            os.makedirs(os.path.dirname(out_path), exist_ok=True)
            with z.open(member, "r") as src, open(out_path, "wb") as dst:
                dst.write(src.read())


def make_backup_zip_bytes() -> bytes:
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", compression=zipfile.ZIP_DEFLATED) as z:
        if os.path.exists(DATA_DIR):
            for root, _, files in os.walk(DATA_DIR):
                for fn in files:
                    ap = os.path.join(root, fn)
                    rel = os.path.relpath(ap, ".")
                    z.write(ap, rel)
    return buf.getvalue()


# ---------------------------
# ç”Ÿæˆæ¨¡æ¿ï¼ˆæ— APIä¹Ÿå¯ï¼‰
# ---------------------------
def template_training_plan(major: str, grade: str, course_group: str) -> str:
    return f"""# {grade}çº§ã€Š{major}ã€‹åŸ¹å…»æ–¹æ¡ˆï¼ˆç¤ºä¾‹ï¼‰

## ä¸€ã€åŸ¹å…»ç›®æ ‡
- é¢å‘å·¥ç¨‹å®è·µï¼Œå…·å¤‡æ‰å®çš„æ•°å­¦/åŠ›å­¦/ææ–™åŸºç¡€
- å…·å¤‡ææ–™æˆå‹ä¸åˆ¶é€ è¿‡ç¨‹çš„åˆ†æã€è®¾è®¡ä¸ä¼˜åŒ–èƒ½åŠ›
- å…·å¤‡å·¥ç¨‹ä¼¦ç†ã€å›¢é˜Ÿåä½œä¸ç»ˆèº«å­¦ä¹ èƒ½åŠ›

## äºŒã€æ¯•ä¸šè¦æ±‚ï¼ˆç¤ºä¾‹ï¼‰
1. å·¥ç¨‹çŸ¥è¯†
2. é—®é¢˜åˆ†æ
3. è®¾è®¡/å¼€å‘è§£å†³æ–¹æ¡ˆ
4. ç ”ç©¶
5. ç°ä»£å·¥å…·ä½¿ç”¨
6. å·¥ç¨‹ä¸ç¤¾ä¼š
7. ç¯å¢ƒä¸å¯æŒç»­å‘å±•
8. èŒä¸šè§„èŒƒ
9. ä¸ªäººä¸å›¢é˜Ÿ
10. æ²Ÿé€š
11. é¡¹ç›®ç®¡ç†
12. ç»ˆèº«å­¦ä¹ 

## ä¸‰ã€è¯¾ç¨‹ä½“ç³»ï¼š{course_group}
- é€šè¯†ä¸åŸºç¡€
- ä¸“ä¸šæ ¸å¿ƒ
- ä¸“ä¸šæ–¹å‘
- å®è·µç¯èŠ‚
"""


def template_syllabus(
    course_name: str,
    hours_total: int,
    credits: float,
    extra_req: str,
    tp_text: str,
    support_points: Optional[List[str]] = None,
) -> Tuple[str, Dict[str, Any]]:
    outcomes = []
    for line in tp_text.splitlines():
        m = re.match(r"^\s*\d+\.\s*(.+)$", line.strip())
        if m:
            outcomes.append(m.group(1).strip())
    outcomes = outcomes[:8] or ["å·¥ç¨‹çŸ¥è¯†", "é—®é¢˜åˆ†æ", "è®¾è®¡/å¼€å‘è§£å†³æ–¹æ¡ˆ", "ç°ä»£å·¥å…·ä½¿ç”¨"]

    obj = [
        {"id": "CO1", "desc": "ç†è§£è¯¾ç¨‹æ ¸å¿ƒæ¦‚å¿µä¸åŸºæœ¬æ–¹æ³•", "map_to": outcomes[0]},
        {"id": "CO2", "desc": "èƒ½åŸºäºæ¡ˆä¾‹è¿›è¡Œå»ºæ¨¡/åˆ†æå¹¶è§£é‡Šç»“æœ", "map_to": outcomes[1]},
        {"id": "CO3", "desc": "èƒ½å¤Ÿä½¿ç”¨è½¯ä»¶å·¥å…·å®Œæˆè¯¾ç¨‹å®è·µä»»åŠ¡", "map_to": outcomes[min(3, len(outcomes) - 1)]},
    ]
    sp = support_points or []
    sp_md = "ã€".join(sp) if sp else "ï¼ˆå°šæœªä»åŸ¹å…»æ–¹æ¡ˆæ”¯æ’‘çŸ©é˜µä¸­ç¡®è®¤ï¼Œå¯æ‰‹å·¥è¡¥å……ï¼‰"

    md = f"""# ã€Š{course_name}ã€‹è¯¾ç¨‹æ•™å­¦å¤§çº²ï¼ˆä¸¥æ ¼ä¾èµ–åŸ¹å…»æ–¹æ¡ˆï¼‰

## 1. è¯¾ç¨‹åŸºæœ¬ä¿¡æ¯
- å­¦åˆ†ï¼š{credits}
- æ€»å­¦æ—¶ï¼š{hours_total}
- è¯¾ç¨‹æ€§è´¨ï¼šä¸“ä¸šè¯¾/æ–¹å‘è¯¾ï¼ˆç¤ºä¾‹ï¼‰

## 2. æœ¬è¯¾ç¨‹æ”¯æ’‘çš„æ¯•ä¸šè¦æ±‚æŒ‡æ ‡ç‚¹ï¼ˆæ¥è‡ªåŸ¹å…»æ–¹æ¡ˆç¡®è®¤ï¼‰
- {sp_md}

## 3. è¯¾ç¨‹ç›®æ ‡ï¼ˆCOï¼‰ä¸æ¯•ä¸šè¦æ±‚æ˜ å°„
| è¯¾ç¨‹ç›®æ ‡ | æè¿° | å¯¹åº”æ¯•ä¸šè¦æ±‚ |
|---|---|---|
""" + "\n".join([f"| {x['id']} | {x['desc']} | {x['map_to']} |" for x in obj]) + f"""

## 4. è€ƒæ ¸æ–¹å¼ä¸æ¯”ä¾‹ï¼ˆå¯è°ƒæ•´ï¼‰
- å¹³æ—¶ï¼š30%
- ä½œä¸š/é¡¹ç›®ï¼š20%
- æœŸæœ«ï¼š50%

## 5. æ•™å­¦å†…å®¹ä¸å­¦æ—¶åˆ†é…ï¼ˆç¤ºä¾‹ï¼‰
- ç¬¬1ç« ï¼šå¯¼è®ºï¼ˆ2å­¦æ—¶ï¼‰
- ç¬¬2ç« ï¼šæ–¹æ³•ä¸å·¥å…·ï¼ˆ6å­¦æ—¶ï¼‰
- ç¬¬3ç« ï¼šæ¡ˆä¾‹ä¸å®è·µï¼ˆ10å­¦æ—¶ï¼‰
- ç¬¬4ç« ï¼šç»¼åˆé¡¹ç›®ä¸ç­”è¾©ï¼ˆ{max(2, hours_total-18)}å­¦æ—¶ï¼‰

## 6. å®è·µä¸è¦æ±‚
{extra_req or "ç»“åˆå·¥ç¨‹æ¡ˆä¾‹ï¼Œå¼ºè°ƒè¡¨è¾¾ä¸è§„èŒƒæ–‡æ¡£äº§å‡ºã€‚"}
"""
    js = {
        "course_name": course_name,
        "hours_total": hours_total,
        "credits": credits,
        "support_points": sp,
        "CO": obj
    }
    return md, js


def template_calendar(course_name: str, weeks: int, syllabus_json: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
    co = syllabus_json.get("CO", [])
    rows = []
    for w in range(1, weeks + 1):
        rows.append(
            {
                "week": w,
                "topic": f"ç¬¬{w}å‘¨ï¼šä¸»é¢˜ä¸æ¡ˆä¾‹ï¼ˆç¤ºä¾‹ï¼‰",
                "activity": "è®²æˆ+è®¨è®º+ç»ƒä¹ ",
                "homework": "å°ç»ƒä¹ /é˜…è¯»",
                "co": co[(w - 1) % len(co)]["id"] if co else "CO1",
            }
        )
    md = f"""# ã€Š{course_name}ã€‹æ•™å­¦æ—¥å†ï¼ˆä¾èµ–æ•™å­¦å¤§çº²ï¼‰

| å‘¨æ¬¡ | æ•™å­¦ä¸»é¢˜ | æ•™å­¦æ´»åŠ¨ | ä½œä¸š/ä»»åŠ¡ | å¯¹åº”è¯¾ç¨‹ç›®æ ‡ |
|---:|---|---|---|---|
""" + "\n".join([f"| {r['week']} | {r['topic']} | {r['activity']} | {r['homework']} | {r['co']} |" for r in rows])
    return md, {"weeks": weeks, "rows": rows}


def template_lesson_plan(course_name: str, calendar_json: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
    rows = calendar_json.get("rows", [])[:4]
    md = f"# ã€Š{course_name}ã€‹æ•™æ¡ˆï¼ˆä¾èµ–æ•™å­¦æ—¥å†ï¼‰\n\n"
    plans = []
    for r in rows:
        md += f"""## {r['topic']}
- æ•™å­¦ç›®æ ‡ï¼šå›´ç»• {r['co']} è¾¾æˆ
- é‡ç‚¹éš¾ç‚¹ï¼šæ ¸å¿ƒæ¦‚å¿µ+å·¥ç¨‹æ¡ˆä¾‹è§£é‡Š
- æ•™å­¦è¿‡ç¨‹ï¼šå¯¼å…¥ â†’ è®²è§£ â†’ è®¨è®º â†’ ç»ƒä¹  â†’ å°ç»“
- ä½œä¸šï¼š{r['homework']}

"""
        plans.append({"week": r["week"], "co": r["co"], "topic": r["topic"]})
    return md.strip(), {"plans": plans}


def template_assessment(course_name: str, syllabus_json: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
    co = syllabus_json.get("CO", [])
    bank = []
    for i, x in enumerate(co, start=1):
        bank.append(
            {
                "qid": f"Q{i}",
                "type": "ç®€ç­”/è®¡ç®—/æ¡ˆä¾‹",
                "target_co": x["id"],
                "stem": f"å›´ç»• {x['id']}ï¼šè¯´æ˜å…³é”®æ¦‚å¿µï¼Œå¹¶ç»™å‡ºä¸€ä¸ªå·¥ç¨‹ç¤ºä¾‹ã€‚",
                "rubric": "æ¦‚å¿µæ­£ç¡®(40)+æ¨ç†æ¸…æ™°(40)+è¡¨è¾¾è§„èŒƒ(20)",
            }
        )
    md = f"""# ã€Š{course_name}ã€‹ä½œä¸š/é¢˜åº“/è¯•å·æ–¹æ¡ˆï¼ˆä¾èµ–æ•™å­¦å¤§çº²ï¼‰

## é¢˜åº“ï¼ˆç¤ºä¾‹ï¼‰
""" + "\n".join(
        [
            f"- **{q['qid']}**ï¼ˆ{q['type']}ï¼Œå¯¹åº”{q['target_co']}ï¼‰ï¼š{q['stem']}\n  - è¯„åˆ†ç»†åˆ™ï¼š{q['rubric']}"
            for q in bank
        ]
    )
    return md, {"bank": bank}


def template_review_forms(
    course_name: str, assessment_json: Dict[str, Any], syllabus_json: Dict[str, Any]
) -> Tuple[str, Dict[str, Any]]:
    bank = assessment_json.get("bank", [])
    co = [x.get("id") for x in syllabus_json.get("CO", [])]
    cover = {c: 0 for c in co}
    for q in bank:
        if q.get("target_co") in cover:
            cover[q["target_co"]] += 1

    md = f"""# ã€Š{course_name}ã€‹å®¡æ ¸è¡¨é›†åˆï¼ˆä¾èµ–è¯•å·æ–¹æ¡ˆ/æ•™å­¦å¤§çº²ï¼‰

## A. è¯•é¢˜å®¡æ ¸è¡¨ï¼ˆç¤ºä¾‹ï¼‰
| é¢˜å· | é¢˜å‹ | å¯¹åº”CO | è¦†ç›–è¯´æ˜ | ç»“è®º |
|---|---|---|---|---|
""" + "\n".join(
        [f"| {q['qid']} | {q['type']} | {q['target_co']} | è¦†ç›–{q['target_co']}å…³é”®èƒ½åŠ› | é€šè¿‡ |" for q in bank]
    ) + f"""

## B. è¯¾ç¨‹ç›®æ ‡è¾¾æˆè¯„ä»·ä¾æ®åˆç†æ€§å®¡æ ¸ï¼ˆç¤ºä¾‹ï¼‰
| è¯¾ç¨‹ç›®æ ‡ | è¯„ä»·è¯æ® | è¯æ®å……åˆ†æ€§ | å¤‡æ³¨ |
|---|---|---|---|
""" + "\n".join([f"| {c} | é¢˜åº“/ä½œä¸š/é¡¹ç›®/æœŸæœ« | è¾ƒå……åˆ† | å¯æŒç»­ä¼˜åŒ– |" for c in co]) + f"""

## C. è¦†ç›–æ£€æŸ¥
""" + "\n".join([f"- {k}ï¼š{v} é¢˜" for k, v in cover.items()])
    return md, {"coverage": cover}


def template_report(course_name: str, syllabus_json: Dict[str, Any], note: str = "") -> Tuple[str, Dict[str, Any]]:
    co = [x["id"] for x in syllabus_json.get("CO", [])] or ["CO1", "CO2", "CO3"]
    achieve = {c: round(0.72 - i * 0.05, 2) for i, c in enumerate(co)}
    md = f"""# ã€Š{course_name}ã€‹è¯¾ç¨‹ç›®æ ‡è¾¾æˆæƒ…å†µè¯„ä»·æŠ¥å‘Šï¼ˆä¾èµ–æ•™å­¦å¤§çº²ï¼‰

## 1. è¯„ä»·æ–¹æ³•
- ä¾æ®ï¼šä½œä¸šã€é¡¹ç›®ã€æœŸæœ«è¯•é¢˜ä¸COæ˜ å°„
- æŒ‡æ ‡ï¼šè¾¾æˆåº¦ï¼ˆ0~1ï¼‰

## 2. è¾¾æˆåº¦ç»“æœï¼ˆç¤ºä¾‹ï¼‰
| è¯¾ç¨‹ç›®æ ‡ | è¾¾æˆåº¦ | ç»“è®º |
|---|---:|---|
""" + "\n".join([f"| {c} | {achieve[c]} | {'è¾¾æˆ' if achieve[c] >= 0.6 else 'éœ€æ”¹è¿›'} |" for c in co]) + f"""

## 3. é—®é¢˜åˆ†æä¸æ”¹è¿›æªæ–½
- å¯¹è¾¾æˆåº¦è¾ƒä½çš„ç›®æ ‡ï¼Œå»ºè®®å¢åŠ é’ˆå¯¹æ€§æ¡ˆä¾‹ä¸å½¢æˆæ€§è¯„ä»·ã€‚
- æ”¹è¿›é—­ç¯ï¼šä¸‹è½®æ•™å­¦æ—¥å†ä¸ä½œä¸šé¢˜åº“å°†ä¾æ®æœ¬æŠ¥å‘Šè‡ªåŠ¨è°ƒæ•´ã€‚

## 4. å¤‡æ³¨
{note or "ï¼ˆæ¼”ç¤ºç‰ˆï¼šå¯ä¸Šä¼ æˆç»©è¡¨åç”ŸæˆçœŸå®è¾¾æˆåº¦ï¼‰"}
"""
    return md, {"achieve": achieve}


def template_manual(course_name: str, lesson_json: Dict[str, Any], evidence_md: str = "") -> Tuple[str, Dict[str, Any]]:
    plans = lesson_json.get("plans", [])
    md = f"""# ã€Š{course_name}ã€‹æˆè¯¾æ‰‹å†Œï¼ˆä¾èµ–æ•™æ¡ˆ/è¿‡ç¨‹è¯æ®ï¼‰

## 1. æˆè¯¾è¿‡ç¨‹è®°å½•ï¼ˆç¤ºä¾‹ï¼‰
""" + "\n".join([f"- ç¬¬{p['week']}å‘¨ï¼š{p['topic']}ï¼ˆå¯¹åº”{p['co']}ï¼‰" for p in plans]) + f"""

## 2. è¿‡ç¨‹è¯æ®æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
{evidence_md or "ï¼ˆå°šæœªæ·»åŠ è¯¾å ‚çŠ¶æ€è¯æ®ï¼Œå¯åœ¨â€œè¯¾å ‚çŠ¶æ€ä¸è¿‡ç¨‹è¯æ®â€æ¨¡å—ä¸Šä¼ ï¼‰"}

## 3. åæ€ä¸æ”¹è¿›
- æœ¬å‘¨å­¦ç”Ÿåé¦ˆï¼šâ€¦â€¦
- éœ€è¦å¼ºåŒ–çš„çŸ¥è¯†ç‚¹ï¼šâ€¦â€¦
- ä¸‹å‘¨è°ƒæ•´ï¼šâ€¦â€¦
"""
    return md, {"weeks": len(plans)}


# ---------------------------
# è¯¾å ‚è¯æ®ï¼ˆå¯é€‰ï¼‰
# ---------------------------
def img_to_dataurl(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=90)
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    return f"data:image/jpeg;base64,{b64}"


@st.cache_data(ttl=600, show_spinner=False)
def qwen_vl_classroom_summary(image_dataurl: str, context: str) -> str:
    key = get_qwen_key()
    if not key:
        return "ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼šæœªé…ç½®QWEN_API_KEYï¼Œè¯¾å ‚è¯æ®æ‘˜è¦æš‚ç”¨å ä½æ–‡æœ¬ï¼‰\n- Stu1ï¼šä¸“æ³¨ï¼ˆåå§¿ç¨³å®šï¼‰\n- Stu2ï¼šéœ€è¦å…³æ³¨ï¼ˆç›®å…‰æ¸¸ç¦»ï¼‰"
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    prompt = f"""
ä½ æ˜¯è¯¾å ‚è¿‡ç¨‹è¯æ®è®°å½•åŠ©æ‰‹ã€‚è¯·ä»…æ ¹æ®è¯¾å ‚ç…§ç‰‡ç»™å‡ºâ€œç­çº§çŠ¶æ€æ‘˜è¦â€ã€‚
è¦æ±‚ï¼š
1) ä¸è¿›è¡Œèº«ä»½è¯†åˆ«ï¼Œä¸æ¨æ–­å§“åï¼Œä»…ç”¨ Stu1/Stu2... ç¼–å·ï¼›
2) æ¯ä¸ªç¼–å·ç»™å‡ºï¼šä¸“æ³¨/éœ€è¦å…³æ³¨/çŠ¶æ€ä¸ä½³ ä¸‰é€‰ä¸€ï¼›
3) ç»™å‡ºä¸è¶…è¿‡15å­—ä¾æ®ï¼›
4) è¾“å‡ºä¸ºMarkdownåˆ—è¡¨ï¼›
è¯¾å ‚å†…å®¹ï¼š{context}
"""
    data = {
        "model": DEFAULT_VL_MODEL,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸¥è°¨çš„è¯¾å ‚è¿‡ç¨‹è¯æ®è®°å½•åŠ©æ‰‹ã€‚"},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_dataurl}},
                ],
            },
        ],
        "temperature": 0.2,
        "max_tokens": 450,
    }
    resp = requests.post(BASE_URL + "/chat/completions", headers=headers, json=data, timeout=60)
    if resp.status_code != 200:
        return f"ï¼ˆè¯¾å ‚è¯æ®æ¥å£è°ƒç”¨å¤±è´¥ï¼š{resp.status_code}ï¼‰"
    return resp.json()["choices"][0]["message"]["content"].strip()


# ---------------------------
# é€šç”¨ç»„ä»¶ï¼šä¾èµ–æ¡ + é¢„è§ˆ + ç¼–è¾‘
# ---------------------------
def type_label(a_type: str) -> str:
    for t, name in DOC_TYPES:
        if t == a_type:
            return name
    return a_type


def dep_status(project_id: int, a_type: str) -> Tuple[bool, List[Tuple[str, bool]]]:
    req = DEP_RULES.get(a_type, [])
    detail = []
    ok = True
    for r in req:
        exists = get_artifact(project_id, r) is not None
        detail.append((r, exists))
        ok = ok and exists
    return ok, detail


def render_depbar(project_id: int, a_type: str):
    ok, detail = dep_status(project_id, a_type)
    chips = []
    for r, exists in detail:
        cls = "ok" if exists else "bad"
        chips.append(f'<span class="badge {cls}">{type_label(r)}</span>')
    st.markdown(
        f"""
<div class="depbar">
  <div class="depitem"><b>ä¾èµ–æ£€æŸ¥</b>ï¼š{"âœ…é½å…¨" if ok else "âš ï¸ç¼ºå¤±ä¸Šæ¸¸"}</div>
  <div class="depitem">{''.join(chips) if chips else '<span class="badge ok">æ— ä¸Šæ¸¸ä¾èµ–</span>'}</div>
</div>
""",
        unsafe_allow_html=True,
    )


import html as _html


def render_doc_preview(md: str):
    safe = _html.escape(md).replace("\n", "<br>")
    st.markdown(f'<div class="docbox">{safe}</div>', unsafe_allow_html=True)


def md_textarea(label: str, value: str, height: int = 420, key: str = "") -> str:
    return st.text_area(label, value=value, height=height, key=key)


def artifact_toolbar(a: Dict[str, Any]):
    st.markdown(
        f"""
<div class="card">
  <div style="display:flex; justify-content:space-between; gap:12px; align-items:center;">
    <div>
      <div style="font-size:18px; font-weight:800;">{_html.escape(a['title'])}</div>
      <div style="opacity:.75; font-size:12px; margin-top:4px;">
        ç±»å‹ï¼š{type_label(a['type'])} ï½œ Hashï¼š<code>{a['hash'][:12]}</code> ï½œ æ›´æ–°æ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(a['updated_at']))}
      </div>
    </div>
    <div>
      <span class="badge ok">å¯ç¼–è¾‘</span>
      <span class="badge warn">å¯ç‰ˆæœ¬åŒ–</span>
      <span class="badge warn">ä¾èµ–å¯è¿½æº¯</span>
    </div>
  </div>
</div>
""",
        unsafe_allow_html=True,
    )


def export_docx_bytes_plaintext(md: str) -> bytes:
    try:
        from docx import Document as DocxDoc
    except Exception:
        return b""
    doc = DocxDoc()
    for line in md.splitlines():
        doc.add_paragraph(line)
    buf = io.BytesIO()
    doc.save(buf)
    return buf.getvalue()


# ---------------------------
# ä¾èµ–å›¾å¯è§†åŒ–ï¼ˆæ ‘ + Graphvizï¼‰
# ---------------------------
DOC_ORDER = [
    ("training_plan", "åŸ¹å…»æ–¹æ¡ˆ"),
    ("syllabus", "æ•™å­¦å¤§çº²"),
    ("calendar", "æ•™å­¦æ—¥å†"),
    ("lesson_plan", "æ•™æ¡ˆ"),
    ("assessment", "ä½œä¸š/é¢˜åº“/è¯•å·æ–¹æ¡ˆ"),
    ("review", "å®¡æ ¸è¡¨"),
    ("report", "è¾¾æˆè¯„ä»·æŠ¥å‘Š"),
    ("manual", "æˆè¯¾æ‰‹å†Œ"),
    ("evidence", "è¿‡ç¨‹è¯æ®"),
    ("vge", "è¯æ®é“¾/VGE"),
]


def build_edges_for_project(project_id: int) -> List[Tuple[str, str]]:
    conn = db()
    rows = conn.execute(
        "SELECT p.type, c.type "
        "FROM edges e "
        "JOIN artifacts c ON e.child_artifact_id=c.id "
        "JOIN artifacts p ON e.parent_artifact_id=p.id "
        "WHERE e.project_id=?",
        (project_id,),
    ).fetchall()
    conn.close()
    return [(r[0], r[1]) for r in rows]


def render_dep_tree_from_db(project_id: int):
    st.subheader("ä¾èµ–å…³ç³»ï¼ˆæ ‘çŠ¶ï¼‰")
    docs_present = {t for (t, _) in DOC_ORDER if get_artifact(project_id, t) is not None}

    for k, name in DOC_ORDER:
        if k in docs_present:
            a = get_artifact(project_id, k)
            vcount = len(get_versions(a["id"])) if a else 0
            deps = DEP_RULES.get(k, [])
            dep_txt = "ã€".join(deps) if deps else "æ— "
            st.markdown(f"- âœ… **{name}**  ï½œç‰ˆæœ¬ï¼š{vcount} ï½œä¾èµ–ï¼š{dep_txt}")
        else:
            st.markdown(f"- â¬œ {name}ï¼ˆæœªç”Ÿæˆ/æœªä¸Šä¼ ï¼‰")


def build_dot_from_db(project_id: int) -> str:
    labels = {k: name for k, name in DOC_ORDER}
    nodes = set()
    edges = build_edges_for_project(project_id)

    for p, c in edges:
        nodes.add(p)
        nodes.add(c)

    for k, _ in DOC_ORDER:
        if get_artifact(project_id, k) is not None:
            nodes.add(k)

    lines = [
        "digraph G {",
        'rankdir="LR";',
        'node [shape=box, style="rounded,filled", fillcolor="#ffffff"];',
        'edge [color="#64748b"];',
    ]

    for n in nodes:
        a = get_artifact(project_id, n)
        lab = labels.get(n, n)
        if a:
            lines.append(f'"{n}" [label="{lab}\\n{a["hash"][:8]}", fillcolor="#E8F5E9"];')
        else:
            lines.append(f'"{n}" [label="{lab}\\n(ç¼ºå¤±)", fillcolor="#FFEBEE", style="rounded,dashed,filled"];')

    for p, c in edges:
        lines.append(f'"{p}" -> "{c}";')

    if not edges:
        for child, reqs in DEP_RULES.items():
            for parent in reqs:
                lines.append(f'"{parent}" -> "{child}" [style=dashed];')

    lines.append("}")
    return "\n".join(lines)


def page_dep_graph():
    ensure_project()
    st.markdown("### ä¾èµ–å›¾å¯è§†åŒ–ï¼ˆæ ‘çŠ¶å›¾ / Graphvizï¼‰")
    st.caption("ç”¨äºå±•ç¤ºâ€œåŸ¹å…»æ–¹æ¡ˆâ†’å¤§çº²â†’æ—¥å†â†’æ•™æ¡ˆâ†’è¯•å·/å®¡æ ¸â†’è¾¾æˆâ†’æ‰‹å†Œâ†’è¯æ®é“¾â€çš„ä¾èµ–å…³ç³»ä¸å¯è¿½æº¯æ€§ã€‚")

    c1, c2 = st.columns([1, 1])
    with c1:
        render_dep_tree_from_db(project_id)
    with c2:
        st.subheader("ä¾èµ–å…³ç³»ï¼ˆGraphvizï¼‰")
        dot = build_dot_from_db(project_id)
        st.graphviz_chart(dot)

    st.markdown("---")
    st.subheader("æç¤º")
    st.markdown(
        "- åªæœ‰åœ¨ç”Ÿæˆ/ä¿å­˜ä¾èµ–å‹æ–‡æ¡£æ—¶ï¼Œç³»ç»Ÿæ‰ä¼šè®°å½•çœŸå®ä¾èµ–è¾¹ï¼ˆedgesï¼‰ã€‚\n"
        "- è‹¥ä½ ä¸Šä¼ äº†æŸä¸ªæ–‡æ¡£ä½œä¸ºåº•åº§ï¼ˆå¦‚åŸ¹å…»æ–¹æ¡ˆ/å¤§çº²ï¼‰ï¼Œåç»­ç”Ÿæˆçš„æ–‡æ¡£ä¼šè‡ªåŠ¨æŒ‡å‘å®ƒã€‚\n"
        "- ç”³æŠ¥å±•ç¤ºæ—¶ï¼Œå¯ä»¥æŠŠè¿™å¼ å›¾ä½œä¸ºâ€œæ•™è¯„ä¸€ä½“åŒ–ã€å¯éªŒè¯ç”Ÿæˆã€è¯æ®é“¾â€çš„æ ¸å¿ƒäº®ç‚¹ä¹‹ä¸€ã€‚"
    )


# ---------------------------
# æ¨¡æ¿åŒ– DOCX å¯¼å‡ºï¼ˆdocxtplï¼‰
# ---------------------------
def docx_render_from_template(template_bytes: bytes, context: Dict[str, Any]) -> bytes:
    if DocxTemplate is None:
        raise RuntimeError("å½“å‰ç¯å¢ƒæœªå®‰è£… docxtplã€‚è¯·åœ¨ requirements.txt æ·»åŠ ï¼šdocxtpl jinja2 lxml")
    tpl = DocxTemplate(io.BytesIO(template_bytes))
    tpl.render(context)
    out = io.BytesIO()
    tpl.save(out)
    return out.getvalue()


def flatten_syllabus_to_context(project_meta: Dict[str, Any], syllabus: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    ctx = {
        "major": project_meta.get("major", ""),
        "grade": project_meta.get("grade", ""),
        "course_group": project_meta.get("course_group", ""),
        "course_name": "",
        "credits": "",
        "hours_total": "",
        "course_objectives": "",
        "co_table": [],
        "assessment_ratio": "å¹³æ—¶30%+ä½œä¸š/é¡¹ç›®20%+æœŸæœ«50%",
    }
    if syllabus:
        js = syllabus.get("content_json") or {}
        ctx["course_name"] = js.get("course_name", "")
        ctx["credits"] = js.get("credits", "")
        ctx["hours_total"] = js.get("hours_total", "")
        co = js.get("CO", []) or []
        ctx["co_table"] = co
        ctx["course_objectives"] = "\n".join([f"{x.get('id','')}ï¼š{x.get('desc','')}" for x in co]).strip()
    return ctx


def flatten_calendar_to_context(calendar: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    ctx = {"calendar_rows": []}
    if calendar:
        js = calendar.get("content_json") or {}
        ctx["calendar_rows"] = js.get("rows", []) or []
    return ctx


def page_docx_export():
    ensure_project()
    st.markdown("### æ¨¡æ¿åŒ– DOCX å¯¼å‡ºï¼ˆå­—æ®µæ˜ å°„å¡«å……ï¼‰")
    st.caption("æŠŠå­¦æ ¡æ­£å¼æ¨¡æ¿ï¼ˆdocxï¼‰æ”¹æˆ {{å­—æ®µ}} å ä½ç¬¦ï¼Œå³å¯å¯¼å‡ºâ€œåƒå­¦æ ¡æ–‡ä»¶â€çš„ç‰ˆæœ¬ã€‚")

    if DocxTemplate is None:
        st.warning("å½“å‰ç¯å¢ƒç¼ºå°‘ docxtplã€‚è¦å¯ç”¨æ¨¡æ¿åŒ–å¯¼å‡ºï¼Œè¯·åœ¨ requirements.txt æ·»åŠ ï¼šdocxtpl jinja2 lxml")
        st.info("ä½ ä»å¯ä½¿ç”¨å„æ¨¡å—é‡Œçš„â€œç®€ç‰ˆDOCXå¯¼å‡ºâ€ã€‚")
        return

    meta = get_project_meta(project_id)
    sy = get_artifact(project_id, "syllabus")
    cal = get_artifact(project_id, "calendar")
    tp = get_artifact(project_id, "training_plan")
    rv = get_artifact(project_id, "review")
    rp = get_artifact(project_id, "report")
    mn = get_artifact(project_id, "manual")

    doc_kind = st.selectbox(
        "é€‰æ‹©è¦å¯¼å‡ºçš„æ­£å¼æ–‡ä»¶ç±»å‹",
        [
            "æ•™å­¦å¤§çº²ï¼ˆæ¨¡æ¿ï¼‰",
            "æ•™å­¦æ—¥å†ï¼ˆæ¨¡æ¿ï¼‰",
            "è¯•é¢˜å®¡æ ¸è¡¨ï¼ˆæ¨¡æ¿ï¼‰",
            "è¯„ä»·ä¾æ®åˆç†æ€§å®¡æ ¸è¡¨ï¼ˆæ¨¡æ¿ï¼‰",
            "è¯¾ç¨‹ç›®æ ‡è¾¾æˆè¯„ä»·æŠ¥å‘Šï¼ˆæ¨¡æ¿ï¼‰",
            "æˆè¯¾æ‰‹å†Œï¼ˆæ¨¡æ¿ï¼‰",
            "åŸ¹å…»æ–¹æ¡ˆï¼ˆæ¨¡æ¿ï¼‰",
        ],
    )

    tpl = st.file_uploader("ä¸Šä¼ å¯¹åº” DOCX æ¨¡æ¿ï¼ˆå¿…é¡»æ˜¯ .docxï¼‰", type=["docx"])
    if not tpl:
        st.info("è¯·å…ˆä¸Šä¼ æ¨¡æ¿ docxï¼ˆæ¨¡æ¿å†…ç”¨ {{å­—æ®µ}} æ ‡æ³¨è¦å¡«å……çš„ä½ç½®ï¼‰ã€‚")
        with st.expander("æ¨¡æ¿å­—æ®µç¤ºä¾‹ï¼ˆå¤åˆ¶åˆ° Word æ¨¡æ¿é‡Œï¼‰", expanded=False):
            st.code(
                """å¸¸ç”¨å­—æ®µï¼ˆä½ å¯æŒ‰éœ€å–ç”¨ï¼‰ï¼š
{{ major }}  {{ grade }}  {{ course_group }}
{{ course_name }} {{ credits }} {{ hours_total }}
{{ course_objectives }}   ï¼ˆå¤šè¡Œæ–‡æœ¬ï¼‰
{{ assessment_ratio }}

å¾ªç¯è¡¨æ ¼ï¼ˆdocxtplï¼‰ç¤ºä¾‹ï¼š
- COè¡¨å¾ªç¯ï¼š{% for x in co_table %} ... {{ x.id }} ... {{ x.desc }} ... {% endfor %}
- æ—¥å†å¾ªç¯ï¼š{% for r in calendar_rows %} ... {{ r.week }} ... {{ r.topic }} ... {% endfor %}
""",
                language="text",
            )
        return

    base_ctx = flatten_syllabus_to_context(meta, sy)
    base_ctx.update(flatten_calendar_to_context(cal))
    base_ctx.update(
        {
            "training_plan_text": (tp["content_md"] if tp else ""),
            "review_text": (rv["content_md"] if rv else ""),
            "report_text": (rp["content_md"] if rp else ""),
            "manual_text": (mn["content_md"] if mn else ""),
            "export_time": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
        }
    )

    st.subheader("å­—æ®µæ˜ å°„ï¼ˆå¯ä¿®æ”¹ï¼‰")
    c1, c2, c3 = st.columns(3)
    with c1:
        major = st.text_input("major", value=str(base_ctx.get("major", "")))
        grade = st.text_input("grade", value=str(base_ctx.get("grade", "")))
        course_group = st.text_input("course_group", value=str(base_ctx.get("course_group", "")))
    with c2:
        course_name = st.text_input("course_name", value=str(base_ctx.get("course_name", "")))
        credits = st.text_input("credits", value=str(base_ctx.get("credits", "")))
        hours_total = st.text_input("hours_total", value=str(base_ctx.get("hours_total", "")))
    with c3:
        assessment_ratio = st.text_input("assessment_ratio", value=str(base_ctx.get("assessment_ratio", "")))
        export_time = st.text_input("export_time", value=str(base_ctx.get("export_time", "")))

    course_objectives = st.text_area(
        "course_objectivesï¼ˆå¤šè¡Œæ–‡æœ¬ï¼‰",
        value=str(base_ctx.get("course_objectives", "")),
        height=120,
    )

    with st.expander("é«˜çº§å­—æ®µï¼šCOè¡¨ / æ—¥å†è¡¨ï¼ˆJSONï¼Œå¯ç”¨äºæ¨¡æ¿å¾ªç¯ï¼‰", expanded=False):
        co_json_str = st.text_area(
            "co_tableï¼ˆJSON æ•°ç»„ï¼‰",
            value=json.dumps(base_ctx.get("co_table", []), ensure_ascii=False, indent=2),
            height=180,
        )
        cal_json_str = st.text_area(
            "calendar_rowsï¼ˆJSON æ•°ç»„ï¼‰",
            value=json.dumps(base_ctx.get("calendar_rows", []), ensure_ascii=False, indent=2),
            height=180,
        )

    ctx = dict(base_ctx)
    ctx.update(
        {
            "major": major,
            "grade": grade,
            "course_group": course_group,
            "course_name": course_name,
            "credits": credits,
            "hours_total": hours_total,
            "assessment_ratio": assessment_ratio,
            "course_objectives": course_objectives,
            "export_time": export_time,
        }
    )

    try:
        ctx["co_table"] = json.loads(co_json_str) if co_json_str.strip() else []
    except Exception:
        st.warning("co_table JSON è§£æå¤±è´¥ï¼Œå·²å›é€€ä¸ºç©ºã€‚")
        ctx["co_table"] = []

    try:
        ctx["calendar_rows"] = json.loads(cal_json_str) if cal_json_str.strip() else []
    except Exception:
        st.warning("calendar_rows JSON è§£æå¤±è´¥ï¼Œå·²å›é€€ä¸ºç©ºã€‚")
        ctx["calendar_rows"] = []

    if st.button("ç”Ÿæˆ DOCXï¼ˆæ¨¡æ¿å¡«å……ï¼‰", type="primary"):
        try:
            out_bytes = docx_render_from_template(tpl.read(), ctx)
            fname = f"{doc_kind}-{course_name or 'è¯¾ç¨‹'}.docx"
            st.success("å·²ç”Ÿæˆã€‚")
            st.download_button(
                "ä¸‹è½½ DOCX",
                data=out_bytes,
                file_name=fname,
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            )
        except Exception as e:
            st.error(f"æ¨¡æ¿æ¸²æŸ“å¤±è´¥ï¼š{e}")


# ---------------------------
# é¡¶éƒ¨ä¸ä¾§è¾¹æ ï¼šé¡¹ç›® + æ¨¡å¼ + æ¨¡å—å¯¼èˆª
# ---------------------------
def topbar():
    st.markdown(
        """
<div class="topbar">
  <div class="title">æ•™å­¦æ™ºèƒ½ä½“å¹³å°</div>
  <div class="sub">åŸ¹å…»æ–¹æ¡ˆ â†’ å¤§çº² â†’ æ—¥å† â†’ æ•™æ¡ˆ â†’ è¯•å·/å®¡æ ¸ â†’ è¾¾æˆæŠ¥å‘Š â†’ æˆè¯¾æ‰‹å†Œ ï½œ æ”¯æŒä¸Šä¼ ã€ä¿®æ”¹ã€ç‰ˆæœ¬ä¸ä¾èµ–è¿½æº¯ï¼ˆVGEï¼‰</div>
</div>
""",
        unsafe_allow_html=True,
    )


# åˆå§‹åŒ– DB
ensure_db_schema()

topbar()
st.write("")

st.sidebar.markdown("## è¿è¡Œæ¨¡å¼")
run_mode = st.sidebar.radio("è¿è¡Œæ¨¡å¼", ["æ¼”ç¤ºæ¨¡å¼ï¼ˆæ— APIï¼‰", "åœ¨çº¿æ¨¡å¼ï¼ˆåƒé—®APIï¼‰"], index=0)
st.sidebar.caption("æ¼”ç¤ºæ¨¡å¼ä¸éœ€è¦ Keyï¼›åœ¨çº¿æ¨¡å¼è¯·åœ¨ Secrets ä¸­é…ç½® QWEN_API_KEYã€‚")

st.sidebar.markdown("## æ•°æ®åº“ç»´æŠ¤")
cA, cB = st.sidebar.columns(2)
with cA:
    if st.button("å¤‡ä»½(zip)"):
        b = make_backup_zip_bytes()
        st.sidebar.download_button("ä¸‹è½½å¤‡ä»½", data=b, file_name="teaching_agent_backup.zip")
with cB:
    restore = st.sidebar.file_uploader("è¿˜åŸ(zip)", type=["zip"], label_visibility="collapsed")
    if restore is not None:
        try:
            safe_extract_zip(restore.read(), ".")
            st.sidebar.success("å·²è¿˜åŸï¼ˆå»ºè®®åˆ·æ–°/é‡å¯åº”ç”¨ï¼‰")
            st.rerun()
        except Exception as e:
            st.sidebar.error(f"è¿˜åŸå¤±è´¥ï¼š{e}")

if st.sidebar.button("âš ï¸ é‡ç½®æ•°æ®åº“ï¼ˆåˆ é™¤ app.dbï¼‰"):
    try:
        for p in [DB_PATH, DB_PATH + "-shm", DB_PATH + "-wal"]:
            if os.path.exists(p):
                os.remove(p)
        st.sidebar.success("å·²åˆ é™¤æ•°æ®åº“æ–‡ä»¶ï¼Œå°†è‡ªåŠ¨é‡å»ºã€‚")
        st.rerun()
    except Exception as e:
        st.sidebar.error(f"é‡ç½®å¤±è´¥ï¼š{e}")


st.sidebar.markdown("## é¡¹ç›®ï¼ˆä¸“ä¸š/å¹´çº§/è¯¾ç¨‹ä½“ç³»ï¼‰")
projects = get_projects()
p_names = ["ï¼ˆæ–°å»ºé¡¹ç›®ï¼‰"] + [f"{pid} Â· {name}" for pid, name in projects]
p_sel = st.sidebar.selectbox("é€‰æ‹©é¡¹ç›®", p_names, index=0)

if p_sel == "ï¼ˆæ–°å»ºé¡¹ç›®ï¼‰":
    with st.sidebar.expander("åˆ›å»ºæ–°é¡¹ç›®", expanded=True):
        pname = st.text_input("é¡¹ç›®åç§°", value="ææ–™æˆå‹-æ•™è¯„ä¸€ä½“åŒ–ç¤ºä¾‹", key="new_pname")
        major = st.text_input("ä¸“ä¸š", value="ææ–™æˆå‹åŠæ§åˆ¶å·¥ç¨‹", key="new_major")
        grade = st.text_input("å¹´çº§", value="22", key="new_grade")
        course_group = st.text_input("è¯¾ç¨‹ä½“ç³»/æ–¹å‘", value="ææ–™æˆå‹-æ•°å€¼æ¨¡æ‹Ÿæ–¹å‘", key="new_group")
        if st.button("åˆ›å»ºé¡¹ç›®", type="primary"):
            pid = create_project(pname, {"major": major, "grade": grade, "course_group": course_group})
            st.success("å·²åˆ›å»ºé¡¹ç›®ï¼Œè¯·åœ¨ä¸‹æ‹‰ä¸­é€‰æ‹©å®ƒã€‚")
            st.rerun()
    project_id = None
else:
    project_id = int(p_sel.split("Â·")[0].strip())

st.sidebar.markdown("## åŠŸèƒ½æ¨¡å—")
module = st.sidebar.radio("å¯¼èˆª", [name for _, name in DOC_TYPES], index=1)
type_by_name = {name: t for t, name in DOC_TYPES}
current_type = type_by_name[module]


# ---------------------------
# ä¸»åŒºåŸŸï¼šæ¨¡å—é¡µé¢
# ---------------------------
def ensure_project():
    if project_id is None:
        st.info("è¯·å…ˆåœ¨å·¦ä¾§åˆ›å»ºå¹¶é€‰æ‹©ä¸€ä¸ªé¡¹ç›®ã€‚")
        st.stop()


def pick_parents_for(project_id: int, a_type: str) -> List[int]:
    req = DEP_RULES.get(a_type, [])
    parent_ids: List[int] = []
    for r in req:
        pa = get_artifact(project_id, r)
        if pa:
            parent_ids.append(pa["id"])
    if a_type == "manual":
        ev = get_artifact(project_id, "evidence")
        if ev:
            parent_ids.append(ev["id"])
    return parent_ids


def page_overview():
    ensure_project()
    st.markdown("### é¦–é¡µæ€»è§ˆ")
    arts = list_artifacts(project_id)
    if not arts:
        st.info("å½“å‰é¡¹ç›®è¿˜æ²¡æœ‰ä»»ä½•æ–‡æ¡£ã€‚å»ºè®®å…ˆä»â€œåŸ¹å…»æ–¹æ¡ˆï¼ˆåº•åº§ï¼‰â€å¼€å§‹ã€‚")
        return

    st.markdown('<div class="card">ğŸ“Œ å½“å‰é¡¹ç›®å·²æœ‰æ–‡æ¡£ï¼ˆæœ€è¿‘æ›´æ–°åœ¨å‰ï¼‰</div>', unsafe_allow_html=True)
    rows = []
    for a in arts:
        rows.append(
            {
                "ç±»å‹": type_label(a["type"]),
                "æ ‡é¢˜": a["title"],
                "Hash(å‰12)": a["hash"][:12],
                "æ›´æ–°æ—¶é—´": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(a["updated_at"])),
            }
        )
    st.dataframe(rows, use_container_width=True)

    st.markdown("---")
    st.markdown("### å¿«é€Ÿå…¥å£")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown('<div class="card"><b>â‘  ä»åº•åº§å¼€å§‹</b><br>å…ˆè¯†åˆ«/ç¡®è®¤åŸ¹å…»æ–¹æ¡ˆï¼Œå†ç”Ÿæˆå¤§çº²ã€‚</div>', unsafe_allow_html=True)
    with c2:
        st.markdown('<div class="card"><b>â‘¡ çœ‹ä¾èµ–é“¾</b><br>åˆ°â€œä¾èµ–å›¾å¯è§†åŒ–â€æŸ¥çœ‹å¯è¿½æº¯å…³ç³»ã€‚</div>', unsafe_allow_html=True)
    with c3:
        st.markdown('<div class="card"><b>â‘¢ æ­£å¼å¯¼å‡º</b><br>åˆ°â€œæ¨¡æ¿åŒ–DOCXå¯¼å‡ºâ€ç”¨å­¦æ ¡æ¨¡æ¿ç”Ÿæˆæ­£å¼æ–‡ä»¶ã€‚</div>', unsafe_allow_html=True)


# ============ NEWï¼šåŸ¹å…»æ–¹æ¡ˆè¯†åˆ«ç¡®è®¤ UI ============

def dot_from_edge_rows(edge_rows: List[Dict[str, str]]) -> str:
    lines = [
        "digraph G {",
        'rankdir="LR";',
        'node [shape=box, style="rounded,filled", fillcolor="#ffffff"];',
        'edge [color="#64748b"];'
    ]
    for e in edge_rows:
        s = (e.get("source") or "").strip()
        t = (e.get("target") or "").strip()
        if s and t:
            lines.append(f'"{s}" -> "{t}";')
    lines.append("}")
    return "\n".join(lines)


def render_table_editor(table_2d: List[List[Any]], key: str):
    """
    è¿”å›ç”¨æˆ·ç¼–è¾‘åçš„ table_2d
    """
    if pd is None:
        s = st.text_area("è¡¨æ ¼ï¼ˆJSONï¼Œå¯ç¼–è¾‘ï¼‰", value=json.dumps(table_2d, ensure_ascii=False, indent=2), height=220, key=key)
        try:
            return json.loads(s) if s.strip() else table_2d
        except Exception:
            st.warning("JSON è§£æå¤±è´¥ï¼Œå·²ä¿ç•™åŸè¡¨ã€‚")
            return table_2d

    df = table_to_dataframe(table_2d)
    if df is None:
        return table_2d
    edited = st.data_editor(df, use_container_width=True, num_rows="dynamic", key=key)
    # è½¬å› 2dï¼ˆå«è¡¨å¤´ï¼‰
    new_table = [list(edited.columns)]
    for _, row in edited.iterrows():
        new_table.append([("" if pd.isna(x) else str(x)) for x in list(row.values)])
    return new_table


def page_training_plan():
    ensure_project()
    a = get_artifact(project_id, "training_plan")
    render_depbar(project_id, "training_plan")

    st.markdown("### åŸ¹å…»æ–¹æ¡ˆï¼ˆåº•åº§ï¼‰")
    st.caption("æ¨èï¼šä¸Šä¼ åŸ¹å…»æ–¹æ¡ˆ â†’ è‡ªåŠ¨è¯†åˆ« â†’ è¯†åˆ«æ¸…å•ç¡®è®¤/ä¿®æ­£ â†’ ä¿å­˜ï¼ˆç»“æ„åŒ–åº•åº§ï¼‰ã€‚")

    tab1, tab2, tab3, tab4 = st.tabs(["ç”Ÿæˆ/ä¸Šä¼ &è¯†åˆ«ç¡®è®¤", "é¢„è§ˆ", "ç¼–è¾‘", "ç‰ˆæœ¬/å¯¼å‡º"])

    with tab1:
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown("#### æ–¹å¼Aï¼šä¸€é”®ç”Ÿæˆï¼ˆæ¼”ç¤º/å¿«é€Ÿï¼‰")
            major = st.text_input("ä¸“ä¸š", value="ææ–™æˆå‹åŠæ§åˆ¶å·¥ç¨‹", key="tp_major")
            grade = st.text_input("å¹´çº§", value="22", key="tp_grade")
            group = st.text_input("è¯¾ç¨‹ä½“ç³»/æ–¹å‘", value="ææ–™æˆå‹-æ•°å€¼æ¨¡æ‹Ÿæ–¹å‘", key="tp_group")
            if st.button("ç”ŸæˆåŸ¹å…»æ–¹æ¡ˆå¹¶ä¿å­˜", type="primary"):
                md = template_training_plan(major, grade, group)
                a = upsert_artifact(
                    project_id,
                    "training_plan",
                    f"{grade}çº§ã€Š{major}ã€‹åŸ¹å…»æ–¹æ¡ˆ",
                    md,
                    {"major": major, "grade": grade, "course_group": group, "confirmed": True},
                    [],
                    note="generate",
                )
                st.success("å·²ä¿å­˜åŸ¹å…»æ–¹æ¡ˆï¼ˆå¯ä½œä¸ºåç»­æ–‡ä»¶ä¾èµ–åº•åº§ï¼‰")
                st.rerun()

        with col2:
            st.markdown("#### æ–¹å¼Bï¼šä¸Šä¼ å·²æœ‰åŸ¹å…»æ–¹æ¡ˆï¼ˆè¯†åˆ«â†’ç¡®è®¤â†’ä¿å­˜ï¼‰")
            up = st.file_uploader("ä¸Šä¼ åŸ¹å…»æ–¹æ¡ˆæ–‡ä»¶", type=["pdf", "doc", "docx", "txt"], key="tp_upload")

            use_ai_fix = st.checkbox("ï¼ˆå¯é€‰ï¼‰ç”¨åƒé—®å¯¹è¯†åˆ«ç»“æœåšçº é”™/è¡¥å…¨", value=False, disabled=not run_mode.startswith("åœ¨çº¿"))
            if up is not None and st.button("å¼€å§‹è¯†åˆ«ï¼ˆç”Ÿæˆæ¸…å•ï¼‰", key="tp_start_extract"):
                txt = extract_text_from_upload(up)
                tables_pack = extract_pdf_tables(up) if (up.name.lower().endswith(".pdf")) else []
                checklist = extract_training_plan_checklist(txt)
                matrix_guess = guess_course_support_matrix(tables_pack)

                st.session_state["tp_extract"] = {
                    "source": up.name,
                    "text": txt,
                    "tables_pack": tables_pack,
                    "checklist": checklist,
                    "matrix_guess": matrix_guess,
                    # åˆå§‹è¾¹è¡¨ï¼šç©ºï¼Œé ç”¨æˆ·è¡¥
                    "course_edges": [
                        {"source": "å…ˆä¿®è¯¾ç¨‹A", "target": "åç»­è¯¾ç¨‹B"},
                    ],
                }
                st.success("å·²ç”Ÿæˆè¯†åˆ«æ¸…å•ï¼Œè¯·åœ¨ä¸‹æ–¹ç¡®è®¤/ä¿®æ­£ï¼Œç„¶åå†ä¿å­˜ã€‚")

            if "tp_extract" in st.session_state:
                ex = st.session_state["tp_extract"]
                st.markdown("---")
                st.markdown("### è¯†åˆ«æ¸…å•ï¼ˆè¯·ç¡®è®¤/ä¿®æ­£ï¼‰")
                st.caption("åŸåˆ™ï¼šç³»ç»Ÿå…ˆå°½åŠ›æŠ½å–ï¼Œæœ€ç»ˆä»¥ä½ çš„ç¡®è®¤ç»“æœä¸ºå‡†ï¼›ç¡®è®¤åçš„ç»“æ„åŒ–ä¿¡æ¯ä¼šç”¨äºåç»­å¤§çº²è‡ªåŠ¨å¡«å……ã€‚")

                ck = ex["checklist"]
                colA, colB, colC = st.columns(3)
                with colA:
                    major2 = st.text_input("ä¸“ä¸šï¼ˆå¯ä¿®æ­£ï¼‰", value=ck.get("major_guess", ""), key="tp_major_fix")
                    grade2 = st.text_input("å¹´çº§ï¼ˆå¯ä¿®æ­£ï¼‰", value=ck.get("grade_guess", ""), key="tp_grade_fix")
                with colB:
                    course_group2 = st.text_input("è¯¾ç¨‹ä½“ç³»/æ–¹å‘ï¼ˆå¯è¡¥å……ï¼‰", value="", key="tp_group_fix")
                    confirmed_flag = st.checkbox("æˆ‘å·²ç¡®è®¤ä»¥ä¸Šä¿¡æ¯å¤§ä½“æ­£ç¡®", value=False, key="tp_confirm_flag")
                with colC:
                    st.markdown("**è¯†åˆ«æ¥æº**")
                    st.code(ex.get("source", ""), language="text")

                st.markdown("#### 1) åŸ¹å…»ç›®æ ‡ï¼ˆå¯ç¼–è¾‘ï¼‰")
                goals_init = ck.get("goals_guess", []) or []
                goals_text = st.text_area(
                    "æ¯è¡Œä¸€ä¸ªç›®æ ‡ï¼ˆå¯å¢åˆ /æ”¹å†™ï¼‰",
                    value="\n".join(goals_init) if goals_init else "",
                    height=140,
                    key="tp_goals_edit",
                )
                goals_final = [x.strip() for x in goals_text.splitlines() if x.strip()]

                st.markdown("#### 2) æ¯•ä¸šè¦æ±‚ï¼ˆå¯ç¼–è¾‘ï¼‰")
                out_init = ck.get("outcomes_guess", []) or []
                if pd is not None:
                    df_out = pd.DataFrame(out_init) if out_init else pd.DataFrame(columns=["no", "name"])
                    df_out2 = st.data_editor(df_out, use_container_width=True, num_rows="dynamic", key="tp_out_editor")
                    outcomes_final = [{"no": str(r["no"]), "name": str(r["name"])} for _, r in df_out2.iterrows() if str(r.get("no","")).strip()]
                else:
                    outcomes_json = st.text_area(
                        "æ¯•ä¸šè¦æ±‚ JSONï¼ˆæ•°ç»„ï¼‰",
                        value=json.dumps(out_init, ensure_ascii=False, indent=2),
                        height=160,
                        key="tp_out_json",
                    )
                    try:
                        outcomes_final = json.loads(outcomes_json) if outcomes_json.strip() else []
                    except Exception:
                        outcomes_final = out_init

                st.markdown("#### 3) è¯¾ç¨‹-æ¯•ä¸šè¦æ±‚æ”¯æ’‘çŸ©é˜µï¼ˆè¡¨æ ¼â†’å¯ç¼–è¾‘ï¼‰")
                mg = ex["matrix_guess"]
                st.info(mg.get("hint", ""))
                best = mg.get("best_table", None)

                # ç¼–è¾‘â€œç–‘ä¼¼çŸ©é˜µè¡¨â€
                edited_best_table = None
                if best and best.get("table"):
                    st.markdown(f"**ç–‘ä¼¼çŸ©é˜µè¡¨ï¼ˆç¬¬ {best.get('page')} é¡µï¼‰**ï¼šè¯·ç›´æ¥æ”¹è¡¨æ ¼å†…å®¹ï¼ˆåŒ…æ‹¬è¡¨å¤´ï¼‰")
                    edited_best_table = render_table_editor(best["table"], key="tp_matrix_table_editor")
                else:
                    st.warning("æœªæŠ½åˆ°ç–‘ä¼¼æ”¯æ’‘çŸ©é˜µè¡¨æ ¼ã€‚ä½ å¯ä»¥ï¼š1) åœ¨ PDF æ›´æ¸…æ™°æ—¶å†è¯•ï¼›2) ä¸‹é¢æ‰‹å·¥å½•å…¥æœ¬è¯¾ç¨‹æ”¯æ’‘ç‚¹ã€‚")

                st.markdown("#### 4) è¯¾ç¨‹å…³ç³»å›¾ï¼ˆè¾¹è¡¨â†’å¯ç¼–è¾‘ + Graphviz é¢„è§ˆï¼‰")
                st.caption("å¾ˆå¤š PDF å¯¼å›¾æ˜¯å›¾ç‰‡ï¼Œä¸æ˜“è‡ªåŠ¨è¿˜åŸã€‚è¿™é‡Œç”¨å¯ç¼–è¾‘â€œè¾¹è¡¨â€æ›´å¯é ï¼šä½ åªéœ€å¡«â€œå…ˆä¿®â†’åç»­â€ã€‚")

                edges = ex.get("course_edges", [{"source": "", "target": ""}])
                if pd is not None:
                    df_e = pd.DataFrame(edges)
                    df_e2 = st.data_editor(df_e, use_container_width=True, num_rows="dynamic", key="tp_edges_editor")
                    edges_final = [{"source": str(r["source"]), "target": str(r["target"])} for _, r in df_e2.iterrows()]
                else:
                    edges_json = st.text_area(
                        "è¾¹è¡¨ JSONï¼ˆæ•°ç»„ï¼‰",
                        value=json.dumps(edges, ensure_ascii=False, indent=2),
                        height=160,
                        key="tp_edges_json",
                    )
                    try:
                        edges_final = json.loads(edges_json) if edges_json.strip() else edges
                    except Exception:
                        edges_final = edges

                dot = dot_from_edge_rows(edges_final)
                st.graphviz_chart(dot)

                st.markdown("#### 5) ä»æ”¯æ’‘çŸ©é˜µä¸­æå–â€œæŸé—¨è¯¾ç¨‹çš„æ”¯æ’‘æŒ‡æ ‡ç‚¹â€ï¼ˆç”¨äºå¤§çº²é»˜è®¤å¡«å……ï¼‰")
                st.caption("å¦‚æœä½ åœ¨ä¸Šé¢çš„çŸ©é˜µè¡¨é‡Œèƒ½çœ‹åˆ°è¯¾ç¨‹è¡Œï¼Œå¯ä»¥åœ¨è¿™é‡Œé€‰æ‹©è¯¾ç¨‹å¹¶å‹¾é€‰æ”¯æ’‘ç‚¹ã€‚")

                # ç®€å•ï¼šè®©ç”¨æˆ·æ‰‹å·¥å½•å…¥å½“å‰é¡¹ç›®â€œé»˜è®¤è¯¾ç¨‹â€çš„æ”¯æ’‘ç‚¹ï¼ˆåé¢å¤§çº²é¡µå¯é€‰è¯¾ç¨‹åå†æ˜ å°„ï¼‰
                support_points_text = st.text_input(
                    "å½“å‰è¦é‡ç‚¹æ”¯æŒçš„è¯¾ç¨‹æŒ‡æ ‡ç‚¹ï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚ 1.1,2.3,3.2ï¼‰",
                    value="",
                    key="tp_support_points_text",
                )
                support_points = [x.strip() for x in re.split(r"[ï¼Œ,;\s]+", support_points_text) if x.strip()]

                st.markdown("---")
                if st.button("âœ… ç¡®è®¤å¹¶ä¿å­˜ä¸ºåŸ¹å…»æ–¹æ¡ˆåº•åº§", type="primary", disabled=not confirmed_flag):
                    # å¯é€‰ï¼šç”¨åƒé—®åšä¸€æ¬¡â€œç»“æ„è¡¥å…¨â€ï¼ˆåªå¯¹æ–‡æœ¬ï¼Œä¸å¼ºä¾èµ–ï¼‰
                    text_final = ex.get("text", "") or ""
                    if use_ai_fix and get_qwen_key():
                        try:
                            sys = "ä½ æ˜¯é«˜æ ¡åŸ¹å…»æ–¹æ¡ˆæŠ½å–ä¸æ ¡æ­£åŠ©æ‰‹ã€‚è¾“å‡ºå¿…é¡»æ˜¯JSON+ç®€çŸ­è¯´æ˜ã€‚"
                            user = f"""
è¯·å¯¹ä»¥ä¸‹åŸ¹å…»æ–¹æ¡ˆæ–‡æœ¬åšç»“æ„åŒ–æŠ½å–å¹¶æ ¡æ­£ï¼Œé‡ç‚¹æŠ½å–ï¼šåŸ¹å…»ç›®æ ‡ã€æ¯•ä¸šè¦æ±‚åˆ—è¡¨ï¼ˆå«ç¼–å·ä¸åç§°ï¼‰ã€ä»»ä½•å‡ºç°çš„â€œè¯¾ç¨‹-æ¯•ä¸šè¦æ±‚æ”¯æ’‘å…³ç³»â€æç¤ºã€‚
è¿”å›JSONå­—æ®µï¼šgoals(list[str]), outcomes(list[{{no,name}}]), notes(str)ã€‚
æ–‡æœ¬ï¼ˆæˆªæ–­ï¼‰ï¼š{text_final[:8000]}
"""
                            out = qwen_chat([{"role": "system", "content": sys}, {"role": "user", "content": user}], temperature=0.2, max_tokens=1200)
                            m = re.search(r"\{[\s\S]*\}", out)
                            if m:
                                js_ai = json.loads(m.group(0))
                                # ä»…åœ¨ç”¨æˆ·æœªå¡«æ—¶è¡¥å……
                                if not goals_final and js_ai.get("goals"):
                                    goals_final = js_ai.get("goals", [])
                                if (not outcomes_final) and js_ai.get("outcomes"):
                                    outcomes_final = js_ai.get("outcomes", [])
                        except Exception as e:
                            st.warning(f"AIæ ¡æ­£å¤±è´¥ï¼ˆå¿½ç•¥ï¼Œä¸å½±å“ä¿å­˜ï¼‰ï¼š{e}")

                    # ç»„è£…ç»“æ„åŒ– content_jsonï¼ˆç¡®è®¤ç‰ˆï¼‰
                    content_json = {
                        "source": ex.get("source", ""),
                        "confirmed": True,
                        "major": major2,
                        "grade": grade2,
                        "course_group": course_group2,
                        "goals": goals_final,
                        "outcomes": outcomes_final,
                        "support_points_default": support_points,  # é»˜è®¤/ç¤ºä¾‹ï¼šå¯ç”¨äºå¤§çº²
                        "support_matrix_best_table": {
                            "page": best.get("page") if best else None,
                            "table": edited_best_table if edited_best_table is not None else (best.get("table") if best else None),
                        },
                        "course_edges": edges_final,
                    }

                    # ç”Ÿæˆä¸€ä»½æ›´â€œå¯è¯»â€çš„ mdï¼ˆæ–¹ä¾¿é¢„è§ˆï¼‰
                    md = f"# åŸ¹å…»æ–¹æ¡ˆï¼ˆä¸Šä¼ è¯†åˆ«-å·²ç¡®è®¤ï¼‰\n\n"
                    md += f"- ä¸“ä¸šï¼š{major2}\n- å¹´çº§ï¼š{grade2}\n- è¯¾ç¨‹ä½“ç³»/æ–¹å‘ï¼š{course_group2}\n\n"
                    md += "## ä¸€ã€åŸ¹å…»ç›®æ ‡ï¼ˆç¡®è®¤ç‰ˆï¼‰\n" + ("\n".join([f"- {x}" for x in goals_final]) if goals_final else "- ï¼ˆæœªå¡«ï¼‰") + "\n\n"
                    md += "## äºŒã€æ¯•ä¸šè¦æ±‚ï¼ˆç¡®è®¤ç‰ˆï¼‰\n" + ("\n".join([f"- {o.get('no','')}. {o.get('name','')}" for o in outcomes_final]) if outcomes_final else "- ï¼ˆæœªå¡«ï¼‰") + "\n\n"
                    md += "## ä¸‰ã€è¯¾ç¨‹æ”¯æ’‘æŒ‡æ ‡ç‚¹ï¼ˆé»˜è®¤/ç¤ºä¾‹ï¼‰\n" + (("ã€".join(support_points)) if support_points else "ï¼ˆæœªå¡«ï¼‰") + "\n\n"
                    md += "## å››ã€åŸå§‹æŠ½å–æ–‡æœ¬ï¼ˆä¾›è¿½æº¯ï¼‰\n\n" + (ex.get("text","")[:20000] if ex.get("text") else "")

                    title = f"åŸ¹å…»æ–¹æ¡ˆï¼ˆç¡®è®¤ç‰ˆï¼‰-{ex.get('source','ä¸Šä¼ ')}"
                    a2 = upsert_artifact(project_id, "training_plan", title, md, content_json, [], note="upload-confirm")
                    st.success("å·²ä¿å­˜â€œç¡®è®¤ç‰ˆåŸ¹å…»æ–¹æ¡ˆåº•åº§â€ã€‚åç»­ç”Ÿæˆå¤§çº²ä¼šä¼˜å…ˆä½¿ç”¨ç»“æ„åŒ–å­—æ®µã€‚")
                    st.session_state.pop("tp_extract", None)
                    st.rerun()

                if st.button("æ¸…é™¤æœ¬æ¬¡è¯†åˆ«ç»“æœï¼ˆä¸ä¿å­˜ï¼‰"):
                    st.session_state.pop("tp_extract", None)
                    st.info("å·²æ¸…é™¤ã€‚")

    with tab2:
        if not a:
            st.info("æš‚æ— åŸ¹å…»æ–¹æ¡ˆã€‚è¯·å…ˆç”Ÿæˆæˆ–ä¸Šä¼ å¹¶ç¡®è®¤ã€‚")
        else:
            artifact_toolbar(a)
            render_doc_preview(a["content_md"])
            st.markdown("#### ç»“æ„åŒ–ï¼ˆç¡®è®¤ç‰ˆï¼‰JSON")
            st.json(a.get("content_json") or {})

            # é¢å¤–å±•ç¤ºï¼šè¯¾ç¨‹å…³ç³»å›¾
            cj = a.get("content_json") or {}
            edges = cj.get("course_edges", []) or []
            if edges:
                st.markdown("#### è¯¾ç¨‹å…³ç³»å›¾ï¼ˆGraphvizï¼‰")
                st.graphviz_chart(dot_from_edge_rows(edges))

    with tab3:
        if not a:
            st.info("æš‚æ— åŸ¹å…»æ–¹æ¡ˆã€‚è¯·å…ˆç”Ÿæˆæˆ–ä¸Šä¼ ã€‚")
        else:
            edited = md_textarea("åœ¨çº¿ç¼–è¾‘åŸ¹å…»æ–¹æ¡ˆï¼ˆæ”¯æŒç›´æ¥ä¿®æ”¹ï¼‰", a["content_md"], key="tp_edit")
            note = st.text_input("ä¿å­˜è¯´æ˜ï¼ˆå¯é€‰ï¼‰", value="edit", key="tp_note")
            if st.button("ä¿å­˜ä¿®æ”¹ï¼ˆç”Ÿæˆæ–°ç‰ˆæœ¬ï¼‰", type="primary", key="tp_save"):
                a2 = upsert_artifact(project_id, "training_plan", a["title"], edited, a["content_json"], [], note=note)
                st.success("å·²ä¿å­˜ã€‚åç»­ä¾èµ–æ–‡ä»¶å°†å¼•ç”¨æ›´æ–°åçš„åŸ¹å…»æ–¹æ¡ˆã€‚")
                st.rerun()

    with tab4:
        if not a:
            st.info("æš‚æ— åŸ¹å…»æ–¹æ¡ˆã€‚")
        else:
            vers = get_versions(a["id"])
            st.markdown("#### ç‰ˆæœ¬è®°å½•")
            st.dataframe(vers if vers else [], use_container_width=True)
            st.markdown("#### å¯¼å‡ºï¼ˆç®€ç‰ˆï¼‰")
            docx_bytes = export_docx_bytes_plaintext(a["content_md"])
            if docx_bytes:
                st.download_button("ä¸‹è½½ DOCXï¼ˆç®€ç‰ˆå¯¼å‡ºï¼‰", data=docx_bytes, file_name="åŸ¹å…»æ–¹æ¡ˆ.docx")
            else:
                st.warning("å½“å‰ç¯å¢ƒç¼ºå°‘ python-docxï¼Œæ— æ³•å¯¼å‡º DOCXã€‚")


def page_syllabus():
    ensure_project()
    render_depbar(project_id, "syllabus")
    tp = get_artifact(project_id, "training_plan")
    a = get_artifact(project_id, "syllabus")

    st.markdown("### è¯¾ç¨‹æ•™å­¦å¤§çº²ï¼šä¸¥æ ¼ä¾èµ–åŸ¹å…»æ–¹æ¡ˆï¼ˆå¯éªŒè¯ï¼‰")
    st.caption("å¢å¼ºï¼šè‹¥åŸ¹å…»æ–¹æ¡ˆå·²ç¡®è®¤ç»“æ„åŒ–æ”¯æ’‘ç‚¹ï¼Œå°†è‡ªåŠ¨å¡«å……åˆ°å¤§çº²ã€‚å¹¶æ”¯æŒä¸Šä¼ å·²æœ‰å¤§çº²åšå¯¹é½æ£€æŸ¥ï¼ˆç®€ç‰ˆï¼‰ã€‚")

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["å¡«å†™/ç”Ÿæˆ", "ä¸Šä¼ å·²æœ‰å¤§çº²&å¯¹é½æ£€æŸ¥", "é¢„è§ˆ", "ç¼–è¾‘", "ç‰ˆæœ¬/å¯¼å‡º"])

    with tab1:
        if not tp:
            st.warning("ç¼ºå°‘ä¸Šæ¸¸ä¾èµ–ï¼šåŸ¹å…»æ–¹æ¡ˆã€‚è¯·å…ˆåˆ°â€œåŸ¹å…»æ–¹æ¡ˆï¼ˆåº•åº§ï¼‰â€æ¨¡å—ä¸Šä¼ å¹¶ç¡®è®¤ã€‚")

        course_name = st.text_input("è¯¾ç¨‹åç§°", value="æ•°å€¼æ¨¡æ‹Ÿåœ¨ææ–™æˆå‹ä¸­çš„åº”ç”¨", key="sy_course")
        credits = st.number_input("å­¦åˆ†", min_value=0.5, max_value=10.0, value=2.0, step=0.5)
        hours_total = st.number_input("æ€»å­¦æ—¶", min_value=8, max_value=128, value=32, step=2)

        tp_json = (tp.get("content_json") if tp else {}) or {}
        default_support = tp_json.get("support_points_default", []) or []
        support_points_text = st.text_input(
            "æœ¬è¯¾ç¨‹æ”¯æ’‘çš„æ¯•ä¸šè¦æ±‚æŒ‡æ ‡ç‚¹ï¼ˆå¯æ”¹ï¼Œé€—å·åˆ†éš”ï¼‰",
            value=",".join(default_support) if default_support else "",
            key="sy_support_points",
        )
        support_points = [x.strip() for x in re.split(r"[ï¼Œ,;\s]+", support_points_text) if x.strip()]

        extra = st.text_area(
            "å¯¹å¤§çº²çš„è¡¥å……è¦æ±‚ï¼ˆè€ƒæ ¸æ¯”ä¾‹/æ•™å­¦æ–¹æ³•/å®è·µè¦æ±‚ç­‰ï¼‰",
            value="è¯¾ç¨‹ç›®æ ‡3-5ä¸ªï¼›å¹³æ—¶30%+å¤§ä½œä¸š20%+æœŸæœ«50%ï¼›å¼ºè°ƒå·¥ç¨‹è¡¨è¾¾ä¸æ¡ˆä¾‹ï¼›å†™æ˜CO-æ¯•ä¸šè¦æ±‚æ˜ å°„ã€‚",
            height=120,
        )

        use_ai = st.checkbox("ä½¿ç”¨åƒé—®ç”Ÿæˆæ›´å®Œæ•´çš„å¤§çº²ï¼ˆéœ€è¦QWEN_API_KEYï¼‰", value=run_mode.startswith("åœ¨çº¿"))
        if st.button("ç”Ÿæˆå¹¶ä¿å­˜æ•™å­¦å¤§çº²ï¼ˆJSON+å¯è¯»é¢„è§ˆï¼‰", type="primary"):
            if not tp:
                st.error("è¯·å…ˆæä¾›åŸ¹å…»æ–¹æ¡ˆã€‚")
            else:
                tp_text = tp["content_md"]
                if use_ai and get_qwen_key():
                    sys = "ä½ æ˜¯é«˜æ ¡æ•™å­¦æ–‡ä»¶æ’°å†™ä¸“å®¶ï¼Œè¾“å‡ºå¿…é¡»è§„èŒƒã€å¯è½åœ°ã€‚"
                    user = f"""è¯·ä¾æ®ä»¥ä¸‹åŸ¹å…»æ–¹æ¡ˆï¼Œä¸ºè¯¾ç¨‹ã€Š{course_name}ã€‹æ’°å†™æ•™å­¦å¤§çº²ã€‚
è¦æ±‚ï¼šç»™å‡ºè¯¾ç¨‹ä¿¡æ¯ã€è¯¾ç¨‹ç›®æ ‡CO(3-5)ã€CO-æ¯•ä¸šè¦æ±‚æ˜ å°„ã€å­¦æ—¶åˆ†é…ã€æ•™å­¦æ–¹æ³•ã€è€ƒæ ¸æ¯”ä¾‹ã€å®è·µè¦æ±‚ã€‚
å¹¶æ˜ç¡®å†™å‡ºæœ¬è¯¾ç¨‹æ”¯æ’‘çš„æ¯•ä¸šè¦æ±‚æŒ‡æ ‡ç‚¹ï¼š{support_points}
è¡¥å……è¦æ±‚ï¼š{extra}
åŸ¹å…»æ–¹æ¡ˆæ–‡æœ¬ï¼š
{tp_text[:5000]}
è¾“å‡ºï¼šå…ˆè¾“å‡º JSONï¼ˆå­—æ®µï¼šcourse_name, credits, hours_total, support_points, CO[{id,desc,map_to}], assessment, outlineï¼‰ï¼Œç„¶åè¾“å‡ºä¸€ä»½Markdownå¤§çº²ã€‚
"""
                    try:
                        out = qwen_chat(
                            [{"role": "system", "content": sys}, {"role": "user", "content": user}],
                            model=DEFAULT_TEXT_MODEL,
                            temperature=0.2,
                            max_tokens=1600,
                        )
                        m = re.search(r"\{[\s\S]*\}", out)
                        js = {}
                        if m:
                            try:
                                js = json.loads(m.group(0))
                            except Exception:
                                js = {}
                        md = out
                    except Exception as e:
                        st.warning(f"AIç”Ÿæˆå¤±è´¥ï¼Œå·²å›é€€åˆ°æ¨¡æ¿ç”Ÿæˆï¼š{e}")
                        md, js = template_syllabus(course_name, int(hours_total), float(credits), extra, tp_text, support_points)
                else:
                    md, js = template_syllabus(course_name, int(hours_total), float(credits), extra, tp_text, support_points)

                parents = [tp["id"]]
                a2 = upsert_artifact(project_id, "syllabus", f"ã€Š{course_name}ã€‹æ•™å­¦å¤§çº²", md, js, parents, note="generate")
                st.success("å·²ä¿å­˜æ•™å­¦å¤§çº²ï¼ˆåç»­æ—¥å†/æ•™æ¡ˆ/è¯•å·ç­‰å°†ä¾èµ–å®ƒï¼‰")
                st.rerun()

    with tab2:
        if not tp:
            st.warning("è¯·å…ˆæœ‰åŸ¹å…»æ–¹æ¡ˆï¼ˆç¡®è®¤ç‰ˆæ›´å¥½ï¼‰ï¼Œå¦åˆ™å¯¹é½æ£€æŸ¥æ„ä¹‰ä¸å¤§ã€‚")
        st.markdown("#### ä¸Šä¼ å·²æœ‰æ•™å­¦å¤§çº²ï¼ˆPDF/DOC/DOCX/TXTï¼‰")
        up2 = st.file_uploader("ä¸Šä¼ å·²æœ‰è¯¾ç¨‹æ•™å­¦å¤§çº²", type=["pdf", "doc", "docx", "txt"], key="sy_upload_existing")
        if up2 is not None and st.button("åˆ†æå¹¶ç»™å‡ºå¯¹é½æ£€æŸ¥ï¼ˆç®€ç‰ˆï¼‰", key="sy_check_align"):
            sy_txt = extract_text_from_upload(up2)
            tp_json = (tp.get("content_json") if tp else {}) or {}
            tp_outcomes = tp_json.get("outcomes", []) or []
            tp_support_default = tp_json.get("support_points_default", []) or []

            # ç®€å•å¯¹é½ï¼šæ˜¯å¦åŒ…å«é»˜è®¤æ”¯æ’‘ç‚¹å­—ç¬¦ä¸²
            missing = []
            for p in tp_support_default:
                if p and (p not in sy_txt):
                    missing.append(p)

            st.markdown("### å¯¹é½æ£€æŸ¥ç»“æœï¼ˆç®€ç‰ˆï¼‰")
            st.write(f"- å¤§çº²æ–‡ä»¶ï¼š{up2.name}")
            st.write(f"- åŸ¹å…»æ–¹æ¡ˆé»˜è®¤æ”¯æ’‘ç‚¹ï¼š{', '.join(tp_support_default) if tp_support_default else 'ï¼ˆæœªè®¾ç½®ï¼‰'}")
            if tp_support_default and missing:
                st.warning("å¤§çº²æ–‡æœ¬ä¸­æœªæ˜æ˜¾å‡ºç°ä»¥ä¸‹æ”¯æ’‘æŒ‡æ ‡ç‚¹ï¼ˆå¯èƒ½ç¼ºå¤±æˆ–è¡¨è¿°ä¸ä¸€è‡´ï¼‰ï¼š")
                st.write(", ".join(missing))
            else:
                st.success("å¤§çº²ä¸­å·²åŒ…å«/æˆ–æ— éœ€æ£€æŸ¥é»˜è®¤æ”¯æ’‘ç‚¹ã€‚")

            # å»ºè®®ï¼ˆæ¼”ç¤ºç‰ˆï¼‰ï¼šåœ¨çº¿æ¨¡å¼å¯è®© LLM ç»™ä¿®è®¢å»ºè®®
            if run_mode.startswith("åœ¨çº¿") and get_qwen_key():
                if st.button("ç”¨åƒé—®ç»™å‡ºä¿®è®¢å»ºè®®ï¼ˆå¯é€‰ï¼‰", key="sy_llm_suggest"):
                    sys = "ä½ æ˜¯æ•™å­¦å¤§çº²åˆè§„å®¡æ ¡ä¸“å®¶ã€‚è¾“å‡ºç®€æ˜çš„å·®å¼‚æ¸…å•ä¸å»ºè®®æ”¹å†™æ®µè½ã€‚"
                    user = f"""
è¯·åŸºäºåŸ¹å…»æ–¹æ¡ˆæ¯•ä¸šè¦æ±‚ï¼ˆå¯èƒ½å«æŒ‡æ ‡ç‚¹ï¼‰ä¸è¯¥æ•™å­¦å¤§çº²æ–‡æœ¬ï¼Œæ£€æŸ¥ä¸€è‡´æ€§ä¸ä¸è¶³ï¼Œå¹¶ç»™å‡ºå¯æ‰§è¡Œçš„ä¿®è®¢å»ºè®®ã€‚
åŸ¹å…»æ–¹æ¡ˆï¼ˆç»“æ„åŒ–æ‘˜è¦ï¼‰ï¼š{json.dumps(tp_json, ensure_ascii=False)[:6000]}
æ•™å­¦å¤§çº²æ–‡æœ¬ï¼ˆæˆªæ–­ï¼‰ï¼š{sy_txt[:8000]}
è¾“å‡ºï¼š1) å·®å¼‚æ¸…å•ï¼ˆæ¡ç›®åŒ–ï¼‰ 2) å»ºè®®ä¿®è®¢æ®µè½ï¼ˆå¯ç›´æ¥æ›¿æ¢ï¼‰ 3) ä¸€å¥è¯æ€»ä½“è¯„ä»·ã€‚
"""
                    try:
                        out = qwen_chat([{"role":"system","content":sys},{"role":"user","content":user}], temperature=0.2, max_tokens=1200)
                        st.markdown(out)
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")

            with st.expander("æŸ¥çœ‹å¤§çº²æŠ½å–æ–‡æœ¬ï¼ˆæˆªæ–­ï¼‰", expanded=False):
                st.code(sy_txt[:12000], language="text")

    with tab3:
        if not a:
            st.info("æš‚æ— æ•™å­¦å¤§çº²ã€‚è¯·åœ¨â€œå¡«å†™/ç”Ÿæˆâ€ä¸­ç”Ÿæˆå¹¶ä¿å­˜ã€‚")
        else:
            artifact_toolbar(a)
            js = a["content_json"] or {}
            st.markdown('<div class="card"><b>ç»“æ„åŒ–æ‘˜è¦</b></div>', unsafe_allow_html=True)
            c1, c2, c3 = st.columns(3)
            c1.metric("è¯¾ç¨‹", js.get("course_name", "-"))
            c2.metric("å­¦åˆ†", js.get("credits", "-"))
            c3.metric("æ€»å­¦æ—¶", js.get("hours_total", "-"))
            st.markdown("#### æ”¯æ’‘æŒ‡æ ‡ç‚¹")
            st.write("ã€".join(js.get("support_points", []) or []) or "ï¼ˆæœªå¡«ï¼‰")
            st.markdown("#### å¤§çº²æ­£æ–‡")
            render_doc_preview(a["content_md"])

    with tab4:
        if not a:
            st.info("æš‚æ— æ•™å­¦å¤§çº²ã€‚")
        else:
            edited = md_textarea("åœ¨çº¿ç¼–è¾‘æ•™å­¦å¤§çº²", a["content_md"], key="sy_edit")
            note = st.text_input("ä¿å­˜è¯´æ˜ï¼ˆå¯é€‰ï¼‰", value="edit", key="sy_note")
            if st.button("ä¿å­˜ä¿®æ”¹ï¼ˆç”Ÿæˆæ–°ç‰ˆæœ¬ï¼‰", type="primary", key="sy_save"):
                parents = pick_parents_for(project_id, "syllabus")
                a2 = upsert_artifact(project_id, "syllabus", a["title"], edited, a["content_json"], parents, note=note)
                st.success("å·²ä¿å­˜ã€‚")
                st.rerun()

    with tab5:
        if not a:
            st.info("æš‚æ— æ•™å­¦å¤§çº²ã€‚")
        else:
            vers = get_versions(a["id"])
            st.markdown("#### ç‰ˆæœ¬è®°å½•")
            st.dataframe(vers if vers else [], use_container_width=True)
            st.markdown("#### å¯¼å‡ºï¼ˆç®€ç‰ˆï¼‰")
            docx_bytes = export_docx_bytes_plaintext(a["content_md"])
            if docx_bytes:
                st.download_button("ä¸‹è½½ DOCXï¼ˆç®€ç‰ˆå¯¼å‡ºï¼‰", data=docx_bytes, file_name="æ•™å­¦å¤§çº².docx")
            st.download_button(
                "ä¸‹è½½ JSONï¼ˆç»“æ„åŒ–ï¼‰",
                data=json.dumps(a["content_json"], ensure_ascii=False, indent=2),
                file_name="æ•™å­¦å¤§çº².json",
            )


def page_calendar():
    ensure_project()
    render_depbar(project_id, "calendar")
    sy = get_artifact(project_id, "syllabus")
    a = get_artifact(project_id, "calendar")

    st.markdown("### æ•™å­¦æ—¥å†ï¼šä¾æ®æ•™å­¦å¤§çº²è‡ªåŠ¨ç”Ÿæˆï¼ˆå¯ç¼–è¾‘ï¼‰")

    tab1, tab2, tab3, tab4 = st.tabs(["ç”Ÿæˆ", "é¢„è§ˆ", "ç¼–è¾‘", "ç‰ˆæœ¬/å¯¼å‡º"])
    with tab1:
        if not sy:
            st.warning("ç¼ºå°‘ä¸Šæ¸¸ä¾èµ–ï¼šæ•™å­¦å¤§çº²ã€‚è¯·å…ˆç”Ÿæˆå¤§çº²ã€‚")
        weeks = st.number_input("å‘¨æ•°", min_value=4, max_value=20, value=16, step=1)
        if st.button("ç”Ÿæˆå¹¶ä¿å­˜æ•™å­¦æ—¥å†", type="primary"):
            if not sy:
                st.error("è¯·å…ˆç”Ÿæˆæ•™å­¦å¤§çº²ã€‚")
            else:
                md, js = template_calendar(sy["content_json"].get("course_name", "è¯¾ç¨‹"), int(weeks), sy["content_json"])
                parents = [sy["id"]]
                a2 = upsert_artifact(
                    project_id,
                    "calendar",
                    f"ã€Š{sy['content_json'].get('course_name','è¯¾ç¨‹')}ã€‹æ•™å­¦æ—¥å†",
                    md,
                    js,
                    parents,
                    note="generate",
                )
                st.success("å·²ä¿å­˜æ•™å­¦æ—¥å†ã€‚")
                st.rerun()
    with tab2:
        if not a:
            st.info("æš‚æ— æ•™å­¦æ—¥å†ã€‚")
        else:
            artifact_toolbar(a)
            render_doc_preview(a["content_md"])
    with tab3:
        if not a:
            st.info("æš‚æ— æ•™å­¦æ—¥å†ã€‚")
        else:
            edited = md_textarea("åœ¨çº¿ç¼–è¾‘æ•™å­¦æ—¥å†", a["content_md"], key="cal_edit")
            note = st.text_input("ä¿å­˜è¯´æ˜", value="edit", key="cal_note")
            if st.button("ä¿å­˜ä¿®æ”¹", type="primary", key="cal_save"):
                parents = pick_parents_for(project_id, "calendar")
                a2 = upsert_artifact(project_id, "calendar", a["title"], edited, a["content_json"], parents, note=note)
                st.success("å·²ä¿å­˜ã€‚")
                st.rerun()
    with tab4:
        if not a:
            st.info("æš‚æ— æ•™å­¦æ—¥å†ã€‚")
        else:
            st.dataframe(get_versions(a["id"]) or [], use_container_width=True)
            docx_bytes = export_docx_bytes_plaintext(a["content_md"])
            if docx_bytes:
                st.download_button("ä¸‹è½½ DOCXï¼ˆç®€ç‰ˆå¯¼å‡ºï¼‰", data=docx_bytes, file_name="æ•™å­¦æ—¥å†.docx")


def page_lesson_plan():
    ensure_project()
    render_depbar(project_id, "lesson_plan")
    cal = get_artifact(project_id, "calendar")
    a = get_artifact(project_id, "lesson_plan")

    st.markdown("### æ•™æ¡ˆï¼šä¾æ®æ•™å­¦æ—¥å†ç”Ÿæˆï¼ˆå¯ç¼–è¾‘ï¼‰")
    tab1, tab2, tab3, tab4 = st.tabs(["ç”Ÿæˆ", "é¢„è§ˆ", "ç¼–è¾‘", "ç‰ˆæœ¬/å¯¼å‡º"])

    with tab1:
        if not cal:
            st.warning("ç¼ºå°‘ä¸Šæ¸¸ä¾èµ–ï¼šæ•™å­¦æ—¥å†ã€‚è¯·å…ˆç”Ÿæˆæ—¥å†ã€‚")
        if st.button("ç”Ÿæˆå¹¶ä¿å­˜æ•™æ¡ˆï¼ˆç¤ºä¾‹ï¼šå‰4å‘¨ï¼‰", type="primary"):
            if not cal:
                st.error("è¯·å…ˆç”Ÿæˆæ•™å­¦æ—¥å†ã€‚")
            else:
                course_name = "è¯¾ç¨‹"
                sy = get_artifact(project_id, "syllabus")
                if sy:
                    course_name = sy["content_json"].get("course_name", "è¯¾ç¨‹")
                md, js = template_lesson_plan(course_name, cal["content_json"])
                parents = [cal["id"]]
                a2 = upsert_artifact(project_id, "lesson_plan", f"ã€Š{course_name}ã€‹æ•™æ¡ˆ", md, js, parents, note="generate")
                st.success("å·²ä¿å­˜æ•™æ¡ˆã€‚")
                st.rerun()

    with tab2:
        if not a:
            st.info("æš‚æ— æ•™æ¡ˆã€‚")
        else:
            artifact_toolbar(a)
            render_doc_preview(a["content_md"])

    with tab3:
        if not a:
            st.info("æš‚æ— æ•™æ¡ˆã€‚")
        else:
            edited = md_textarea("åœ¨çº¿ç¼–è¾‘æ•™æ¡ˆ", a["content_md"], key="lp_edit")
            note = st.text_input("ä¿å­˜è¯´æ˜", value="edit", key="lp_note")
            if st.button("ä¿å­˜ä¿®æ”¹", type="primary", key="lp_save"):
                parents = pick_parents_for(project_id, "lesson_plan")
                a2 = upsert_artifact(project_id, "lesson_plan", a["title"], edited, a["content_json"], parents, note=note)
                st.success("å·²ä¿å­˜ã€‚")
                st.rerun()

    with tab4:
        if not a:
            st.info("æš‚æ— æ•™æ¡ˆã€‚")
        else:
            st.dataframe(get_versions(a["id"]) or [], use_container_width=True)
            docx_bytes = export_docx_bytes_plaintext(a["content_md"])
            if docx_bytes:
                st.download_button("ä¸‹è½½ DOCXï¼ˆç®€ç‰ˆå¯¼å‡ºï¼‰", data=docx_bytes, file_name="æ•™æ¡ˆ.docx")


def page_assessment():
    ensure_project()
    render_depbar(project_id, "assessment")
    sy = get_artifact(project_id, "syllabus")
    a = get_artifact(project_id, "assessment")

    st.markdown("### ä½œä¸š/é¢˜åº“/è¯•å·æ–¹æ¡ˆï¼šä¾æ®æ•™å­¦å¤§çº²ç”Ÿæˆï¼ˆå¯ç¼–è¾‘ï¼‰")
    tab1, tab2, tab3, tab4 = st.tabs(["ç”Ÿæˆ", "é¢„è§ˆ", "ç¼–è¾‘", "ç‰ˆæœ¬/å¯¼å‡º"])

    with tab1:
        if not sy:
            st.warning("ç¼ºå°‘ä¸Šæ¸¸ä¾èµ–ï¼šæ•™å­¦å¤§çº²ã€‚è¯·å…ˆç”Ÿæˆå¤§çº²ã€‚")
        if st.button("ç”Ÿæˆå¹¶ä¿å­˜è¯•å·æ–¹æ¡ˆ", type="primary"):
            if not sy:
                st.error("è¯·å…ˆç”Ÿæˆæ•™å­¦å¤§çº²ã€‚")
            else:
                course_name = sy["content_json"].get("course_name", "è¯¾ç¨‹")
                md, js = template_assessment(course_name, sy["content_json"])
                parents = [sy["id"]]
                a2 = upsert_artifact(project_id, "assessment", f"ã€Š{course_name}ã€‹è¯•å·æ–¹æ¡ˆ/é¢˜åº“", md, js, parents, note="generate")
                st.success("å·²ä¿å­˜è¯•å·æ–¹æ¡ˆã€‚")
                st.rerun()

    with tab2:
        if not a:
            st.info("æš‚æ— è¯•å·æ–¹æ¡ˆã€‚")
        else:
            artifact_toolbar(a)
            render_doc_preview(a["content_md"])

    with tab3:
        if not a:
            st.info("æš‚æ— è¯•å·æ–¹æ¡ˆã€‚")
        else:
            edited = md_textarea("åœ¨çº¿ç¼–è¾‘è¯•å·æ–¹æ¡ˆ", a["content_md"], key="as_edit")
            note = st.text_input("ä¿å­˜è¯´æ˜", value="edit", key="as_note")
            if st.button("ä¿å­˜ä¿®æ”¹", type="primary", key="as_save"):
                parents = pick_parents_for(project_id, "assessment")
                a2 = upsert_artifact(project_id, "assessment", a["title"], edited, a["content_json"], parents, note=note)
                st.success("å·²ä¿å­˜ã€‚")
                st.rerun()

    with tab4:
        if not a:
            st.info("æš‚æ— è¯•å·æ–¹æ¡ˆã€‚")
        else:
            st.dataframe(get_versions(a["id"]) or [], use_container_width=True)
            docx_bytes = export_docx_bytes_plaintext(a["content_md"])
            if docx_bytes:
                st.download_button("ä¸‹è½½ DOCXï¼ˆç®€ç‰ˆå¯¼å‡ºï¼‰", data=docx_bytes, file_name="è¯•å·æ–¹æ¡ˆ.docx")


def page_review():
    ensure_project()
    render_depbar(project_id, "review")
    sy = get_artifact(project_id, "syllabus")
    ass = get_artifact(project_id, "assessment")
    a = get_artifact(project_id, "review")

    st.markdown("### å®¡æ ¸è¡¨ï¼šä¾æ®è¯•å·æ–¹æ¡ˆ/æ•™å­¦å¤§çº²ç”Ÿæˆï¼ˆå¯ç¼–è¾‘ï¼‰")
    tab1, tab2, tab3, tab4 = st.tabs(["ç”Ÿæˆ", "é¢„è§ˆ", "ç¼–è¾‘", "ç‰ˆæœ¬/å¯¼å‡º"])

    with tab1:
        if not (sy and ass):
            st.warning("ç¼ºå°‘ä¸Šæ¸¸ä¾èµ–ï¼šéœ€è¦ æ•™å­¦å¤§çº² + è¯•å·æ–¹æ¡ˆã€‚")
        if st.button("ç”Ÿæˆå¹¶ä¿å­˜å®¡æ ¸è¡¨", type="primary"):
            if not (sy and ass):
                st.error("è¯·å…ˆç”Ÿæˆæ•™å­¦å¤§çº²ä¸è¯•å·æ–¹æ¡ˆã€‚")
            else:
                course_name = sy["content_json"].get("course_name", "è¯¾ç¨‹")
                md, js = template_review_forms(course_name, ass["content_json"], sy["content_json"])
                parents = [ass["id"], sy["id"]]
                a2 = upsert_artifact(project_id, "review", f"ã€Š{course_name}ã€‹å®¡æ ¸è¡¨é›†åˆ", md, js, parents, note="generate")
                st.success("å·²ä¿å­˜å®¡æ ¸è¡¨ã€‚")
                st.rerun()

    with tab2:
        if not a:
            st.info("æš‚æ— å®¡æ ¸è¡¨ã€‚")
        else:
            artifact_toolbar(a)
            render_doc_preview(a["content_md"])

    with tab3:
        if not a:
            st.info("æš‚æ— å®¡æ ¸è¡¨ã€‚")
        else:
            edited = md_textarea("åœ¨çº¿ç¼–è¾‘å®¡æ ¸è¡¨", a["content_md"], key="rv_edit")
            note = st.text_input("ä¿å­˜è¯´æ˜", value="edit", key="rv_note")
            if st.button("ä¿å­˜ä¿®æ”¹", type="primary", key="rv_save"):
                parents = pick_parents_for(project_id, "review")
                a2 = upsert_artifact(project_id, "review", a["title"], edited, a["content_json"], parents, note=note)
                st.success("å·²ä¿å­˜ã€‚")
                st.rerun()

    with tab4:
        if not a:
            st.info("æš‚æ— å®¡æ ¸è¡¨ã€‚")
        else:
            st.dataframe(get_versions(a["id"]) or [], use_container_width=True)
            docx_bytes = export_docx_bytes_plaintext(a["content_md"])
            if docx_bytes:
                st.download_button("ä¸‹è½½ DOCXï¼ˆç®€ç‰ˆå¯¼å‡ºï¼‰", data=docx_bytes, file_name="å®¡æ ¸è¡¨.docx")


def page_report():
    ensure_project()
    render_depbar(project_id, "report")
    sy = get_artifact(project_id, "syllabus")
    a = get_artifact(project_id, "report")

    st.markdown("### è¯¾ç¨‹ç›®æ ‡è¾¾æˆè¯„ä»·æŠ¥å‘Šï¼šä¾æ®æ•™å­¦å¤§çº²ç”Ÿæˆï¼ˆå¯ç¼–è¾‘ï¼‰")
    tab1, tab2, tab3, tab4 = st.tabs(["ç”Ÿæˆ/ä¸Šä¼ æˆç»©", "é¢„è§ˆ", "ç¼–è¾‘", "ç‰ˆæœ¬/å¯¼å‡º"])

    with tab1:
        if not sy:
            st.warning("ç¼ºå°‘ä¸Šæ¸¸ä¾èµ–ï¼šæ•™å­¦å¤§çº²ã€‚")
        note = st.text_area("è¡¥å……è¯´æ˜ï¼ˆå¦‚ï¼šæœ¬è½®æ•™å­¦ç‰¹ç‚¹/é—®é¢˜ï¼‰", value="å¯åœ¨æ­¤å†™å…¥æ•™å­¦åæ€ä¸æ”¹è¿›é—­ç¯è¯´æ˜ã€‚", height=100)
        st.caption("æˆç»©è¡¨ä¸Šä¼ ï¼ˆå¯é€‰ï¼‰ï¼šåç»­å¯æ‰©å±•ä¸ºè‡ªåŠ¨è®¡ç®—è¾¾æˆåº¦ï¼ˆæ¼”ç¤ºç‰ˆæš‚ä¸è®¡ç®—ï¼‰ã€‚")
        st.file_uploader("ä¸Šä¼ æˆç»©è¡¨ï¼ˆCSV/Excelï¼‰", type=["csv", "xlsx"], key="grade_up")

        if st.button("ç”Ÿæˆå¹¶ä¿å­˜è¾¾æˆæŠ¥å‘Š", type="primary"):
            if not sy:
                st.error("è¯·å…ˆç”Ÿæˆæ•™å­¦å¤§çº²ã€‚")
            else:
                course_name = sy["content_json"].get("course_name", "è¯¾ç¨‹")
                md, js = template_report(course_name, sy["content_json"], note=note)
                parents = [sy["id"]]
                a2 = upsert_artifact(project_id, "report", f"ã€Š{course_name}ã€‹è¯¾ç¨‹ç›®æ ‡è¾¾æˆæŠ¥å‘Š", md, js, parents, note="generate")
                st.success("å·²ä¿å­˜è¾¾æˆæŠ¥å‘Šã€‚")
                st.rerun()

    with tab2:
        if not a:
            st.info("æš‚æ— è¾¾æˆæŠ¥å‘Šã€‚")
        else:
            artifact_toolbar(a)
            render_doc_preview(a["content_md"])

    with tab3:
        if not a:
            st.info("æš‚æ— è¾¾æˆæŠ¥å‘Šã€‚")
        else:
            edited = md_textarea("åœ¨çº¿ç¼–è¾‘è¾¾æˆæŠ¥å‘Š", a["content_md"], key="rp_edit")
            note2 = st.text_input("ä¿å­˜è¯´æ˜", value="edit", key="rp_note")
            if st.button("ä¿å­˜ä¿®æ”¹", type="primary", key="rp_save"):
                parents = pick_parents_for(project_id, "report")
                a2 = upsert_artifact(project_id, "report", a["title"], edited, a["content_json"], parents, note=note2)
                st.success("å·²ä¿å­˜ã€‚")
                st.rerun()

    with tab4:
        if not a:
            st.info("æš‚æ— è¾¾æˆæŠ¥å‘Šã€‚")
        else:
            st.dataframe(get_versions(a["id"]) or [], use_container_width=True)
            docx_bytes = export_docx_bytes_plaintext(a["content_md"])
            if docx_bytes:
                st.download_button("ä¸‹è½½ DOCXï¼ˆç®€ç‰ˆå¯¼å‡ºï¼‰", data=docx_bytes, file_name="è¾¾æˆæŠ¥å‘Š.docx")


def page_evidence():
    ensure_project()
    render_depbar(project_id, "evidence")
    a = get_artifact(project_id, "evidence")

    st.markdown("### è¯¾å ‚çŠ¶æ€ä¸è¿‡ç¨‹è¯æ®ï¼ˆä¸Šä¼ ç…§ç‰‡ç”Ÿæˆæ‘˜è¦ï¼‰")
    st.caption("åˆè§„æç¤ºï¼šä¸åšèº«ä»½è¯†åˆ«ï¼Œä»…è¾“å‡º Stu ç¼–å· + çŠ¶æ€ä¼°è®¡ï¼Œç”¨äºâ€œè¿‡ç¨‹è¯æ®â€æ”¯æ’‘ã€‚")

    context = st.text_input("è¯¾å ‚å†…å®¹ï¼ˆç”¨äºç”Ÿæˆæ›´è´´åˆçš„æ‘˜è¦ï¼‰", value="å¾®ç§¯åˆ†ï¼šé“¾å¼æ³•åˆ™è®²è§£", key="ev_ctx")
    up = st.file_uploader("ä¸Šä¼ è¯¾å ‚ç…§ç‰‡ï¼ˆJPG/PNGï¼‰", type=["jpg", "jpeg", "png"], key="ev_img")

    if up is not None:
        img = ImageOps.exif_transpose(Image.open(up)).convert("RGB")
        st.image(img, caption="ä¸Šä¼ çš„è¯¾å ‚ç…§ç‰‡ï¼ˆä»…ç”¨äºç”Ÿæˆæ‘˜è¦ï¼‰", use_container_width=True)
        if st.button("ç”Ÿæˆå¹¶ä¿å­˜è¿‡ç¨‹è¯æ®æ‘˜è¦", type="primary"):
            dataurl = img_to_dataurl(img)
            summary = qwen_vl_classroom_summary(dataurl, context)
            md = f"# è¯¾å ‚è¿‡ç¨‹è¯æ®æ‘˜è¦\n\n- è¯¾å ‚å†…å®¹ï¼š{context}\n\n{summary}\n"
            a2 = upsert_artifact(
                project_id,
                "evidence",
                "è¯¾å ‚è¿‡ç¨‹è¯æ®æ‘˜è¦",
                md,
                {"context": context, "source": up.name},
                [],
                note="generate",
            )
            st.success("å·²ä¿å­˜è¿‡ç¨‹è¯æ®æ‘˜è¦ã€‚å¯åœ¨â€œæˆè¯¾æ‰‹å†Œâ€æ¨¡å—è‡ªåŠ¨å¼•ç”¨ã€‚")
            st.rerun()

    st.markdown("#### å½“å‰è¯æ®")
    if not a:
        st.info("æš‚æ— è¿‡ç¨‹è¯æ®ã€‚ä½ å¯ä»¥ä¸Šä¼ ä¸€å¼ è¯¾å ‚ç…§ç‰‡ç”Ÿæˆæ‘˜è¦ã€‚")
    else:
        artifact_toolbar(a)
        render_doc_preview(a["content_md"])


def page_manual():
    ensure_project()
    render_depbar(project_id, "manual")
    lp = get_artifact(project_id, "lesson_plan")
    ev = get_artifact(project_id, "evidence")
    a = get_artifact(project_id, "manual")

    st.markdown("### æˆè¯¾æ‰‹å†Œï¼šä¾èµ–æ•™æ¡ˆï¼ˆå¯é€‰å¼•ç”¨è¿‡ç¨‹è¯æ®ï¼‰")
    tab1, tab2, tab3, tab4 = st.tabs(["ç”Ÿæˆ", "é¢„è§ˆ", "ç¼–è¾‘", "ç‰ˆæœ¬/å¯¼å‡º"])

    with tab1:
        if not lp:
            st.warning("ç¼ºå°‘ä¸Šæ¸¸ä¾èµ–ï¼šæ•™æ¡ˆã€‚")
        use_ev = st.checkbox("å¼•ç”¨è¯¾å ‚è¿‡ç¨‹è¯æ®æ‘˜è¦ï¼ˆå¦‚æœå­˜åœ¨ï¼‰", value=True)
        if st.button("ç”Ÿæˆå¹¶ä¿å­˜æˆè¯¾æ‰‹å†Œ", type="primary"):
            if not lp:
                st.error("è¯·å…ˆç”Ÿæˆæ•™æ¡ˆã€‚")
            else:
                sy = get_artifact(project_id, "syllabus")
                course_name = sy["content_json"].get("course_name", "è¯¾ç¨‹") if sy else "è¯¾ç¨‹"
                ev_md = ev["content_md"] if (use_ev and ev) else ""
                md, js = template_manual(course_name, lp["content_json"], ev_md)
                parents = pick_parents_for(project_id, "manual")
                a2 = upsert_artifact(project_id, "manual", f"ã€Š{course_name}ã€‹æˆè¯¾æ‰‹å†Œ", md, js, parents, note="generate")
                st.success("å·²ä¿å­˜æˆè¯¾æ‰‹å†Œã€‚")
                st.rerun()

    with tab2:
        if not a:
            st.info("æš‚æ— æˆè¯¾æ‰‹å†Œã€‚")
        else:
            artifact_toolbar(a)
            render_doc_preview(a["content_md"])

    with tab3:
        if not a:
            st.info("æš‚æ— æˆè¯¾æ‰‹å†Œã€‚")
        else:
            edited = md_textarea("åœ¨çº¿ç¼–è¾‘æˆè¯¾æ‰‹å†Œ", a["content_md"], key="mn_edit")
            note = st.text_input("ä¿å­˜è¯´æ˜", value="edit", key="mn_note")
            if st.button("ä¿å­˜ä¿®æ”¹", type="primary", key="mn_save"):
                parents = pick_parents_for(project_id, "manual")
                a2 = upsert_artifact(project_id, "manual", a["title"], edited, a["content_json"], parents, note=note)
                st.success("å·²ä¿å­˜ã€‚")
                st.rerun()

    with tab4:
        if not a:
            st.info("æš‚æ— æˆè¯¾æ‰‹å†Œã€‚")
        else:
            st.dataframe(get_versions(a["id"]) or [], use_container_width=True)
            docx_bytes = export_docx_bytes_plaintext(a["content_md"])
            if docx_bytes:
                st.download_button("ä¸‹è½½ DOCXï¼ˆç®€ç‰ˆå¯¼å‡ºï¼‰", data=docx_bytes, file_name="æˆè¯¾æ‰‹å†Œ.docx")


def page_vge():
    ensure_project()
    st.markdown("### è¯æ®é“¾ä¸å¯éªŒè¯ç”Ÿæˆï¼ˆVGEï¼‰")
    st.caption("å±•ç¤ºï¼šæ¯ä»½æ–‡æ¡£çš„ hashã€ä¾èµ–è¾¹ã€å¯è¿½æº¯å…³ç³»ï¼ˆç”¨äºç”³æŠ¥â€œå¯éªŒè¯ç”Ÿæˆ/è¯æ®é“¾â€äº®ç‚¹ï¼‰ã€‚")

    arts = list_artifacts(project_id)
    if not arts:
        st.info("æš‚æ— æ–‡æ¡£ã€‚è¯·å…ˆç”ŸæˆåŸ¹å…»æ–¹æ¡ˆ/å¤§çº²ç­‰ã€‚")
        return

    rows = []
    for a in arts:
        rows.append(
            {
                "ç±»å‹": a["type"],
                "åç§°": a["title"],
                "Hash": a["hash"][:16],
                "æ›´æ–°æ—¶é—´": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(a["updated_at"])),
            }
        )
    st.markdown('<div class="card"><b>æ–‡æ¡£æ¸…å•ï¼ˆhash ä½œä¸ºå¯éªŒè¯æ ‡è¯†ï¼‰</b></div>', unsafe_allow_html=True)
    st.dataframe(rows, use_container_width=True)

    conn = db()
    e = conn.execute(
        "SELECT c.type, c.title, c.hash, p.type, p.title, p.hash "
        "FROM edges e "
        "JOIN artifacts c ON e.child_artifact_id=c.id "
        "JOIN artifacts p ON e.parent_artifact_id=p.id "
        "WHERE e.project_id=? ORDER BY e.id DESC",
        (project_id,),
    ).fetchall()
    conn.close()

    st.markdown('<div class="card"><b>ä¾èµ–å…³ç³»ï¼ˆchild â† parentï¼‰</b></div>', unsafe_allow_html=True)
    rows2 = []
    if not e:
        st.info("æš‚æ— ä¾èµ–è¾¹ï¼ˆè¿˜æœªç”Ÿæˆä¾èµ–å‹æ–‡ä»¶ï¼‰ã€‚")
    else:
        for r in e:
            rows2.append({"Child": f"{r[0]} | {r[1]} | {r[2][:12]}", "Parent": f"{r[3]} | {r[4]} | {r[5][:12]}"})
        st.dataframe(rows2, use_container_width=True)

    export = {"project_id": project_id, "artifacts": arts, "edges": rows2}
    st.download_button("ä¸‹è½½ VGE è¯æ®é“¾æ—¥å¿—ï¼ˆJSONï¼‰", data=json.dumps(export, ensure_ascii=False, indent=2), file_name="vge_log.json")


# ---------------------------
# è·¯ç”±ï¼šæŒ‰æ¨¡å—æ˜¾ç¤º
# ---------------------------
ROUTES = {
    "overview": page_overview,
    "training_plan": page_training_plan,
    "syllabus": page_syllabus,
    "calendar": page_calendar,
    "lesson_plan": page_lesson_plan,
    "assessment": page_assessment,
    "review": page_review,
    "report": page_report,
    "manual": page_manual,
    "evidence": page_evidence,
    "vge": page_vge,
    "dep_graph": page_dep_graph,
    "docx_export": page_docx_export,
}

fn = ROUTES.get(current_type, page_overview)
fn()

st.caption("æ³¨ï¼šæ¼”ç¤ºç‰ˆæ”¯æŒæ— APIç”Ÿæˆï¼›åœ¨çº¿æ¨¡å¼å¯å¯ç”¨åƒé—®ï¼›æ¨¡æ¿åŒ–DOCXå¯¼å‡ºéœ€ docxtplã€‚")
