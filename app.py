import io, json, time, random, re
import pandas as pd
import streamlit as st
import pdfplumber
import google.generativeai as genai
from typing import Dict, List, Any
from openai import OpenAI
from google.api_core import exceptions

# ============================================================
# 1. ä¾›åº”å•†é…ç½®
# ============================================================
PROVIDERS = {
    "é€šä¹‰åƒé—® (Qwen)": {"base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1", "model": "qwen-plus", "is_gemini": False, "limit": 2048},
    "DeepSeek": {"base_url": "https://api.deepseek.com", "model": "deepseek-chat", "is_gemini": False, "limit": 4096},
    "Gemini (Google)": {"base_url": None, "model": "gemini-1.5-flash", "is_gemini": True, "limit": 8192},
}

# ============================================================
# 2. å¢å¼ºå‹æ•°æ®æ¸…æ´—å·¥å…·
# ============================================================
def safe_to_df(data: Any, default_cols: List[str]) -> pd.DataFrame:
    """è§£å†³å†…å®¹ä¸æ˜¾ç¤ºçš„æ ¸å¿ƒï¼šå¤šå±‚æœç´¢ä¸ç±»å‹è½¬æ¢"""
    if not data: return pd.DataFrame(columns=default_cols)
    
    clean_list = []
    # æ™ºèƒ½è§£åŒ…ï¼šå¦‚æœæ˜¯å­—å…¸ï¼Œå¯»æ‰¾å…¶ä¸­çš„åˆ—è¡¨
    rows = data if isinstance(data, list) else []
    if isinstance(data, dict):
        for k in ["table1", "table2", "table4", "data", "items"]:
            if isinstance(data.get(k), list):
                rows = data[k]
                break
        if not rows: # å…œåº•ï¼šå–ç¬¬ä¸€ä¸ªåˆ—è¡¨å€¼
            for v in data.values():
                if isinstance(v, list): rows = v; break

    for item in rows:
        if isinstance(item, dict): clean_list.append(item)
        elif isinstance(item, list): clean_list.append(dict(zip(default_cols, item)))
    
    return pd.DataFrame(clean_list) if clean_list else pd.DataFrame(columns=default_cols)

# ============================================================
# 3. ç»Ÿä¸€è°ƒç”¨å†…æ ¸ (å¸¦ Markdown å‰¥ç¦»)
# ============================================================
def call_llm_engine(provider_name, api_key, prompt, max_retries=3):
    config = PROVIDERS.get(provider_name, PROVIDERS["Gemini (Google)"])
    for i in range(max_retries):
        try:
            time.sleep(6 if config["is_gemini"] else 3)
            if config["is_gemini"]:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(config["model"])
                resp = model.generate_content(prompt, generation_config={"response_mime_type":"application/json"})
                return json.loads(resp.text)
            else:
                client = OpenAI(api_key=api_key, base_url=config["base_url"])
                resp = client.chat.completions.create(
                    model=config["model"],
                    messages=[{"role":"system","content":"ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æ•™åŠ¡ä¸“å®¶ï¼Œåªè¾“å‡ºJSONã€‚"},{"role":"user","content":prompt}],
                    response_format={"type": "json_object"},
                    max_tokens=config["limit"]
                )
                raw = resp.choices[0].message.content
                # å‰¥ç¦» Markdown æ ‡ç­¾ä»¥é˜²è§£æå¤±è´¥
                return json.loads(re.sub(r'```json\s*|\s*```', '', raw).strip())
        except exceptions.ResourceExhausted:
            time.sleep(20 * (i + 1))
        except Exception:
            continue
    return None

# ============================================================
# 4. æè‡´åˆ†å—è§£æå¼•æ“ (ä¿®å¤ç¼ºå¤±ä¸ç©ºæ˜¾ç¤º)
# ============================================================
def ultra_parse_v56(api_key, pdf_bytes, provider_name):
    results = {"sections": {}, "table1": [], "table2": [], "table4": []}
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        all_text = "\n".join([p.extract_text() or "" for p in pdf.pages])
        raw_t1, raw_t4 = [], []
        for p in pdf.pages:
            txt, tbls = p.extract_text() or "", p.extract_tables()
            if any(x in txt for x in ["é™„è¡¨1", "æ•™å­¦è®¡åˆ’è¡¨"]):
                for t in tbls: raw_t1.extend(t)
            if any(x in txt for x in ["é™„è¡¨4", "æ”¯æ’‘çŸ©é˜µ"]):
                for t in tbls: raw_t4.extend(t)

    # 1. æ­£æ–‡ç‹¬ç«‹æå–
    st.info("æ­¥éª¤ 1/5: æ­£åœ¨æå– 1-6 é¡¹æ­£æ–‡...")
    res_sec = call_llm_engine(provider_name, api_key, f"æå– 1-6 é¡¹æ­£æ–‡ JSONã€‚é”®åï¼š1åŸ¹å…»ç›®æ ‡, 2æ¯•ä¸šè¦æ±‚, 3ä¸“ä¸šå®šä½ä¸ç‰¹è‰², 4ä¸»å¹²å­¦ç§‘, 5æ ‡å‡†å­¦åˆ¶, 6æ¯•ä¸šæ¡ä»¶ã€‚å†…å®¹ï¼š{all_text[:12000]}")
    if res_sec: results["sections"] = res_sec

    # 2. é™„è¡¨ 1 (æè‡´åˆ‡ç‰‡ï¼šQwen å»ºè®® 15 è¡Œ)
    if raw_t1:
        clean_t1 = [r for r in raw_t1 if any(r)]
        st.info(f"æ­¥éª¤ 2/5: è§£æè®¡åˆ’è¡¨ (å…± {len(clean_t1)} è¡Œï¼Œé˜²æ­¢ç¼ºå¤±)...")
        for i in range(0, len(clean_t1), 15): # ğŸ‘ˆ ä¸‹è°ƒåˆ†å—å¤§å°è‡³ 15
            chunk = clean_t1[i : i+15]
            st.write(f"  > æ­£åœ¨å¤„ç†è®¡åˆ’è¡¨ç¬¬ {i+1} è‡³ {i+len(chunk)} è¡Œ...")
            r = call_llm_engine(provider_name, api_key, f"å°†è¡¨æ ¼è¡Œè½¬ä¸º JSON åˆ—è¡¨ [è¯¾ç¨‹åç§°, å­¦åˆ†, å­¦ä½è¯¾, ä¸Šè¯¾å­¦æœŸ]ã€‚æ•°æ®ï¼š{json.dumps(chunk, ensure_ascii=False)}")
            results["table1"].extend(safe_to_df(r, ["è¯¾ç¨‹åç§°", "å­¦åˆ†", "å­¦ä½è¯¾", "ä¸Šè¯¾å­¦æœŸ"]).to_dict('records'))

    # 3. é™„è¡¨ 2 (ç‹¬ç«‹æå–ï¼Œè§£å†³ç©ºæ˜¾ç¤º)
    st.info("æ­¥éª¤ 3/5: è§£æå­¦åˆ†ç»Ÿè®¡è¡¨...")
    res_t2 = call_llm_engine(provider_name, api_key, f"æå–é™„è¡¨ 2 å­¦åˆ†ç»Ÿè®¡ JSON åˆ—è¡¨ã€‚å¿…é¡»åŒºåˆ†'ç„Šæ¥'å’Œ'æ— æŸæ£€æµ‹'æ–¹å‘ã€‚å†…å®¹ï¼š{all_text}")
    results["table2"] = safe_to_df(res_t2, ["ä¸“ä¸šæ–¹å‘", "é¡¹ç›®", "å­¦åˆ†è¦æ±‚"]).to_dict('records')

    # 4. é™„è¡¨ 4 (æ”¯æ’‘çŸ©é˜µæè‡´åˆ‡ç‰‡)
    if raw_t4:
        clean_t4 = [r for r in raw_t4 if any(r)]
        st.info(f"æ­¥éª¤ 4/5: è§£ææ”¯æ’‘çŸ©é˜µ (å…± {len(clean_t4)} è¡Œï¼Œé˜²æ­¢ç¼ºå¤±)...")
        for i in range(0, len(clean_t4), 15): # ğŸ‘ˆ ä¸‹è°ƒåˆ†å—å¤§å°è‡³ 15
            chunk = clean_t4[i : i+15]
            st.write(f"  > æ­£åœ¨æ˜ å°„çŸ©é˜µç¬¬ {i+1} è‡³ {i+len(chunk)} æ¡æ”¯æ’‘å…³ç³»...")
            r = call_llm_engine(provider_name, api_key, f"æå–æ”¯æ’‘çŸ©é˜µ JSON åˆ—è¡¨ [è¯¾ç¨‹åç§°, æŒ‡æ ‡ç‚¹, å¼ºåº¦]ã€‚æ•°æ®ï¼š{json.dumps(chunk, ensure_ascii=False)}")
            results["table4"].extend(safe_to_df(r, ["è¯¾ç¨‹åç§°", "æŒ‡æ ‡ç‚¹", "å¼ºåº¦"]).to_dict('records'))

    return results

# ============================================================
# 5. UI æ¸²æŸ“
# ============================================================
def main():
    st.set_page_config(layout="wide", page_title="æ•™å­¦æ–¹æ¡ˆæå– v5.6")
    if "data" not in st.session_state: st.session_state.data = None

    with st.sidebar:
        st.title("âš™ï¸ é…ç½®")
        prov = st.selectbox("æ¨¡å‹ä¾›åº”å•†", list(PROVIDERS.keys()))
        key = st.text_input("API Key", type="password")
        if st.button("æ¸…ç†ç¼“å­˜"):
            st.session_state.data = None
            st.rerun()

    st.header("ğŸ§  åŸ¹å…»æ–¹æ¡ˆæ™ºèƒ½å·¥ä½œå° (æè‡´ç²¾åº¦ç‰ˆ)")
    file = st.file_uploader("ä¸Šä¼  PDF", type="pdf")

    if file and key and st.button("ğŸš€ å¼€å§‹æ‰§è¡ŒæŠ½å–", type="primary"):
        res = ultra_parse_v56(key, file.getvalue(), prov)
        if res:
            st.session_state.data = res
            st.success("ğŸ‰ æŠ½å–ä»»åŠ¡å·²å…¨éƒ¨å®Œæˆï¼")

    if st.session_state.data:
        d = st.session_state.data
        tabs = st.tabs(["1-6 æ­£æ–‡", "é™„è¡¨1: è®¡åˆ’è¡¨", "é™„è¡¨2: å­¦åˆ†ç»Ÿè®¡", "é™„è¡¨4: æ”¯æ’‘çŸ©é˜µ"])
        with tabs[0]:
            sec = d.get("sections", {})
            if isinstance(sec, dict) and sec:
                if "sections" in sec: sec = sec["sections"]
                pick = st.selectbox("æŸ¥çœ‹æ ç›®", list(sec.keys()), key="v56_sel")
                st.text_area("å†…å®¹", value=str(sec.get(pick, "")), height=400, key=f"v56_ta_{pick}")
        with tabs[1]: st.dataframe(pd.DataFrame(d.get("table1", [])), use_container_width=True)
        with tabs[2]: st.dataframe(pd.DataFrame(d.get("table2", [])), use_container_width=True)
        with tabs[3]: st.dataframe(pd.DataFrame(d.get("table4", [])), use_container_width=True)

if __name__ == "__main__":
    main()