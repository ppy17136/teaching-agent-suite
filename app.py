import io, json, time, re
import pandas as pd
import streamlit as st
import pdfplumber
import google.generativeai as genai
from typing import Dict, List, Any
from openai import OpenAI  # ç”¨äºé€‚é… DeepSeek, Kimi, Yi, æ™ºè°±ç­‰

# ============================================================
# 1. æ¨¡å‹ä¾›åº”å•†é…ç½®
# ============================================================
PROVIDERS = {
    "Gemini (Google)": {"base_url": None, "model": "gemini-2.5-flash"},
    "DeepSeek": {"base_url": "https://api.deepseek.com", "model": "deepseek-chat"},
    "Kimi (Moonshot)": {"base_url": "https://api.moonshot.cn/v1", "model": "moonshot-v1-8k"},
    "æ™ºè°± AI (GLM)": {"base_url": "https://open.bigmodel.cn/api/paas/v4/", "model": "glm-4"},
    "é›¶ä¸€ä¸‡ç‰© (Yi)": {"base_url": "https://api.lingyiwanwu.com/v1", "model": "yi-34b-chat-0205"},
    "é€šä¹‰åƒé—® (Qwen)": {"base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1", "model": "qwen-plus"},
    "è±†åŒ… (å­—èŠ‚)": {"base_url": "https://ark.cn-beijing.volces.com/api/v3", "model": "doubao-pro-32k"}
}

# ============================================================
# 2. ç»Ÿä¸€å¤§æ¨¡å‹è°ƒç”¨è·¯ç”±
# ============================================================
def call_llm(provider_name, api_key, prompt):
    config = PROVIDERS[provider_name]
    
    # --- åœºæ™¯ A: Gemini ä¸“ç”¨ SDK ---
    if "Gemini" in provider_name:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(config["model"])
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(response.text)
    
    # --- åœºæ™¯ B: OpenAI å…¼å®¹æ ¼å¼ (DeepSeek, Kimi, GLM, etc.) ---
    else:
        client = OpenAI(api_key=api_key, base_url=config["base_url"])
        response = client.chat.completions.create(
            model=config["model"],
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåªè¾“å‡º JSON çš„æ•™åŠ¡ä¸“å®¶åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)


# ============================================================
# 1. æ ¸å¿ƒæç¤ºè¯å®šä¹‰ï¼šä¸€æ¬¡æ€§æŒ‡ä»¤
# ============================================================
MEGA_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªé«˜æ ¡æ•™åŠ¡ä¸“å®¶ã€‚è¯·é˜…è¯»ä»¥ä¸‹å®Œæ•´çš„åŸ¹å…»æ–¹æ¡ˆæ–‡æœ¬ï¼Œå¹¶ç²¾ç¡®æå–ä»¥ä¸‹æ‰€æœ‰å†…å®¹ã€‚
è¯·ä¸¥æ ¼è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œç»“æ„å¦‚ä¸‹ï¼š

{
  "sections": {
    "1åŸ¹å…»ç›®æ ‡": "...",
    "2æ¯•ä¸šè¦æ±‚": "...",
    "3ä¸“ä¸šå®šä½ä¸ç‰¹è‰²": "...",
    "4ä¸»å¹²å­¦ç§‘/æ ¸å¿ƒè¯¾ç¨‹/å®è·µç¯èŠ‚": "...",
    "5æ ‡å‡†å­¦åˆ¶ä¸æˆäºˆå­¦ä½": "...",
    "6æ¯•ä¸šæ¡ä»¶": "..."
  },
  "table1": [{"è¯¾ç¨‹ä½“ç³»": "...", "è¯¾ç¨‹ç¼–ç ": "...", "è¯¾ç¨‹åç§°": "...", "å¼€è¯¾æ¨¡å¼": "...", "è€ƒæ ¸æ–¹å¼": "...", "è¯¾å†…å­¦åˆ†": "...", "è¯¾å†…æ€»å­¦æ—¶": "...", "è¯¾å†…è®²è¯¾å­¦æ—¶": "...", "è¯¾å†…å®éªŒå­¦æ—¶": "...", "è¯¾å†…ä¸Šæœºå­¦æ—¶": "...", "è¯¾å†…å®è·µå­¦æ—¶": "...", "è¯¾å¤–å­¦åˆ†": "...", "è¯¾å¤–å­¦æ—¶": "...", "ä¸Šè¯¾å­¦æœŸ": "...", "ä¸“ä¸šæ–¹å‘": "...", "æ˜¯å¦å­¦ä½è¯¾": "...", "å¤‡æ³¨": "..."}],
  "table2": [{"ä¸“ä¸šæ–¹å‘": "...", "è¯¾ç¨‹ä½“ç³»": "...", "å¼€è¯¾æ¨¡å¼": "...", "å­¦æœŸä¸€å­¦åˆ†åˆ†é…": "...", "å­¦æœŸäºŒå­¦åˆ†åˆ†é…": "...", "å­¦æœŸä¸‰å­¦åˆ†åˆ†é…": "...", "å­¦æœŸå››å­¦åˆ†åˆ†é…": "...", "å­¦æœŸäº”å­¦åˆ†åˆ†é…": "...", "å­¦æœŸå…­å­¦åˆ†åˆ†é…": "...", "å­¦æœŸä¸ƒå­¦åˆ†åˆ†é…": "...", "å­¦æœŸå…«å­¦åˆ†åˆ†é…": "...", "å­¦åˆ†ç»Ÿè®¡": "...", "å­¦åˆ†æ¯”ä¾‹": "..."}],
  "table4": [{"è¯¾ç¨‹åç§°": "...", "æŒ‡æ ‡ç‚¹": "...", "å¼ºåº¦": "..."}]
}

è¦æ±‚ï¼š
1. é™„è¡¨1 (æ•™å­¦è®¡åˆ’è¡¨) è¯·æå–æ‰€æœ‰è¯¾ç¨‹ï¼Œä¸è¦é—æ¼ã€‚
2. é™„è¡¨2 (å­¦åˆ†ç»Ÿè®¡) å¿…é¡»åŒºåˆ†â€œç„Šæ¥â€å’Œâ€œæ— æŸæ£€æµ‹â€æ–¹å‘ã€‚
3. é™„è¡¨4 (æ”¯æ’‘çŸ©é˜µ) æå–è¯¾ç¨‹ä¸æŒ‡æ ‡ç‚¹çš„å¯¹åº”å¼ºåº¦ã€‚
"""

# ============================================================
# 2. ç®€åŒ–çš„è§£æå¼•æ“
# ============================================================
def parse_document_mega(api_key, pdf_bytes):
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash')
    
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        # ä¸€æ¬¡æ€§è¯»å–å…¨æ–‡æ–‡æœ¬
        all_text = "\n".join([p.extract_text() or "" for p in pdf.pages])
        
    st.info("æ­£åœ¨å‘é€å•æ¬¡å…¨é‡æŠ½å–è¯·æ±‚ï¼Œè¯·ç¨å€™ï¼ˆçº¦ 15-30 ç§’ï¼‰...")
    
    try:
        # åªå‘ä¸€æ¬¡è¯·æ±‚ï¼Œè§£å†³ ResourceExhausted é—®é¢˜
        full_prompt = f"{MEGA_PROMPT}\n\nåŸ¹å…»æ–¹æ¡ˆåŸæ–‡ï¼š\n{all_text}"
        result = call_llm(selected_provider, api_key, full_prompt)
        return result
    except Exception as e:
        st.error(f"æŠ½å–å¤±è´¥: {str(e)}")
        return None

# ============================================================
# 3. Streamlit UI
# ============================================================
def main():
    st.set_page_config(layout="wide", page_title="å¤šæ¨¡å‹æ™ºèƒ½æ•™å­¦å·¥ä½œå°")
    
    if "mega_data" not in st.session_state:
        st.session_state.mega_data = None

    with st.sidebar:
        st.title("ğŸ¤– æ¨¡å‹é…ç½®")
        selected_provider = st.selectbox("é€‰æ‹©æ¨¡å‹ä¾›åº”å•†", list(PROVIDERS.keys()))
        api_key = st.text_input(f"è¾“å…¥ {selected_provider} çš„ API Key", type="password")
        st.info(f"å½“å‰æ¨¡å‹: {PROVIDERS[selected_provider]['model']}")
        st.warning("å¦‚æœæç¤ºé…é¢è€—å°½ä¸”ç­‰å¾…æ— æ•ˆï¼Œè¯·æ›´æ¢ä¸€ä¸ªæ–°çš„ API Keyã€‚")        
   

    st.header("ğŸ§  åŸ¹å…»æ–¹æ¡ˆå…¨é‡æå– (å¤šæ¨¡å‹ç‰ˆ)")
    file = st.file_uploader("ä¸Šä¼  PDF åŸ¹å…»æ–¹æ¡ˆ", type="pdf")

    if file and api_key and st.button("ğŸš€ æ‰§è¡Œä¸€é”®å…¨é‡æŠ½å–", type="primary"):
        result = parse_document_mega(api_key, file.getvalue())
        if result:
            st.session_state.mega_data = result
            st.success("æŠ½å–æˆåŠŸï¼ä»…æ¶ˆè€— 1 æ¬¡ API è¯·æ±‚é…é¢ã€‚")


    if st.session_state.mega_data:
        d = st.session_state.mega_data
        tab1, tab2, tab3, tab4 = st.tabs(["1-6 æ­£æ–‡", "é™„è¡¨1: è®¡åˆ’è¡¨", "é™„è¡¨2: å­¦åˆ†ç»Ÿè®¡", "é™„è¡¨4: æ”¯æ’‘çŸ©é˜µ"])
        
        with tab1:
            sections = d.get("sections", {})
            sec_pick = st.selectbox("é€‰æ‹©æ ç›®", list(sections.keys()))
            st.text_area("å†…å®¹", value=sections.get(sec_pick, ""), height=400, key=f"ta_{sec_pick}")

        with tab2:
            st.dataframe(pd.DataFrame(d.get("table1", [])), use_container_width=True)

        with tab3:
            st.dataframe(pd.DataFrame(d.get("table2", [])), use_container_width=True)

        with tab4:
            st.dataframe(pd.DataFrame(d.get("table4", [])), use_container_width=True)

if __name__ == "__main__":
    main()