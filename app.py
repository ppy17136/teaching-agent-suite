import io, json, time, random, hashlib, base64
import pandas as pd
import streamlit as st
import pdfplumber
import google.generativeai as genai
from google.api_core import exceptions
from typing import Dict, List, Any

# ============================================================
# 1. å­—æ®µä¸å¸¸é‡å®šä¹‰
# ============================================================
TABLE_1_FULL_COLS = [
    "è¯¾ç¨‹ä½“ç³»", "è¯¾ç¨‹ç¼–ç ", "è¯¾ç¨‹åç§°", "å¼€è¯¾æ¨¡å¼", "è€ƒæ ¸æ–¹å¼", 
    "å­¦åˆ†", "æ€»å­¦æ—¶", "å†…_è®²è¯¾", "å†…_å®éªŒ", "å†…_ä¸Šæœº", "å†…_å®è·µ", 
    "å¤–_å­¦åˆ†", "å¤–_å­¦æ—¶", "ä¸Šè¯¾å­¦æœŸ", "ä¸“ä¸šæ–¹å‘", "å­¦ä½è¯¾", "å¤‡æ³¨"
]

# ============================================================
# 2. å·¥å…·å‡½æ•° (JSONã€æ–‡æœ¬ã€PDFå¤„ç†)
# ============================================================
def _compact_lines(s: str) -> str:
    s = (s or "").replace("\u00a0", " ")
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()

def payload_to_jsonable(obj):
    if isinstance(obj, pd.DataFrame):
        return obj.fillna("").to_dict(orient="records")
    if isinstance(obj, dict):
        return {str(k): payload_to_jsonable(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [payload_to_jsonable(x) for x in obj]
    return str(obj) if isinstance(obj, (io.BytesIO, bytes)) else obj

# ============================================================
# 3. AI è°ƒç”¨æ ¸å¿ƒ (å¸¦èŠ‚æµä¸é‡è¯•æœºåˆ¶)
# ============================================================
def ai_safe_call(model, prompt: str, max_retries=5):
    """ç¡®ä¿åœ¨ 15 RPM é™åˆ¶å†…ç¨³å®šè¿è¡Œ"""
    retries = 0
    while retries < max_retries:
        try:
            # å¼ºåˆ¶å†·å´ï¼Œç¡®ä¿æ¯åˆ†é’Ÿè¯·æ±‚ä¸è¶…è¿‡ 12 æ¬¡
            time.sleep(5) 
            response = model.generate_content(
                prompt, 
                generation_config={"response_mime_type": "application/json"}
            )
            return json.loads(response.text)
        except exceptions.ResourceExhausted:
            wait_time = (2 ** retries) * 5 + random.uniform(0, 1)
            st.warning(f"è§¦å‘ API é…é¢é™åˆ¶ï¼Œæ­£åœ¨ç­‰å¾… {int(wait_time)} ç§’åé‡è¯•...")
            time.sleep(wait_time)
            retries += 1
        except Exception as e:
            st.error(f"AI è°ƒç”¨å¼‚å¸¸: {e}")
            return None
    return None

def ai_process_large_table(model, raw_rows, prompt_prefix, chunk_size=80):
    """å°†é•¿è¡¨æ ¼åˆ†å—ï¼Œé˜²æ­¢ AI æˆªæ–­"""
    results = []
    total = len(raw_rows)
    for i in range(0, total, chunk_size):
        chunk = raw_rows[i : i + chunk_size]
        st.write(f"æ­£åœ¨å¤„ç†æ•°æ®å—ï¼š{i+1} è‡³ {min(i+chunk_size, total)} è¡Œ...")
        prompt = f"{prompt_prefix}\næ•°æ®ç‰‡æ®µï¼š{json.dumps(chunk, ensure_ascii=False)}"
        res = ai_safe_call(model, prompt)
        if isinstance(res, list):
            results.extend(res)
    return results

# ============================================================
# 4. æ–‡æ¡£æ·±åº¦è§£æå¼•æ“
# ============================================================
def deep_parse_document(api_key, pdf_bytes):
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash')
    results = {"sections": {}, "tables": {"1": [], "2": [], "4": []}}
    
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        # è·å–å…¨æ–‡æ–‡æœ¬ç”¨äºæ­£æ–‡åˆ†æ
        all_text = [p.extract_text() or "" for p in pdf.pages]
        
        # æå– 1-6 é¡¹æ­£æ–‡ [cite: 10, 21, 80, 88, 91]
        st.info("æ­£åœ¨æå–åŸ¹å…»æ–¹æ¡ˆ 1-6 é¡¹æ­£æ–‡...")
        sec_context = "\n".join(all_text[:6])
        results["sections"] = ai_safe_call(model, f"æå– 1-6 é¡¹æ­£æ–‡ JSONã€‚å†…å®¹ï¼š{sec_context}")

        # æ‰«æé™„è¡¨
        raw_t1, raw_t4, text_t2 = [], [], ""
        for i, page in enumerate(pdf.pages):
            txt = all_text[i]
            # é™„è¡¨1 æ‰€åœ¨é¡µ [cite: 105, 107, 109, 111]
            if "é™„è¡¨1" in txt or "æ•™å­¦è®¡åˆ’è¡¨" in txt:
                tbl = page.extract_table()
                if tbl: raw_t1.extend(tbl[1:])
            # é™„è¡¨2 æ‰€åœ¨é¡µ 
            elif "é™„è¡¨2" in txt or "å­¦åˆ†ç»Ÿè®¡" in txt:
                text_t2 += f"\n{txt}"
            # é™„è¡¨4 æ‰€åœ¨é¡µ [cite: 124, 127, 130, 131, 133]
            elif "é™„è¡¨4" in txt or "æ”¯æ’‘å…³ç³»" in txt:
                tbl = page.extract_table()
                if tbl: raw_t4.extend(tbl[1:])

        # æ‰§è¡Œåˆ†å—æŠ½å–
        if raw_t1:
            st.info("æ­£åœ¨å…¨é‡æ ¡å¯¹é™„è¡¨ 1...")
            results["tables"]["1"] = ai_process_large_table(model, raw_t1, f"è½¬æ¢æ•™å­¦è®¡åˆ’è¡¨ã€‚åˆ—ï¼š{TABLE_1_FULL_COLS}", chunk_size=80)
        
        if text_t2:
            st.info("æ­£åœ¨é‡æ„é™„è¡¨ 2 å­¦åˆ†ç»Ÿè®¡...")
            results["tables"]["2"] = ai_safe_call(model, f"æå–å­¦åˆ†ç»Ÿè®¡ JSONã€‚æ•°æ®ï¼š{text_t2}")

        if raw_t4:
            st.info("æ­£åœ¨å…¨é‡æ˜ å°„é™„è¡¨ 4 æ”¯æ’‘çŸ©é˜µ...")
            results["tables"]["4"] = ai_process_large_table(model, raw_t4, "æå–æ”¯æ’‘å…³ç³» JSON [è¯¾ç¨‹åç§°, æŒ‡æ ‡ç‚¹, å¼ºåº¦]", chunk_size=100)

    return results

# ============================================================
# 5. ä¸»ç•Œé¢é€»è¾‘ (ä¿®å¤ç©ºé¡µé¢é—®é¢˜)
# ============================================================
def main():
    st.set_page_config(layout="wide", page_title="æ•™å­¦æ–‡ä»¶æ™ºèƒ½å·¥ä½œå° v1.0", page_icon="ğŸ§ ")
    
    # åˆå§‹åŒ– session state
    if "final_data" not in st.session_state:
        st.session_state.final_data = None

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.title("âš™ï¸ è®¾ç½®")
        api_key = st.text_input("Gemini API Key", type="password", key="final_v1_key")
        st.divider()
        st.caption("ç‰ˆæœ¬: v1.0 ç¨³å®šå…¨é‡æŠ½å–ç‰ˆ")

    # ä¸»ä½“ç•Œé¢
    st.markdown("## ğŸ“‘ åŸ¹å…»æ–¹æ¡ˆå…¨é‡æ™ºèƒ½æŠ½å–å·¥ä½œå°")
    st.info("è¯·ç¡®ä¿å·²åœ¨ä¾§è¾¹æ é…ç½® API Keyã€‚æœ¬ç‰ˆæœ¬æ”¯æŒ 2.5 Flash å…è´¹ç‰ˆé…é¢è‡ªåŠ¨ç®¡ç†ã€‚")
    
    file = st.file_uploader("ä¸Šä¼  2024åŸ¹å…»æ–¹æ¡ˆ.pdf", type="pdf", key="final_v1_uploader")

    if file and api_key:
        if st.button("ğŸš€ æ‰§è¡Œä¸€é”®å…¨é‡æŠ½å–", type="primary", use_container_width=True, key="final_v1_btn"):
            data = deep_parse_document(api_key, file.getvalue())
            if data:
                st.session_state.final_data = data
                st.success("ğŸ‰ å…¨é‡æ•°æ®æŠ½å–æˆåŠŸï¼")

    # æ¸²æŸ“ç»“æœ
    if st.session_state.final_data:
        d = st.session_state.final_data
        tab1, tab2, tab3, tab4 = st.tabs(["1-6 æ­£æ–‡å†…å®¹", "é™„è¡¨1: æ•™å­¦è®¡åˆ’è¡¨", "é™„è¡¨2: å­¦åˆ†ç»Ÿè®¡è¡¨", "é™„è¡¨4: æ”¯æ’‘çŸ©é˜µè¡¨"])
        
        with tab1:
            sec_pick = st.selectbox("é€‰æ‹©æ ç›®æŸ¥çœ‹", ["1","2","3","4","5","6"], key="sec_v1_select")
            content = d["sections"].get(sec_pick, "æœªæå–åˆ°ç›¸å…³æ­£æ–‡")
            st.text_area("æå–ç»“æœ", value=content, height=450, key="sec_v1_ta")

        with tab2:
            df1 = pd.DataFrame(d["tables"].get("1", []))
            if not df1.empty:
                st.markdown(f"**å·²è¯†åˆ«è¯¾ç¨‹æ€»æ•°ï¼š{len(df1)} é—¨**")
                st.data_editor(df1.reindex(columns=TABLE_1_FULL_COLS), use_container_width=True, key="tbl1_v1_editor")
            else:
                st.warning("é™„è¡¨ 1 æš‚æ— æ•°æ®ã€‚")

        with tab3:
            df2 = pd.DataFrame(d["tables"].get("2", []))
            st.table(df2)

        with tab4:
            df4 = pd.DataFrame(d["tables"].get("4", []))
            st.dataframe(df4, use_container_width=True, key="tbl4_v1_df")

if __name__ == "__main__":
    main()